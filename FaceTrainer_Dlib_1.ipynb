{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Facial Recognition using PyTorch and OpenCV\n",
    "\n",
    "https://ritik12.medium.com/facial-recognition-using-pytorch-and-opencv-467c4e41d1f\n",
    "\n",
    "\n",
    "Machine Learning - Face Recognition CNN Pytorch.ipynb\n",
    "https://github.com/rubencg195/Pytorch-Tutorials/blob/master/Machine%20Learning%20-%20Face%20Recognition%20CNN%20Pytorch.ipynb\n",
    "\n",
    "\n",
    "\n",
    "Face Recognition Using Pytorch\n",
    "https://github.com/timesler/facenet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Landmarks Detection With PyTorch\n",
    "\n",
    "https://towardsdatascience.com/face-landmarks-detection-with-pytorch-4b4852f5e9c4\n",
    "\n",
    "\n",
    "\n",
    "다중입력 deep neural network\n",
    "https://rosenfelder.ai/multi-input-neural-network-pytorch/\n",
    "\n",
    "\n",
    "\n",
    "Understanding dimensions in PyTorch\n",
    "https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하기 \n",
    "https://github.com/deeplearningzerotoall/PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.init import *\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from FaceFeatureDataset import FaceFeatureDataset\n",
    "import dlib_index\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, F, C]: torch.Size([30, 2, 68])\n",
      "Shape of Tensor y: torch.Size([30, 33]) torch.float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "training_data = FaceFeatureDataset(\n",
    "    feature_file=\"./outimg/Train/facefeature.csv\", label_file=\"./Dataset/Train/csv/train.csv\")\n",
    "test_data = FaceFeatureDataset(\n",
    "    feature_file=\"./outimg/Test/facefeature.csv\", label_file=\"./Dataset/Test/csv/test.csv\")\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터 로드 확인\n",
    "for X, y in test_loader:\n",
    "    # N , Channel, H= width W = height\n",
    "    print(f\"Shape of X [N, F, C]: {X.shape}\")\n",
    "    print(f\"Shape of Tensor y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "n_total_steps = len(test_loader)\n",
    "\n",
    "plt.scatter(X[0][0], X[0][1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y[0])\n",
    "plt.show()\n",
    "\n",
    "# print(f'Traing dat length {n_total_steps}')\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=136, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Linear(in_features=64, out_features=33, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 33\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(68 * 2, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 배치 차원을 제외한 모든 차원을 하나로 평탄화(flatten)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='sum').to(device)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader : DataLoader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)        \n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        if batch % 99 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 294.250793  [    0/  100]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 272.254456  [    0/  100]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 250.726440  [    0/  100]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 223.633362  [    0/  100]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 146.285339  [    0/  100]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 68.013283  [    0/  100]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 76.474625  [    0/  100]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 39.523323  [    0/  100]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 40.987885  [    0/  100]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 33.686081  [    0/  100]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 34.299751  [    0/  100]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 33.775375  [    0/  100]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 31.861488  [    0/  100]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 31.261713  [    0/  100]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 31.480175  [    0/  100]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 30.087683  [    0/  100]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 30.916389  [    0/  100]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 30.583359  [    0/  100]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 30.110830  [    0/  100]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 30.967548  [    0/  100]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 29.889914  [    0/  100]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 30.921501  [    0/  100]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 30.649021  [    0/  100]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 29.957705  [    0/  100]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 30.136730  [    0/  100]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 30.146881  [    0/  100]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 29.462532  [    0/  100]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 29.919407  [    0/  100]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 29.389832  [    0/  100]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 30.299522  [    0/  100]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 29.948957  [    0/  100]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 30.264463  [    0/  100]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 30.706417  [    0/  100]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 29.528282  [    0/  100]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 30.515339  [    0/  100]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 29.200195  [    0/  100]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 29.195045  [    0/  100]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 30.340305  [    0/  100]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 29.738863  [    0/  100]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 30.702290  [    0/  100]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 30.004143  [    0/  100]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 29.515316  [    0/  100]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 30.232315  [    0/  100]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 29.387527  [    0/  100]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 29.918606  [    0/  100]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 29.843174  [    0/  100]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 30.044481  [    0/  100]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 30.772573  [    0/  100]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 31.069656  [    0/  100]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 29.723980  [    0/  100]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 30.380234  [    0/  100]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 30.738083  [    0/  100]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 30.432003  [    0/  100]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 30.167152  [    0/  100]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 30.320103  [    0/  100]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 30.615570  [    0/  100]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 29.222227  [    0/  100]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 28.849144  [    0/  100]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 30.366215  [    0/  100]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 29.973904  [    0/  100]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 30.034842  [    0/  100]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 30.604643  [    0/  100]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 30.148510  [    0/  100]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 30.896994  [    0/  100]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 29.692446  [    0/  100]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 30.083755  [    0/  100]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 30.435837  [    0/  100]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 29.664001  [    0/  100]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 30.131405  [    0/  100]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 30.730057  [    0/  100]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 30.568516  [    0/  100]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 29.510174  [    0/  100]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 29.999754  [    0/  100]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 30.604044  [    0/  100]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 29.941719  [    0/  100]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 31.667870  [    0/  100]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 30.276630  [    0/  100]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 31.106375  [    0/  100]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 29.836258  [    0/  100]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 31.147667  [    0/  100]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 30.104090  [    0/  100]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 29.912132  [    0/  100]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 29.426073  [    0/  100]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 29.514832  [    0/  100]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 29.200739  [    0/  100]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 30.180958  [    0/  100]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 30.040562  [    0/  100]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 29.895592  [    0/  100]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 30.817814  [    0/  100]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 30.143604  [    0/  100]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 30.220182  [    0/  100]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 30.157684  [    0/  100]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 29.900928  [    0/  100]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 30.541523  [    0/  100]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 32.048832  [    0/  100]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 30.031017  [    0/  100]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 29.008415  [    0/  100]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 30.160007  [    0/  100]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 31.644800  [    0/  100]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 29.030968  [    0/  100]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 30.321955  [    0/  100]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 30.194138  [    0/  100]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 28.856754  [    0/  100]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 30.834778  [    0/  100]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 29.517178  [    0/  100]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 28.935789  [    0/  100]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 29.609135  [    0/  100]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 29.776901  [    0/  100]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 30.360767  [    0/  100]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 30.660057  [    0/  100]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 31.443163  [    0/  100]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 30.401508  [    0/  100]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 29.536530  [    0/  100]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 30.371859  [    0/  100]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 28.712530  [    0/  100]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 30.615219  [    0/  100]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 29.696007  [    0/  100]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 29.877340  [    0/  100]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 30.335424  [    0/  100]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 29.757963  [    0/  100]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 30.314278  [    0/  100]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 29.240391  [    0/  100]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 29.320501  [    0/  100]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 30.911491  [    0/  100]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 28.868103  [    0/  100]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 31.228956  [    0/  100]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 30.628094  [    0/  100]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 30.516163  [    0/  100]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 28.826069  [    0/  100]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 29.268017  [    0/  100]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 29.035278  [    0/  100]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 29.234961  [    0/  100]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 30.536716  [    0/  100]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 30.400597  [    0/  100]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 28.691179  [    0/  100]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 28.471455  [    0/  100]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 29.104509  [    0/  100]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 29.500589  [    0/  100]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 29.541538  [    0/  100]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 29.776814  [    0/  100]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 29.794697  [    0/  100]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 30.254662  [    0/  100]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 30.269848  [    0/  100]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 29.655525  [    0/  100]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 29.429276  [    0/  100]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 28.747997  [    0/  100]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 30.395502  [    0/  100]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 30.565489  [    0/  100]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 28.872192  [    0/  100]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 29.992872  [    0/  100]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 29.458614  [    0/  100]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 29.288118  [    0/  100]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 31.568073  [    0/  100]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 29.844656  [    0/  100]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 30.172997  [    0/  100]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 29.274155  [    0/  100]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 29.685772  [    0/  100]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 29.219837  [    0/  100]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 28.792053  [    0/  100]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 30.437050  [    0/  100]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 30.183689  [    0/  100]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 29.895185  [    0/  100]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 30.320305  [    0/  100]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 30.472069  [    0/  100]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 30.847343  [    0/  100]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 29.626919  [    0/  100]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 29.726166  [    0/  100]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 29.964291  [    0/  100]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 29.022837  [    0/  100]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 29.617039  [    0/  100]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 29.954292  [    0/  100]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 30.021935  [    0/  100]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 30.062744  [    0/  100]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 30.675636  [    0/  100]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 29.557034  [    0/  100]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 28.945105  [    0/  100]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 30.265339  [    0/  100]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 29.748369  [    0/  100]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 29.669853  [    0/  100]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 30.216286  [    0/  100]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 29.138973  [    0/  100]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 28.431316  [    0/  100]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 30.507231  [    0/  100]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 29.751606  [    0/  100]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 29.554661  [    0/  100]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 30.343763  [    0/  100]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 28.509960  [    0/  100]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 30.227335  [    0/  100]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 29.785591  [    0/  100]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 29.829668  [    0/  100]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 29.467085  [    0/  100]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 27.886738  [    0/  100]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 29.014030  [    0/  100]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 30.020164  [    0/  100]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 27.974575  [    0/  100]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 28.263288  [    0/  100]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 29.059868  [    0/  100]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 29.601824  [    0/  100]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 30.174223  [    0/  100]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 28.826452  [    0/  100]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 29.011822  [    0/  100]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 28.885353  [    0/  100]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 30.382051  [    0/  100]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 29.337069  [    0/  100]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 30.293976  [    0/  100]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 27.747786  [    0/  100]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 28.882795  [    0/  100]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 27.762564  [    0/  100]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 30.081240  [    0/  100]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 29.397831  [    0/  100]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 28.469254  [    0/  100]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 28.277304  [    0/  100]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 28.051620  [    0/  100]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 29.308357  [    0/  100]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 30.755318  [    0/  100]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 28.778023  [    0/  100]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 30.595961  [    0/  100]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 28.821159  [    0/  100]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 28.819139  [    0/  100]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 29.475910  [    0/  100]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 29.258020  [    0/  100]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 28.565525  [    0/  100]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 30.219715  [    0/  100]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 28.948669  [    0/  100]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 28.049053  [    0/  100]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 30.500837  [    0/  100]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 29.729061  [    0/  100]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 28.902010  [    0/  100]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 30.611921  [    0/  100]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 29.726400  [    0/  100]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 29.040945  [    0/  100]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 29.866846  [    0/  100]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 27.404858  [    0/  100]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 29.009739  [    0/  100]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 27.671967  [    0/  100]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 29.756538  [    0/  100]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 28.698502  [    0/  100]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 29.434380  [    0/  100]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 28.834026  [    0/  100]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 29.472561  [    0/  100]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 28.729725  [    0/  100]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 29.247684  [    0/  100]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 28.309456  [    0/  100]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 27.814644  [    0/  100]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 27.903965  [    0/  100]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 28.238304  [    0/  100]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 30.037415  [    0/  100]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 27.681208  [    0/  100]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 28.853731  [    0/  100]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 28.070667  [    0/  100]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 30.256252  [    0/  100]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 28.842487  [    0/  100]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 29.081335  [    0/  100]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 28.224140  [    0/  100]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 29.330404  [    0/  100]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 29.127287  [    0/  100]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 28.951078  [    0/  100]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 29.562389  [    0/  100]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 29.961712  [    0/  100]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 27.585300  [    0/  100]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 29.848001  [    0/  100]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 30.141703  [    0/  100]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 30.365387  [    0/  100]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 30.186773  [    0/  100]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 29.723665  [    0/  100]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 31.078108  [    0/  100]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 28.055300  [    0/  100]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 29.450058  [    0/  100]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 30.508892  [    0/  100]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 28.642868  [    0/  100]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 29.636806  [    0/  100]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 28.729057  [    0/  100]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 28.080734  [    0/  100]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 28.298332  [    0/  100]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 28.675207  [    0/  100]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 28.661976  [    0/  100]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 29.939304  [    0/  100]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 29.168678  [    0/  100]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 29.068005  [    0/  100]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 29.487030  [    0/  100]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 30.026863  [    0/  100]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 28.702972  [    0/  100]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 29.029018  [    0/  100]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 29.166822  [    0/  100]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 28.993038  [    0/  100]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 29.464510  [    0/  100]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 28.804756  [    0/  100]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 27.996136  [    0/  100]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 28.515907  [    0/  100]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 29.003475  [    0/  100]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 28.876165  [    0/  100]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 29.615660  [    0/  100]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 29.150681  [    0/  100]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 28.053684  [    0/  100]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 29.085026  [    0/  100]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 29.306496  [    0/  100]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 28.277782  [    0/  100]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 28.503426  [    0/  100]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 28.800983  [    0/  100]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 27.769302  [    0/  100]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 27.800978  [    0/  100]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 27.560013  [    0/  100]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 30.262794  [    0/  100]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 29.322922  [    0/  100]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 28.867878  [    0/  100]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 27.830753  [    0/  100]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 28.204960  [    0/  100]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 27.896893  [    0/  100]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 29.223785  [    0/  100]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 28.271044  [    0/  100]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 28.441952  [    0/  100]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 27.750139  [    0/  100]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 28.802807  [    0/  100]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 28.594572  [    0/  100]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 28.421402  [    0/  100]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 28.403992  [    0/  100]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 29.361023  [    0/  100]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 28.962677  [    0/  100]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 28.754543  [    0/  100]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 30.839844  [    0/  100]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 29.783039  [    0/  100]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 30.306826  [    0/  100]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 29.042784  [    0/  100]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 30.831974  [    0/  100]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 26.622494  [    0/  100]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 29.939745  [    0/  100]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 28.473381  [    0/  100]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 28.573080  [    0/  100]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 28.261612  [    0/  100]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 27.494667  [    0/  100]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 29.048637  [    0/  100]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 30.145975  [    0/  100]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 28.830963  [    0/  100]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 29.154289  [    0/  100]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 29.109234  [    0/  100]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 28.492744  [    0/  100]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 28.107944  [    0/  100]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 28.257446  [    0/  100]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 28.715660  [    0/  100]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 29.225040  [    0/  100]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 28.427771  [    0/  100]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 28.836170  [    0/  100]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 28.503025  [    0/  100]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 27.048512  [    0/  100]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 29.845142  [    0/  100]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 27.121571  [    0/  100]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 28.284523  [    0/  100]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 28.451542  [    0/  100]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 27.450031  [    0/  100]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 27.230434  [    0/  100]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 28.998154  [    0/  100]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 28.605911  [    0/  100]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 28.523209  [    0/  100]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 28.399130  [    0/  100]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 27.011223  [    0/  100]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 30.154064  [    0/  100]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 28.085068  [    0/  100]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 27.068306  [    0/  100]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 28.423225  [    0/  100]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 28.838600  [    0/  100]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 26.924862  [    0/  100]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 28.712608  [    0/  100]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 27.766296  [    0/  100]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 27.965118  [    0/  100]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 27.461950  [    0/  100]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 28.019751  [    0/  100]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 27.671959  [    0/  100]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 27.825947  [    0/  100]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 27.430387  [    0/  100]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 29.204277  [    0/  100]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 27.701691  [    0/  100]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 28.593525  [    0/  100]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 27.384056  [    0/  100]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 27.753477  [    0/  100]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 27.384241  [    0/  100]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 26.581493  [    0/  100]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 28.811069  [    0/  100]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 27.454914  [    0/  100]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 28.628956  [    0/  100]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 28.373838  [    0/  100]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 28.598026  [    0/  100]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 27.643621  [    0/  100]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 27.981651  [    0/  100]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 28.386345  [    0/  100]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 30.174852  [    0/  100]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 27.868763  [    0/  100]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 27.938112  [    0/  100]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 28.472475  [    0/  100]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 27.171373  [    0/  100]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 27.714653  [    0/  100]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 26.131962  [    0/  100]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 27.554779  [    0/  100]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 27.734043  [    0/  100]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 26.502735  [    0/  100]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 27.350071  [    0/  100]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 28.460217  [    0/  100]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 27.289848  [    0/  100]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 28.538622  [    0/  100]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 27.033588  [    0/  100]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 28.738979  [    0/  100]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 28.120239  [    0/  100]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 27.373402  [    0/  100]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 28.003159  [    0/  100]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 27.624451  [    0/  100]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 24.933498  [    0/  100]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 28.363808  [    0/  100]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 27.704718  [    0/  100]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 28.086622  [    0/  100]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 28.826782  [    0/  100]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 28.267273  [    0/  100]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 28.330824  [    0/  100]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 27.749207  [    0/  100]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 25.244621  [    0/  100]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 28.137228  [    0/  100]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 26.988836  [    0/  100]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 26.231770  [    0/  100]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 27.120251  [    0/  100]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 27.613028  [    0/  100]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 27.667032  [    0/  100]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 27.585331  [    0/  100]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 26.335758  [    0/  100]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 26.629292  [    0/  100]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 26.861925  [    0/  100]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 25.930702  [    0/  100]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 26.869080  [    0/  100]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 27.041069  [    0/  100]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 26.151588  [    0/  100]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 26.260958  [    0/  100]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 26.610214  [    0/  100]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 26.878578  [    0/  100]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 27.918968  [    0/  100]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 27.401512  [    0/  100]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 27.819382  [    0/  100]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 28.075699  [    0/  100]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 28.395851  [    0/  100]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 26.536940  [    0/  100]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 27.140032  [    0/  100]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 27.798819  [    0/  100]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 26.874676  [    0/  100]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 26.146080  [    0/  100]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 26.357462  [    0/  100]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 27.382439  [    0/  100]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 25.718048  [    0/  100]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 27.668934  [    0/  100]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 26.075371  [    0/  100]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 28.205418  [    0/  100]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 26.588589  [    0/  100]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 27.061646  [    0/  100]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 26.699337  [    0/  100]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 26.471691  [    0/  100]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 27.470104  [    0/  100]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 28.012974  [    0/  100]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 26.501051  [    0/  100]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 26.825024  [    0/  100]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 27.040154  [    0/  100]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 26.592468  [    0/  100]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 27.259651  [    0/  100]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 26.737049  [    0/  100]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 27.040482  [    0/  100]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 26.065720  [    0/  100]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 25.572731  [    0/  100]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 27.082672  [    0/  100]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 25.648277  [    0/  100]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 25.583622  [    0/  100]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 27.656590  [    0/  100]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 28.127384  [    0/  100]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 25.755680  [    0/  100]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 26.432739  [    0/  100]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 26.950672  [    0/  100]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 26.601519  [    0/  100]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 25.652905  [    0/  100]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 25.335964  [    0/  100]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 26.107052  [    0/  100]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 27.474453  [    0/  100]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 26.395765  [    0/  100]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 26.158657  [    0/  100]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 26.993214  [    0/  100]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 27.330925  [    0/  100]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 26.833481  [    0/  100]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 27.344231  [    0/  100]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 27.111647  [    0/  100]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 26.751842  [    0/  100]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 26.856640  [    0/  100]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 25.830513  [    0/  100]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 25.755619  [    0/  100]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 23.957016  [    0/  100]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 27.831003  [    0/  100]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 25.488615  [    0/  100]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 25.859966  [    0/  100]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 27.355923  [    0/  100]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 26.274652  [    0/  100]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 26.199764  [    0/  100]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 26.108433  [    0/  100]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 26.066183  [    0/  100]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 26.206818  [    0/  100]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 25.625568  [    0/  100]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 24.382587  [    0/  100]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 25.585712  [    0/  100]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 25.151230  [    0/  100]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 27.119537  [    0/  100]\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 25.233070  [    0/  100]\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 26.978529  [    0/  100]\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 26.854406  [    0/  100]\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 26.111433  [    0/  100]\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 24.886002  [    0/  100]\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 26.485146  [    0/  100]\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 27.342257  [    0/  100]\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 26.473261  [    0/  100]\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 26.888653  [    0/  100]\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 25.394398  [    0/  100]\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 25.635767  [    0/  100]\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 26.336048  [    0/  100]\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 26.998215  [    0/  100]\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 24.793476  [    0/  100]\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 25.441730  [    0/  100]\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 25.176205  [    0/  100]\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 25.106201  [    0/  100]\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 26.119526  [    0/  100]\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 25.518171  [    0/  100]\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 26.483543  [    0/  100]\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 25.852873  [    0/  100]\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 25.670626  [    0/  100]\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 25.819254  [    0/  100]\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 28.897896  [    0/  100]\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 26.903095  [    0/  100]\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 26.775665  [    0/  100]\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 25.944654  [    0/  100]\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 26.491953  [    0/  100]\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 26.855022  [    0/  100]\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 24.756477  [    0/  100]\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 25.406469  [    0/  100]\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 26.787441  [    0/  100]\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 26.491495  [    0/  100]\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 26.095575  [    0/  100]\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 25.448669  [    0/  100]\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 26.881798  [    0/  100]\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 28.263756  [    0/  100]\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 29.580967  [    0/  100]\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 27.828053  [    0/  100]\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 27.583809  [    0/  100]\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 26.703611  [    0/  100]\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 25.809731  [    0/  100]\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 25.411289  [    0/  100]\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 27.059856  [    0/  100]\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 24.417084  [    0/  100]\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 25.118122  [    0/  100]\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 24.751720  [    0/  100]\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 25.526081  [    0/  100]\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 25.165302  [    0/  100]\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 24.617767  [    0/  100]\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 25.722586  [    0/  100]\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 25.289200  [    0/  100]\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 25.894489  [    0/  100]\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 25.447519  [    0/  100]\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 25.563576  [    0/  100]\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 26.955479  [    0/  100]\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 25.919489  [    0/  100]\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 25.664829  [    0/  100]\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 26.609978  [    0/  100]\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 27.435438  [    0/  100]\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 27.538254  [    0/  100]\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 28.532402  [    0/  100]\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 29.165998  [    0/  100]\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 30.442921  [    0/  100]\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 28.956593  [    0/  100]\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 26.248835  [    0/  100]\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 25.290997  [    0/  100]\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 25.918770  [    0/  100]\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 26.434860  [    0/  100]\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 24.579693  [    0/  100]\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 24.468763  [    0/  100]\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 26.952400  [    0/  100]\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 24.493446  [    0/  100]\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 23.993053  [    0/  100]\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 25.910297  [    0/  100]\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 24.793802  [    0/  100]\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 24.904388  [    0/  100]\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 26.179567  [    0/  100]\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 24.033030  [    0/  100]\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 25.727364  [    0/  100]\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 24.769466  [    0/  100]\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 24.723423  [    0/  100]\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 25.410448  [    0/  100]\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 25.280285  [    0/  100]\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 26.063023  [    0/  100]\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 25.498119  [    0/  100]\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 25.157436  [    0/  100]\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 24.984709  [    0/  100]\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 26.421652  [    0/  100]\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 25.013979  [    0/  100]\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 24.960472  [    0/  100]\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 25.790834  [    0/  100]\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 26.104828  [    0/  100]\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 25.407738  [    0/  100]\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 24.429171  [    0/  100]\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 26.342457  [    0/  100]\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 24.242373  [    0/  100]\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 24.042322  [    0/  100]\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 24.478260  [    0/  100]\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 25.898914  [    0/  100]\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 26.663410  [    0/  100]\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 24.939480  [    0/  100]\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 24.805973  [    0/  100]\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 24.725470  [    0/  100]\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 25.508568  [    0/  100]\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 23.380058  [    0/  100]\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 24.259300  [    0/  100]\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 25.909130  [    0/  100]\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 25.846512  [    0/  100]\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 24.382086  [    0/  100]\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 24.830559  [    0/  100]\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 24.653273  [    0/  100]\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 23.363369  [    0/  100]\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 25.164915  [    0/  100]\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 24.583809  [    0/  100]\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 21.935415  [    0/  100]\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 25.338402  [    0/  100]\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 24.634020  [    0/  100]\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 25.658443  [    0/  100]\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 25.111513  [    0/  100]\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 23.757450  [    0/  100]\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 24.933765  [    0/  100]\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 24.671501  [    0/  100]\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 22.997583  [    0/  100]\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 23.351166  [    0/  100]\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 23.727131  [    0/  100]\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 24.808651  [    0/  100]\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 25.387604  [    0/  100]\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 24.613382  [    0/  100]\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 24.329481  [    0/  100]\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 25.112869  [    0/  100]\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 24.809414  [    0/  100]\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 26.488947  [    0/  100]\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 25.438705  [    0/  100]\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 24.904018  [    0/  100]\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 25.704018  [    0/  100]\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 23.872120  [    0/  100]\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 23.272547  [    0/  100]\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 23.074913  [    0/  100]\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 23.043493  [    0/  100]\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 21.881954  [    0/  100]\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 24.043072  [    0/  100]\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 23.929512  [    0/  100]\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 23.931829  [    0/  100]\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 23.483438  [    0/  100]\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 24.642235  [    0/  100]\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 23.284863  [    0/  100]\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 25.526514  [    0/  100]\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 22.398796  [    0/  100]\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 24.061760  [    0/  100]\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 23.029175  [    0/  100]\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 24.351698  [    0/  100]\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 26.054047  [    0/  100]\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 24.297703  [    0/  100]\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 24.900181  [    0/  100]\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 23.284773  [    0/  100]\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 24.062092  [    0/  100]\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 24.881781  [    0/  100]\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 25.421013  [    0/  100]\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 25.381138  [    0/  100]\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 22.880882  [    0/  100]\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 23.078873  [    0/  100]\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 25.287048  [    0/  100]\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 22.343328  [    0/  100]\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 24.261047  [    0/  100]\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 24.555649  [    0/  100]\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 25.528458  [    0/  100]\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 23.668913  [    0/  100]\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 22.477798  [    0/  100]\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 23.886517  [    0/  100]\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 23.674778  [    0/  100]\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 23.771084  [    0/  100]\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 23.835436  [    0/  100]\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 23.072304  [    0/  100]\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 22.802166  [    0/  100]\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 23.794504  [    0/  100]\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 24.932934  [    0/  100]\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 24.464252  [    0/  100]\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 24.639103  [    0/  100]\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 23.168612  [    0/  100]\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 22.873301  [    0/  100]\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 23.927799  [    0/  100]\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 24.254002  [    0/  100]\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 24.470966  [    0/  100]\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 23.571335  [    0/  100]\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 22.077019  [    0/  100]\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 24.143349  [    0/  100]\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 23.721754  [    0/  100]\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 22.720573  [    0/  100]\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 24.587645  [    0/  100]\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 22.267998  [    0/  100]\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 23.430599  [    0/  100]\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 25.475725  [    0/  100]\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 24.342789  [    0/  100]\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 23.446072  [    0/  100]\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 23.572763  [    0/  100]\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 23.967815  [    0/  100]\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 23.846636  [    0/  100]\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 21.467579  [    0/  100]\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 24.562067  [    0/  100]\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 22.479450  [    0/  100]\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 22.996037  [    0/  100]\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 22.612881  [    0/  100]\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 24.621582  [    0/  100]\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 24.585316  [    0/  100]\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 22.416033  [    0/  100]\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 21.418364  [    0/  100]\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 22.793570  [    0/  100]\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 24.287571  [    0/  100]\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 23.362707  [    0/  100]\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 23.071106  [    0/  100]\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 22.035591  [    0/  100]\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 21.826805  [    0/  100]\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 23.272957  [    0/  100]\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 23.004505  [    0/  100]\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 23.661297  [    0/  100]\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 23.947176  [    0/  100]\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 23.522814  [    0/  100]\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 22.300859  [    0/  100]\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 22.458817  [    0/  100]\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 23.723785  [    0/  100]\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 25.658028  [    0/  100]\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 24.257652  [    0/  100]\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 25.384686  [    0/  100]\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 24.384296  [    0/  100]\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 24.081676  [    0/  100]\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 24.425949  [    0/  100]\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 22.709084  [    0/  100]\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 24.243586  [    0/  100]\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 25.738743  [    0/  100]\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 25.174522  [    0/  100]\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 23.563150  [    0/  100]\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 22.192162  [    0/  100]\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 23.276310  [    0/  100]\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 22.328024  [    0/  100]\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 22.535891  [    0/  100]\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 23.275068  [    0/  100]\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 23.325029  [    0/  100]\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 21.368937  [    0/  100]\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 23.031988  [    0/  100]\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 23.389317  [    0/  100]\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 22.752245  [    0/  100]\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 22.776188  [    0/  100]\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 22.269156  [    0/  100]\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 24.494200  [    0/  100]\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 22.815489  [    0/  100]\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 24.136223  [    0/  100]\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 21.551167  [    0/  100]\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 21.497593  [    0/  100]\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 22.832672  [    0/  100]\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 22.852528  [    0/  100]\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 20.806004  [    0/  100]\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 22.840349  [    0/  100]\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 21.516588  [    0/  100]\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 23.037971  [    0/  100]\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 22.191280  [    0/  100]\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 23.605896  [    0/  100]\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 20.971027  [    0/  100]\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 21.440418  [    0/  100]\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 23.053604  [    0/  100]\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 23.263718  [    0/  100]\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 23.199955  [    0/  100]\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 22.733225  [    0/  100]\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 21.985203  [    0/  100]\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 23.048237  [    0/  100]\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 22.134315  [    0/  100]\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 21.273792  [    0/  100]\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 23.079414  [    0/  100]\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 22.986605  [    0/  100]\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 23.119537  [    0/  100]\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 21.805511  [    0/  100]\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 22.686773  [    0/  100]\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 22.780598  [    0/  100]\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 20.922070  [    0/  100]\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 20.126251  [    0/  100]\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 20.047941  [    0/  100]\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 21.155361  [    0/  100]\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 21.848881  [    0/  100]\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 20.764500  [    0/  100]\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 22.586935  [    0/  100]\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 24.797161  [    0/  100]\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 21.207134  [    0/  100]\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 21.882095  [    0/  100]\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 21.290167  [    0/  100]\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 21.055380  [    0/  100]\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 21.131454  [    0/  100]\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 21.412960  [    0/  100]\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 23.109144  [    0/  100]\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 21.061155  [    0/  100]\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 20.618176  [    0/  100]\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 22.345558  [    0/  100]\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 20.728245  [    0/  100]\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 21.928802  [    0/  100]\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 21.976988  [    0/  100]\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 21.458349  [    0/  100]\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 21.674946  [    0/  100]\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 21.380684  [    0/  100]\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 21.144222  [    0/  100]\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 20.602741  [    0/  100]\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 22.133720  [    0/  100]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight tensor([[-0.0507, -0.0538, -0.0583,  ..., -0.1178, -0.0677, -0.0098],\n",
      "        [ 0.0450,  0.0659, -0.0452,  ..., -0.0470, -0.0930,  0.0414],\n",
      "        [-0.0831,  0.0607,  0.0019,  ...,  0.0189, -0.0017,  0.0397],\n",
      "        ...,\n",
      "        [ 0.0375, -0.0454,  0.0804,  ..., -0.0459, -0.0610, -0.0910],\n",
      "        [-0.0494, -0.0321,  0.0725,  ..., -0.1338,  0.0065, -0.0847],\n",
      "        [ 0.0828, -0.0328,  0.0712,  ..., -0.0540,  0.0294, -0.0287]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.0.bias tensor([-0.0414,  0.0209,  0.0406, -0.0428, -0.0373,  0.0648, -0.0728,  0.0496,\n",
      "         0.0220,  0.0066,  0.0366,  0.0684, -0.0166,  0.0539,  0.1003, -0.0132,\n",
      "        -0.0762,  0.0660,  0.0094,  0.1116, -0.0628,  0.0128,  0.0714, -0.0804,\n",
      "         0.0041,  0.0796, -0.0461,  0.0591, -0.0999, -0.0557,  0.0214,  0.0350,\n",
      "         0.0082,  0.0082, -0.0150, -0.0857, -0.0243,  0.0392,  0.0222, -0.0868,\n",
      "         0.0587,  0.0510,  0.0413,  0.0120,  0.0603,  0.0326,  0.0121, -0.0078,\n",
      "        -0.0687, -0.0593,  0.0672,  0.0793, -0.0219, -0.0226, -0.0440,  0.0072,\n",
      "        -0.0596,  0.0252,  0.0063, -0.0673, -0.0810,  0.0134, -0.0721,  0.0679,\n",
      "         0.0380,  0.1061,  0.0420, -0.0651,  0.0768,  0.0124,  0.0193, -0.0421,\n",
      "        -0.0494, -0.0248, -0.0108,  0.0111,  0.0644, -0.0458,  0.0634,  0.0106,\n",
      "        -0.0306,  0.0473,  0.0528, -0.0022,  0.0657, -0.0487,  0.0908, -0.0206,\n",
      "         0.0335,  0.0206, -0.0761, -0.0598, -0.0238,  0.0874, -0.0371,  0.0842,\n",
      "        -0.0247, -0.0685, -0.0309,  0.0579, -0.0569,  0.0671, -0.0803, -0.0236,\n",
      "        -0.0716, -0.0561,  0.0371,  0.0424, -0.0976,  0.0821,  0.0501, -0.0130,\n",
      "         0.0163,  0.1013,  0.0320, -0.0509,  0.0684,  0.0431, -0.0042,  0.0007,\n",
      "        -0.0214, -0.0762,  0.0223, -0.0182, -0.0315,  0.0307,  0.0666,  0.0631],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.2.weight tensor([[-0.0662,  0.1092, -0.0956,  ...,  0.0349,  0.1092, -0.0305],\n",
      "        [-0.0819,  0.0646,  0.0216,  ..., -0.0231, -0.0320,  0.0044],\n",
      "        [ 0.0026,  0.0218,  0.0208,  ...,  0.0909, -0.0553,  0.0206],\n",
      "        ...,\n",
      "        [ 0.0638,  0.0389,  0.0207,  ..., -0.0709,  0.0118,  0.0996],\n",
      "        [ 0.0467, -0.0559,  0.0456,  ...,  0.0612, -0.0814, -0.0820],\n",
      "        [ 0.0228,  0.0471,  0.0293,  ...,  0.0149, -0.0139, -0.0866]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.2.bias tensor([ 0.0748,  0.0310, -0.0872, -0.0880,  0.0323, -0.0839, -0.0532,  0.0867,\n",
      "        -0.0326, -0.0193, -0.1163, -0.0591,  0.0996,  0.0167,  0.0926, -0.0056,\n",
      "         0.0060,  0.1022, -0.0284, -0.0710,  0.0419, -0.0300, -0.0281, -0.0512,\n",
      "         0.0571, -0.0157, -0.0683,  0.0517, -0.0011, -0.0998, -0.0174,  0.1109,\n",
      "        -0.0815, -0.0101,  0.0750,  0.1298,  0.0883, -0.0280, -0.0768,  0.0833,\n",
      "         0.0443, -0.0016, -0.0255,  0.0746, -0.0008,  0.1136,  0.0122,  0.0977,\n",
      "        -0.0276,  0.0728,  0.0638, -0.0442, -0.0227, -0.0563,  0.1229,  0.0357,\n",
      "         0.1455,  0.0564,  0.0842,  0.0824,  0.0297, -0.0428, -0.0013,  0.1067,\n",
      "        -0.0350, -0.0945, -0.0276,  0.0173,  0.0222,  0.0002, -0.0908,  0.0647,\n",
      "         0.0863,  0.0950, -0.0049,  0.0427, -0.0413, -0.1189,  0.0930, -0.0086,\n",
      "         0.1130, -0.0171,  0.0670, -0.0469,  0.0691, -0.0450,  0.0138, -0.0372,\n",
      "        -0.0321, -0.0746, -0.0801,  0.0817, -0.0323,  0.1074,  0.0928, -0.0459,\n",
      "        -0.0926,  0.0933, -0.0616,  0.1393,  0.0605, -0.0194, -0.0390,  0.0995,\n",
      "        -0.0910,  0.1426, -0.1132, -0.1436,  0.0924,  0.0376,  0.0067, -0.0497,\n",
      "         0.0811, -0.0333, -0.0109,  0.0636, -0.1178, -0.1162,  0.0685,  0.0184,\n",
      "        -0.0138, -0.0599,  0.0388,  0.0425, -0.0769,  0.0902,  0.0457, -0.0084],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.4.weight tensor([[-0.0199,  0.0420,  0.0550,  ..., -0.0996,  0.0101,  0.0025],\n",
      "        [-0.0218, -0.0675, -0.0127,  ...,  0.0824, -0.0252, -0.0485],\n",
      "        [ 0.0298,  0.0117,  0.0033,  ...,  0.0600, -0.0590, -0.0486],\n",
      "        ...,\n",
      "        [-0.1301, -0.0147,  0.1123,  ...,  0.0844, -0.1270, -0.0751],\n",
      "        [-0.0319, -0.0088,  0.0554,  ...,  0.0688,  0.0243,  0.0456],\n",
      "        [ 0.0371, -0.0453,  0.0756,  ..., -0.0668,  0.0601,  0.1064]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.4.bias tensor([-1.7587e-02,  9.5112e-02, -5.6393e-02, -1.1067e-01, -3.5454e-02,\n",
      "         4.2335e-02,  2.4548e-02,  5.9707e-02,  1.1564e-04, -2.2104e-02,\n",
      "        -1.0137e-01, -1.2639e-01, -6.2525e-02,  9.2459e-02,  1.2313e-01,\n",
      "        -5.8532e-02,  6.3333e-02,  9.8105e-02,  8.5748e-02, -4.0271e-02,\n",
      "         1.5066e-01,  2.2294e-02,  6.1796e-02,  9.1570e-02,  7.6535e-02,\n",
      "         1.2173e-02, -1.3463e-01,  2.8561e-03, -8.3898e-02,  3.9468e-02,\n",
      "        -3.2107e-02, -8.8165e-02, -1.2670e-01,  6.0537e-02, -1.0970e-01,\n",
      "         5.3045e-02,  8.6319e-02, -1.1326e-01,  5.5671e-02, -3.2944e-02,\n",
      "        -4.4510e-02,  1.3249e-01,  1.3391e-01,  1.0069e-01, -9.9838e-02,\n",
      "        -3.7365e-02, -1.0537e-01, -3.1509e-02, -1.1070e-01,  1.1607e-01,\n",
      "         8.5615e-02,  5.9615e-02,  8.8654e-02,  1.5442e-01,  5.6296e-02,\n",
      "         6.6753e-02, -6.3221e-02,  2.1259e-02,  4.5019e-02,  1.3683e-02,\n",
      "         7.1624e-02, -1.0580e-01, -9.0194e-02,  7.9597e-02], device='cuda:0')\n",
      "linear_relu_stack.6.weight tensor([[-0.0213,  0.0607,  0.0517,  ..., -0.1081, -0.0375,  0.1284],\n",
      "        [-0.0493,  0.0477,  0.0346,  ..., -0.1322, -0.0602, -0.0690],\n",
      "        [ 0.0547, -0.0394,  0.0180,  ...,  0.1558,  0.1041, -0.0443],\n",
      "        ...,\n",
      "        [-0.0686, -0.0486, -0.0087,  ...,  0.0448, -0.0858,  0.1085],\n",
      "        [ 0.1049, -0.1113, -0.0540,  ..., -0.0687,  0.0303, -0.0363],\n",
      "        [ 0.0412,  0.0573, -0.1183,  ..., -0.1610,  0.1168,  0.0313]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.6.bias tensor([-0.0532,  0.1276, -0.1515, -0.0467,  0.0670,  0.1791,  0.0610,  0.1887,\n",
      "         0.0602, -0.1420,  0.1321,  0.0672, -0.2151, -0.1524, -0.0521, -0.0309,\n",
      "        -0.1086,  0.0582, -0.1482,  0.1276,  0.1175,  0.0494,  0.1008, -0.0550,\n",
      "         0.0002,  0.0731,  0.1766,  0.1911, -0.1116,  0.1287, -0.0321,  0.0403,\n",
      "         0.0922, -0.0275,  0.1036, -0.1095,  0.0643, -0.0073,  0.0610, -0.0263,\n",
      "        -0.0380, -0.1029,  0.0344, -0.1009, -0.1033,  0.0070, -0.1568,  0.0257,\n",
      "         0.0134,  0.0867,  0.0994, -0.0103, -0.0509,  0.0901, -0.0973, -0.1390,\n",
      "         0.1808, -0.0280,  0.0691,  0.0353,  0.0121, -0.1111, -0.1089,  0.1089],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.8.weight tensor([[-0.0259, -0.0733,  0.1017,  ...,  0.0459, -0.1540,  0.0546],\n",
      "        [ 0.1404,  0.1640, -0.2606,  ..., -0.0514, -0.2188,  0.0716],\n",
      "        [ 0.0695, -0.0967,  0.0309,  ..., -0.0383, -0.0447, -0.1129],\n",
      "        ...,\n",
      "        [-0.0642, -0.0070,  0.0573,  ...,  0.0805, -0.2418, -0.1463],\n",
      "        [-0.1089,  0.0299, -0.0730,  ..., -0.0897,  0.1714,  0.0298],\n",
      "        [-0.0769, -0.2588, -0.0729,  ...,  0.0317, -0.0944,  0.0508]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.8.bias tensor([-0.0520,  0.1211, -0.0145,  0.1094,  0.0725,  0.0923,  0.0437,  0.0397,\n",
      "         0.0496,  0.1599,  0.0514, -0.1222,  0.0034,  0.0559, -0.0211,  0.0625,\n",
      "        -0.0554,  0.1530, -0.0346,  0.0788,  0.0385, -0.0361, -0.0051,  0.0027,\n",
      "         0.1779,  0.1003,  0.0826,  0.0296,  0.0602,  0.1578,  0.1424, -0.1341,\n",
      "        -0.0800,  0.0985, -0.1545, -0.0823, -0.2161, -0.1023,  0.1049, -0.0870,\n",
      "        -0.1475,  0.1094,  0.0582,  0.0979, -0.0887, -0.0564,  0.0668,  0.0999,\n",
      "        -0.0355,  0.0189,  0.1250, -0.0467,  0.0811, -0.0698, -0.1258,  0.0785,\n",
      "        -0.0496, -0.1924, -0.1146, -0.1001,  0.0762, -0.1373,  0.0350, -0.0098],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.10.weight tensor([[-0.1161, -0.0499,  0.0749,  ..., -0.0343, -0.0141, -0.0496],\n",
      "        [-0.1196, -0.0265,  0.0010,  ...,  0.0723,  0.1544, -0.1433],\n",
      "        [-0.0161, -0.0118,  0.0013,  ..., -0.0680, -0.0210,  0.1277],\n",
      "        ...,\n",
      "        [-0.0082, -0.0482, -0.0618,  ..., -0.0646,  0.1099, -0.1223],\n",
      "        [-0.0088,  0.1347, -0.0735,  ..., -0.0710,  0.0363,  0.0063],\n",
      "        [ 0.0399,  0.1105,  0.1842,  ..., -0.0744, -0.0072,  0.0836]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.10.bias tensor([ 0.0298,  0.0158,  0.1188,  0.1005, -0.0431,  0.0449,  0.0919,  0.0307,\n",
      "        -0.0374, -0.0474,  0.0413,  0.1193, -0.0333, -0.0694,  0.0701, -0.1061,\n",
      "         0.1199, -0.0094,  0.0241,  0.0930, -0.0333, -0.0094,  0.0277,  0.0783,\n",
      "         0.0030,  0.0580,  0.0874, -0.0313, -0.0271, -0.1076, -0.0891,  0.0826,\n",
      "         0.1461], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader : DataLoader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print('test size', size, 'batch size :', dataloader.batch_size)\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        '''\n",
    "        for i, (X, y) in enumerate(dataloader.dataset):            \n",
    "            X = torch.Tensor([X])             \n",
    "            pred = model(X.to(device))\n",
    "            print('I', i)            \n",
    "            print ('Pred ', pred)\n",
    "        # for batch, (X, y) in enumerate(dataloader):\n",
    "        '''\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)            \n",
    "            print('indices =', X.indices)\n",
    "            print('pred =', pred)\n",
    "            #print('loss', loss)\n",
    "            #print('real', y)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size 100 batch size : 30\n",
      "indices = <built-in method indices of Tensor object at 0x000002E69B283380>\n",
      "pred = tensor([[0.6200, 0.5152, 0.3689, 0.4877, 0.5129, 0.3522, 0.3712, 0.5296, 0.5507,\n",
      "         0.5992, 0.6317, 0.5392, 0.5530, 0.4091, 0.6437, 0.4567, 0.6903, 0.5429,\n",
      "         0.3552, 0.4040, 0.5030, 0.5318, 0.3977, 0.5437, 0.5737, 0.5506, 0.5289,\n",
      "         0.4881, 0.5702, 0.4304, 0.5076, 0.5426, 0.4897],\n",
      "        [0.4419, 0.4760, 0.5503, 0.5430, 0.5447, 0.4943, 0.4739, 0.5334, 0.5362,\n",
      "         0.5718, 0.5135, 0.5057, 0.4995, 0.5436, 0.5097, 0.5199, 0.4907, 0.5854,\n",
      "         0.5290, 0.6028, 0.4635, 0.5308, 0.5286, 0.5337, 0.5657, 0.5271, 0.4813,\n",
      "         0.5585, 0.4866, 0.5840, 0.5527, 0.5333, 0.4879],\n",
      "        [0.4789, 0.3325, 0.5627, 0.5095, 0.4546, 0.4566, 0.5404, 0.4299, 0.5184,\n",
      "         0.3987, 0.5685, 0.5580, 0.3870, 0.5137, 0.4061, 0.4530, 0.5386, 0.5081,\n",
      "         0.4823, 0.3812, 0.4787, 0.4784, 0.2492, 0.4130, 0.4786, 0.4863, 0.5931,\n",
      "         0.5300, 0.3802, 0.4741, 0.5734, 0.4407, 0.4627],\n",
      "        [0.2413, 0.7384, 0.4634, 0.3691, 0.3929, 0.5918, 0.3363, 0.5104, 0.5259,\n",
      "         0.6055, 0.3856, 0.3558, 0.6591, 0.4318, 0.5220, 0.4386, 0.5416, 0.5611,\n",
      "         0.5899, 0.2572, 0.4375, 0.5468, 0.7029, 0.3637, 0.4774, 0.3881, 0.4385,\n",
      "         0.5688, 0.4345, 0.3730, 0.2832, 0.2622, 0.2491],\n",
      "        [0.5834, 0.5124, 0.5247, 0.5796, 0.4515, 0.5276, 0.4996, 0.3915, 0.4398,\n",
      "         0.3295, 0.5327, 0.4960, 0.4230, 0.5538, 0.3433, 0.5900, 0.4556, 0.4574,\n",
      "         0.4122, 0.3896, 0.5690, 0.4959, 0.3694, 0.4511, 0.4757, 0.4163, 0.6692,\n",
      "         0.4841, 0.4970, 0.4142, 0.7514, 0.5251, 0.4046],\n",
      "        [0.3437, 0.3861, 0.4852, 0.5443, 0.4655, 0.6242, 0.4724, 0.5391, 0.5713,\n",
      "         0.6136, 0.3914, 0.4998, 0.3699, 0.4909, 0.6492, 0.5470, 0.3108, 0.5096,\n",
      "         0.5167, 0.6224, 0.4908, 0.6114, 0.5154, 0.3832, 0.5299, 0.5726, 0.4824,\n",
      "         0.5106, 0.4948, 0.5216, 0.6595, 0.4366, 0.5009],\n",
      "        [0.4940, 0.5030, 0.5709, 0.5342, 0.5153, 0.5191, 0.4685, 0.5695, 0.5294,\n",
      "         0.5708, 0.5078, 0.5034, 0.4464, 0.5367, 0.5285, 0.5697, 0.4830, 0.5682,\n",
      "         0.5193, 0.5960, 0.5461, 0.5142, 0.4336, 0.5671, 0.6168, 0.5462, 0.5325,\n",
      "         0.4771, 0.5054, 0.5768, 0.6969, 0.5535, 0.4630],\n",
      "        [0.4104, 0.4262, 0.5375, 0.5484, 0.5191, 0.4611, 0.5003, 0.5144, 0.5170,\n",
      "         0.5257, 0.5102, 0.5186, 0.5073, 0.5361, 0.5228, 0.4903, 0.4392, 0.5823,\n",
      "         0.5530, 0.6137, 0.4280, 0.5494, 0.4747, 0.4896, 0.5457, 0.5324, 0.4774,\n",
      "         0.5912, 0.4444, 0.5477, 0.5567, 0.5135, 0.4765],\n",
      "        [0.3633, 0.3940, 0.5570, 0.5454, 0.4971, 0.5403, 0.4384, 0.5400, 0.5673,\n",
      "         0.6314, 0.4350, 0.5101, 0.4114, 0.5070, 0.6072, 0.5560, 0.3894, 0.5428,\n",
      "         0.4961, 0.6005, 0.4866, 0.5762, 0.5748, 0.4408, 0.5593, 0.5421, 0.4661,\n",
      "         0.5761, 0.5009, 0.5361, 0.6154, 0.4751, 0.4914],\n",
      "        [0.5688, 0.5564, 0.5139, 0.5191, 0.4972, 0.4927, 0.5055, 0.5513, 0.4840,\n",
      "         0.4983, 0.5279, 0.5002, 0.4556, 0.5111, 0.4571, 0.5314, 0.5235, 0.5652,\n",
      "         0.5146, 0.5699, 0.5463, 0.4595, 0.3260, 0.6004, 0.6286, 0.5225, 0.5433,\n",
      "         0.4032, 0.4825, 0.5529, 0.7317, 0.5883, 0.4256],\n",
      "        [0.4767, 0.4941, 0.4851, 0.5189, 0.5296, 0.5196, 0.4579, 0.4863, 0.5035,\n",
      "         0.5412, 0.4708, 0.4670, 0.5348, 0.5048, 0.4744, 0.4889, 0.5000, 0.5500,\n",
      "         0.4717, 0.5844, 0.4779, 0.5035, 0.5966, 0.5173, 0.5405, 0.4795, 0.4706,\n",
      "         0.4912, 0.5050, 0.5186, 0.5149, 0.5682, 0.4675],\n",
      "        [0.4343, 0.4846, 0.5151, 0.5153, 0.5240, 0.5390, 0.4063, 0.5080, 0.5468,\n",
      "         0.5967, 0.4674, 0.4860, 0.4510, 0.5061, 0.4699, 0.5330, 0.4926, 0.5539,\n",
      "         0.4552, 0.5346, 0.4776, 0.4948, 0.6343, 0.5240, 0.5535, 0.4645, 0.4436,\n",
      "         0.5222, 0.5323, 0.5348, 0.5370, 0.5221, 0.4819],\n",
      "        [0.4922, 0.5026, 0.5577, 0.5192, 0.5302, 0.5165, 0.5091, 0.5768, 0.5345,\n",
      "         0.5566, 0.5109, 0.5152, 0.4411, 0.5302, 0.5183, 0.5363, 0.4977, 0.5709,\n",
      "         0.5432, 0.6283, 0.5167, 0.5023, 0.3804, 0.5730, 0.6129, 0.5695, 0.5275,\n",
      "         0.4645, 0.4603, 0.5939, 0.6837, 0.5460, 0.4654],\n",
      "        [0.4342, 0.4896, 0.5597, 0.5270, 0.5161, 0.4190, 0.4413, 0.5201, 0.4896,\n",
      "         0.5208, 0.5525, 0.4881, 0.4471, 0.5315, 0.4561, 0.4962, 0.5050, 0.6026,\n",
      "         0.5234, 0.5413, 0.4253, 0.4932, 0.4024, 0.5576, 0.5879, 0.4985, 0.4543,\n",
      "         0.5413, 0.4503, 0.5721, 0.5541, 0.5017, 0.4944],\n",
      "        [0.4244, 0.4366, 0.5911, 0.5439, 0.5110, 0.5551, 0.3975, 0.5491, 0.5618,\n",
      "         0.6331, 0.4564, 0.5192, 0.4119, 0.5159, 0.5480, 0.6096, 0.4502, 0.5559,\n",
      "         0.4658, 0.5689, 0.5194, 0.5398, 0.6303, 0.5153, 0.5805, 0.5126, 0.4853,\n",
      "         0.5747, 0.5577, 0.5414, 0.6303, 0.4981, 0.4994],\n",
      "        [0.5489, 0.4165, 0.6234, 0.4648, 0.5706, 0.4874, 0.4741, 0.5087, 0.4776,\n",
      "         0.5111, 0.4896, 0.5211, 0.5390, 0.5785, 0.4551, 0.4030, 0.2544, 0.5555,\n",
      "         0.5568, 0.6440, 0.6261, 0.5150, 0.7016, 0.4622, 0.4193, 0.3414, 0.6043,\n",
      "         0.5537, 0.4431, 0.4350, 0.5673, 0.4970, 0.5534],\n",
      "        [0.4364, 0.3021, 0.5367, 0.4634, 0.4754, 0.4771, 0.5301, 0.4752, 0.5797,\n",
      "         0.4736, 0.5404, 0.5684, 0.3558, 0.4657, 0.4225, 0.4184, 0.5850, 0.5098,\n",
      "         0.4763, 0.4059, 0.4416, 0.4503, 0.3261, 0.4343, 0.4564, 0.4943, 0.5383,\n",
      "         0.5210, 0.3849, 0.5040, 0.4659, 0.4088, 0.4847],\n",
      "        [0.5036, 0.4550, 0.4753, 0.5374, 0.5171, 0.4125, 0.5491, 0.4829, 0.4473,\n",
      "         0.4214, 0.5523, 0.5000, 0.5920, 0.5090, 0.4839, 0.4112, 0.5067, 0.5863,\n",
      "         0.5579, 0.6427, 0.4028, 0.5037, 0.4053, 0.5277, 0.5291, 0.5185, 0.4944,\n",
      "         0.5359, 0.4260, 0.5174, 0.4889, 0.5700, 0.4717],\n",
      "        [0.4557, 0.3064, 0.5208, 0.4494, 0.4609, 0.4909, 0.4906, 0.5052, 0.6131,\n",
      "         0.5266, 0.5142, 0.5912, 0.3536, 0.4174, 0.4582, 0.4536, 0.6198, 0.4725,\n",
      "         0.4340, 0.4086, 0.4668, 0.4605, 0.3888, 0.4523, 0.4287, 0.5065, 0.5663,\n",
      "         0.5221, 0.4307, 0.5070, 0.4129, 0.4035, 0.4514],\n",
      "        [0.3238, 0.5975, 0.3811, 0.4518, 0.4642, 0.6514, 0.3513, 0.4968, 0.4218,\n",
      "         0.4425, 0.5126, 0.4256, 0.5703, 0.4978, 0.4490, 0.4472, 0.6026, 0.5080,\n",
      "         0.4801, 0.2331, 0.3605, 0.5717, 0.3670, 0.4138, 0.4991, 0.3441, 0.4840,\n",
      "         0.5887, 0.4454, 0.3950, 0.3446, 0.4177, 0.4935],\n",
      "        [0.3957, 0.5076, 0.3425, 0.4500, 0.5582, 0.5575, 0.3763, 0.5098, 0.5565,\n",
      "         0.4601, 0.5840, 0.5843, 0.5436, 0.5022, 0.4672, 0.4389, 0.6419, 0.5175,\n",
      "         0.4364, 0.2244, 0.3403, 0.5584, 0.3302, 0.4968, 0.4819, 0.4596, 0.4849,\n",
      "         0.5036, 0.4557, 0.3813, 0.4079, 0.4394, 0.5322],\n",
      "        [0.5349, 0.5247, 0.3318, 0.4636, 0.5061, 0.4609, 0.5003, 0.4388, 0.4075,\n",
      "         0.4357, 0.4957, 0.3239, 0.6031, 0.4871, 0.4971, 0.3267, 0.5256, 0.4892,\n",
      "         0.4983, 0.5914, 0.4300, 0.5017, 0.4402, 0.5480, 0.5221, 0.4043, 0.4688,\n",
      "         0.2660, 0.4658, 0.4959, 0.3472, 0.6369, 0.4824],\n",
      "        [0.4404, 0.4917, 0.4899, 0.5095, 0.5292, 0.5743, 0.3975, 0.4919, 0.5581,\n",
      "         0.5981, 0.4452, 0.4845, 0.4608, 0.4975, 0.4498, 0.5442, 0.4969, 0.5252,\n",
      "         0.4242, 0.5152, 0.4972, 0.4915, 0.7103, 0.5062, 0.5323, 0.4423, 0.4514,\n",
      "         0.5075, 0.5522, 0.5156, 0.5196, 0.5358, 0.4669],\n",
      "        [0.5098, 0.4439, 0.4924, 0.5515, 0.5231, 0.3939, 0.5724, 0.4960, 0.4450,\n",
      "         0.4010, 0.5932, 0.5279, 0.5969, 0.5277, 0.4932, 0.4178, 0.5150, 0.6078,\n",
      "         0.5962, 0.6608, 0.3825, 0.5207, 0.3486, 0.5458, 0.5348, 0.5422, 0.5052,\n",
      "         0.5753, 0.4242, 0.5477, 0.4924, 0.5644, 0.4905],\n",
      "        [0.6105, 0.5388, 0.4899, 0.5060, 0.4870, 0.5934, 0.4961, 0.5772, 0.5208,\n",
      "         0.5518, 0.4615, 0.5348, 0.4236, 0.4706, 0.4873, 0.5891, 0.5179, 0.5061,\n",
      "         0.4680, 0.5850, 0.6282, 0.4486, 0.4374, 0.5945, 0.6213, 0.5213, 0.5780,\n",
      "         0.3711, 0.5526, 0.5253, 0.8008, 0.6137, 0.3913],\n",
      "        [0.5015, 0.5087, 0.3268, 0.4959, 0.5180, 0.5097, 0.5064, 0.4032, 0.4251,\n",
      "         0.4207, 0.5270, 0.3225, 0.5531, 0.4819, 0.5018, 0.3197, 0.5452, 0.5051,\n",
      "         0.4836, 0.5612, 0.3820, 0.5025, 0.4053, 0.4920, 0.4909, 0.4360, 0.4400,\n",
      "         0.3012, 0.4508, 0.5188, 0.3535, 0.5878, 0.4855],\n",
      "        [0.5271, 0.4973, 0.5517, 0.5310, 0.4837, 0.5473, 0.4323, 0.5556, 0.5175,\n",
      "         0.5719, 0.4745, 0.5031, 0.4345, 0.5037, 0.5246, 0.6032, 0.4728, 0.5379,\n",
      "         0.4625, 0.5634, 0.5913, 0.5004, 0.5046, 0.5575, 0.6073, 0.5096, 0.5417,\n",
      "         0.4613, 0.5635, 0.5211, 0.7291, 0.5678, 0.4394],\n",
      "        [0.4937, 0.2814, 0.6080, 0.3034, 0.6445, 0.6064, 0.5288, 0.6728, 0.4558,\n",
      "         0.6220, 0.4432, 0.2948, 0.4808, 0.6186, 0.4229, 0.3334, 0.1931, 0.4260,\n",
      "         0.5772, 0.6428, 0.6428, 0.6002, 0.7676, 0.5612, 0.3524, 0.2420, 0.6603,\n",
      "         0.2651, 0.4637, 0.5334, 0.3752, 0.5175, 0.7078],\n",
      "        [0.6149, 0.5770, 0.4320, 0.4980, 0.5207, 0.6151, 0.5016, 0.3440, 0.4407,\n",
      "         0.3158, 0.6310, 0.4380, 0.5117, 0.4189, 0.5524, 0.3281, 0.6335, 0.5561,\n",
      "         0.4917, 0.6360, 0.4901, 0.4861, 0.5855, 0.3857, 0.5126, 0.4695, 0.5388,\n",
      "         0.4484, 0.4094, 0.3415, 0.3012, 0.5585, 0.4286],\n",
      "        [0.4826, 0.6856, 0.3374, 0.5363, 0.4715, 0.6301, 0.4130, 0.3567, 0.4543,\n",
      "         0.5105, 0.4434, 0.2495, 0.6267, 0.5068, 0.5289, 0.4301, 0.4931, 0.4780,\n",
      "         0.4595, 0.5517, 0.5175, 0.5679, 0.6693, 0.4794, 0.5529, 0.4000, 0.4900,\n",
      "         0.2794, 0.5193, 0.4927, 0.3784, 0.6052, 0.3600]], device='cuda:0')\n",
      "indices = <built-in method indices of Tensor object at 0x000002E69B281260>\n",
      "pred = tensor([[0.4344, 0.4760, 0.4997, 0.5068, 0.5140, 0.5406, 0.3997, 0.4918, 0.5330,\n",
      "         0.5846, 0.4496, 0.4761, 0.4506, 0.4882, 0.4640, 0.5203, 0.4852, 0.5418,\n",
      "         0.4370, 0.5314, 0.4743, 0.4888, 0.6433, 0.5101, 0.5454, 0.4524, 0.4371,\n",
      "         0.5088, 0.5266, 0.5058, 0.5302, 0.5212, 0.4781],\n",
      "        [0.5373, 0.7451, 0.3744, 0.5442, 0.4705, 0.7052, 0.4339, 0.2807, 0.4491,\n",
      "         0.4057, 0.5129, 0.2909, 0.6113, 0.4719, 0.5638, 0.4025, 0.5388, 0.5181,\n",
      "         0.4725, 0.6029, 0.5615, 0.5644, 0.7400, 0.4012, 0.5786, 0.4180, 0.5620,\n",
      "         0.3446, 0.4573, 0.3490, 0.3348, 0.5739, 0.3239],\n",
      "        [0.5483, 0.5693, 0.5363, 0.3537, 0.6297, 0.5908, 0.4367, 0.4492, 0.5811,\n",
      "         0.4308, 0.5810, 0.6688, 0.3435, 0.5062, 0.3125, 0.3656, 0.6182, 0.5502,\n",
      "         0.4403, 0.4431, 0.4457, 0.5276, 0.6249, 0.4153, 0.4501, 0.5138, 0.5409,\n",
      "         0.6175, 0.3969, 0.4856, 0.2728, 0.5341, 0.5409],\n",
      "        [0.3734, 0.5629, 0.5336, 0.6031, 0.4553, 0.4683, 0.2837, 0.5124, 0.6737,\n",
      "         0.7548, 0.3653, 0.4747, 0.4598, 0.4718, 0.4848, 0.7149, 0.5805, 0.5104,\n",
      "         0.3946, 0.2545, 0.5194, 0.4141, 0.4837, 0.5586, 0.6257, 0.6562, 0.3921,\n",
      "         0.2946, 0.5061, 0.5257, 0.6517, 0.2617, 0.4059],\n",
      "        [0.3688, 0.4337, 0.5147, 0.5659, 0.4987, 0.4710, 0.5260, 0.5107, 0.5088,\n",
      "         0.4792, 0.5312, 0.5064, 0.4958, 0.5585, 0.5701, 0.4930, 0.3736, 0.6006,\n",
      "         0.5960, 0.6317, 0.4089, 0.6004, 0.3312, 0.4705, 0.5461, 0.5801, 0.4911,\n",
      "         0.5741, 0.4367, 0.5529, 0.5854, 0.4774, 0.4928],\n",
      "        [0.5085, 0.4378, 0.5548, 0.5487, 0.4824, 0.4551, 0.4844, 0.4453, 0.4923,\n",
      "         0.4061, 0.6016, 0.5134, 0.4301, 0.5518, 0.4062, 0.4990, 0.5120, 0.5440,\n",
      "         0.4735, 0.4069, 0.5140, 0.4637, 0.4061, 0.4520, 0.5198, 0.4183, 0.5599,\n",
      "         0.5417, 0.4526, 0.4536, 0.6281, 0.5132, 0.4665],\n",
      "        [0.6648, 0.5471, 0.4475, 0.4990, 0.4668, 0.6161, 0.5182, 0.5433, 0.4994,\n",
      "         0.4922, 0.4486, 0.5472, 0.4068, 0.4425, 0.4365, 0.5879, 0.5266, 0.4648,\n",
      "         0.4298, 0.5513, 0.6468, 0.4200, 0.4186, 0.5779, 0.5911, 0.4912, 0.6137,\n",
      "         0.3392, 0.5538, 0.4696, 0.8371, 0.6207, 0.3598],\n",
      "        [0.4176, 0.4683, 0.5363, 0.5261, 0.5286, 0.5718, 0.3945, 0.5150, 0.5659,\n",
      "         0.6264, 0.4453, 0.5037, 0.4358, 0.5069, 0.4966, 0.5730, 0.4703, 0.5502,\n",
      "         0.4493, 0.5454, 0.4960, 0.5193, 0.6774, 0.5101, 0.5635, 0.4788, 0.4529,\n",
      "         0.5509, 0.5523, 0.5303, 0.5688, 0.5103, 0.4867],\n",
      "        [0.4758, 0.4957, 0.4365, 0.5014, 0.5377, 0.5753, 0.4320, 0.4536, 0.5315,\n",
      "         0.5281, 0.4449, 0.4751, 0.5129, 0.4773, 0.4243, 0.5044, 0.5203, 0.4922,\n",
      "         0.4052, 0.5274, 0.4932, 0.4826, 0.7165, 0.4783, 0.4898, 0.4272, 0.4798,\n",
      "         0.4730, 0.5240, 0.4707, 0.4662, 0.5637, 0.4445],\n",
      "        [0.4708, 0.6355, 0.6219, 0.2912, 0.2576, 0.4223, 0.3547, 0.5668, 0.4682,\n",
      "         0.6179, 0.4732, 0.4430, 0.5974, 0.2472, 0.6681, 0.3246, 0.5776, 0.5837,\n",
      "         0.6157, 0.3369, 0.5663, 0.4766, 0.6743, 0.2922, 0.3591, 0.4124, 0.4283,\n",
      "         0.6119, 0.4734, 0.3208, 0.2239, 0.2365, 0.1871],\n",
      "        [0.3822, 0.3803, 0.5652, 0.5236, 0.4544, 0.4899, 0.4601, 0.4346, 0.6285,\n",
      "         0.5452, 0.4218, 0.5650, 0.3526, 0.4940, 0.3683, 0.5542, 0.5286, 0.4844,\n",
      "         0.4296, 0.3049, 0.4653, 0.4743, 0.3476, 0.4379, 0.4947, 0.5797, 0.5140,\n",
      "         0.4473, 0.3832, 0.4855, 0.5816, 0.2883, 0.4392],\n",
      "        [0.4152, 0.4375, 0.6027, 0.5530, 0.5069, 0.5702, 0.4118, 0.5710, 0.5809,\n",
      "         0.6523, 0.4523, 0.5149, 0.4132, 0.5349, 0.6002, 0.6294, 0.4224, 0.5516,\n",
      "         0.4866, 0.5885, 0.5519, 0.5704, 0.6089, 0.5015, 0.5908, 0.5443, 0.5058,\n",
      "         0.5596, 0.5651, 0.5670, 0.6681, 0.5068, 0.4941],\n",
      "        [0.4764, 0.6623, 0.4735, 0.3743, 0.6207, 0.6506, 0.4073, 0.4057, 0.6217,\n",
      "         0.4942, 0.4982, 0.5918, 0.4141, 0.5701, 0.2842, 0.4255, 0.5490, 0.5092,\n",
      "         0.4168, 0.3828, 0.4697, 0.6008, 0.7376, 0.4297, 0.4709, 0.4756, 0.5798,\n",
      "         0.5652, 0.4329, 0.4913, 0.3092, 0.5383, 0.4743],\n",
      "        [0.5305, 0.4119, 0.2483, 0.5359, 0.6683, 0.4852, 0.3452, 0.5687, 0.6593,\n",
      "         0.4883, 0.5984, 0.7159, 0.6459, 0.4661, 0.5596, 0.6250, 0.7276, 0.5190,\n",
      "         0.3211, 0.2937, 0.3836, 0.4606, 0.3372, 0.5622, 0.5026, 0.6362, 0.4409,\n",
      "         0.3203, 0.5256, 0.2498, 0.5984, 0.5084, 0.5374],\n",
      "        [0.4219, 0.3134, 0.5618, 0.4878, 0.4436, 0.5002, 0.5001, 0.4626, 0.5876,\n",
      "         0.4916, 0.4996, 0.5670, 0.3490, 0.4893, 0.3995, 0.4864, 0.5396, 0.4871,\n",
      "         0.4516, 0.3419, 0.4895, 0.4754, 0.3558, 0.4211, 0.4567, 0.4798, 0.5836,\n",
      "         0.5267, 0.4179, 0.4898, 0.5277, 0.3915, 0.4485],\n",
      "        [0.5989, 0.5502, 0.4662, 0.4841, 0.5071, 0.5517, 0.5610, 0.5706, 0.5070,\n",
      "         0.5013, 0.4844, 0.5339, 0.4217, 0.4663, 0.4477, 0.5083, 0.5430, 0.5277,\n",
      "         0.5124, 0.6203, 0.5507, 0.4234, 0.3063, 0.6044, 0.6178, 0.5481, 0.5550,\n",
      "         0.3470, 0.4511, 0.5469, 0.7608, 0.5922, 0.4029],\n",
      "        [0.5265, 0.4863, 0.5709, 0.5768, 0.4902, 0.4431, 0.4706, 0.4611, 0.4700,\n",
      "         0.4199, 0.6197, 0.4958, 0.4657, 0.5794, 0.4311, 0.5314, 0.5031, 0.5660,\n",
      "         0.4934, 0.4273, 0.5400, 0.4903, 0.3854, 0.4853, 0.5640, 0.4361, 0.5713,\n",
      "         0.5356, 0.4830, 0.4875, 0.6714, 0.5503, 0.4626],\n",
      "        [0.4323, 0.3726, 0.3708, 0.3710, 0.4923, 0.3467, 0.5058, 0.5253, 0.5098,\n",
      "         0.4516, 0.4291, 0.5331, 0.5958, 0.5504, 0.4605, 0.4113, 0.3377, 0.3750,\n",
      "         0.5704, 0.5577, 0.4912, 0.5542, 0.5733, 0.5316, 0.5063, 0.2517, 0.5605,\n",
      "         0.4009, 0.4424, 0.3824, 0.3608, 0.6521, 0.4452],\n",
      "        [0.5355, 0.5057, 0.4882, 0.5300, 0.5461, 0.4245, 0.5359, 0.5010, 0.4507,\n",
      "         0.4587, 0.5850, 0.4743, 0.5837, 0.5235, 0.4879, 0.4149, 0.5687, 0.5963,\n",
      "         0.5462, 0.6386, 0.4287, 0.4877, 0.3865, 0.5750, 0.5507, 0.5238, 0.4880,\n",
      "         0.4871, 0.4579, 0.5823, 0.4736, 0.5957, 0.4894],\n",
      "        [0.5165, 0.5941, 0.3509, 0.4671, 0.4711, 0.5473, 0.4359, 0.4096, 0.4505,\n",
      "         0.5073, 0.3981, 0.3338, 0.6658, 0.4988, 0.5360, 0.4251, 0.4432, 0.4191,\n",
      "         0.4788, 0.6095, 0.5675, 0.5659, 0.7111, 0.5135, 0.5669, 0.3454, 0.5409,\n",
      "         0.2845, 0.5052, 0.4138, 0.3788, 0.6694, 0.3822],\n",
      "        [0.4549, 0.4787, 0.4927, 0.4956, 0.5197, 0.4712, 0.4579, 0.4964, 0.5189,\n",
      "         0.5131, 0.5310, 0.4822, 0.4437, 0.4957, 0.4324, 0.4498, 0.5361, 0.5665,\n",
      "         0.4731, 0.5284, 0.4232, 0.4467, 0.5038, 0.5278, 0.5174, 0.4581, 0.4412,\n",
      "         0.5037, 0.4637, 0.5281, 0.4769, 0.5040, 0.4942],\n",
      "        [0.4095, 0.3809, 0.5026, 0.5890, 0.4883, 0.5403, 0.4990, 0.5020, 0.5382,\n",
      "         0.5680, 0.4307, 0.5460, 0.5540, 0.5208, 0.6116, 0.5447, 0.3429, 0.5267,\n",
      "         0.5537, 0.6313, 0.4904, 0.6291, 0.6501, 0.3896, 0.5280, 0.5377, 0.5162,\n",
      "         0.6455, 0.5166, 0.4980, 0.6121, 0.5448, 0.4601],\n",
      "        [0.4341, 0.3911, 0.4972, 0.5720, 0.4911, 0.4686, 0.5331, 0.4838, 0.4775,\n",
      "         0.4662, 0.5073, 0.5274, 0.5583, 0.5147, 0.5623, 0.4639, 0.3743, 0.5745,\n",
      "         0.5749, 0.6525, 0.4247, 0.5813, 0.4668, 0.4388, 0.5058, 0.5483, 0.5075,\n",
      "         0.6262, 0.4532, 0.4915, 0.5678, 0.5168, 0.4796],\n",
      "        [0.4106, 0.4315, 0.5400, 0.5209, 0.5123, 0.5998, 0.4752, 0.5867, 0.6005,\n",
      "         0.6524, 0.4264, 0.5358, 0.3790, 0.4992, 0.6120, 0.5778, 0.4194, 0.5209,\n",
      "         0.5098, 0.6322, 0.5402, 0.5532, 0.5237, 0.4808, 0.5857, 0.5790, 0.5026,\n",
      "         0.5027, 0.5073, 0.5744, 0.6906, 0.5038, 0.4653],\n",
      "        [0.5548, 0.3592, 0.5033, 0.4676, 0.4493, 0.4064, 0.5165, 0.4607, 0.5582,\n",
      "         0.5017, 0.6056, 0.5760, 0.4155, 0.4240, 0.5449, 0.3802, 0.6333, 0.5328,\n",
      "         0.4416, 0.4151, 0.4986, 0.5268, 0.2583, 0.4363, 0.5202, 0.5350, 0.5697,\n",
      "         0.5464, 0.4288, 0.4689, 0.4978, 0.4454, 0.4774],\n",
      "        [0.4928, 0.4708, 0.3926, 0.4829, 0.5335, 0.5299, 0.4829, 0.4640, 0.5447,\n",
      "         0.5423, 0.3891, 0.5205, 0.6894, 0.5448, 0.5231, 0.4975, 0.3901, 0.4034,\n",
      "         0.4994, 0.6190, 0.5746, 0.5720, 0.7916, 0.4816, 0.5318, 0.3650, 0.5729,\n",
      "         0.4541, 0.5178, 0.4238, 0.4870, 0.7153, 0.3846],\n",
      "        [0.4464, 0.5154, 0.5752, 0.5495, 0.5151, 0.4369, 0.4244, 0.5326, 0.5036,\n",
      "         0.5475, 0.5561, 0.4851, 0.4590, 0.5579, 0.4652, 0.5399, 0.4970, 0.6072,\n",
      "         0.5242, 0.5194, 0.4695, 0.5072, 0.4380, 0.5671, 0.6067, 0.4919, 0.4772,\n",
      "         0.5417, 0.4916, 0.5829, 0.5980, 0.5218, 0.4831],\n",
      "        [0.4155, 0.3030, 0.4395, 0.3120, 0.5038, 0.3790, 0.5121, 0.5719, 0.4863,\n",
      "         0.4723, 0.4447, 0.4730, 0.5167, 0.5713, 0.4171, 0.3526, 0.2518, 0.3850,\n",
      "         0.5980, 0.5434, 0.5069, 0.5431, 0.5765, 0.5355, 0.4444, 0.2005, 0.5709,\n",
      "         0.3679, 0.4201, 0.3952, 0.3367, 0.5774, 0.5336],\n",
      "        [0.4532, 0.4614, 0.5523, 0.5420, 0.5364, 0.3917, 0.5329, 0.5066, 0.4538,\n",
      "         0.4400, 0.5876, 0.5134, 0.5062, 0.5429, 0.4908, 0.4514, 0.5053, 0.6177,\n",
      "         0.5880, 0.6384, 0.3709, 0.5279, 0.2798, 0.5538, 0.5712, 0.5642, 0.4786,\n",
      "         0.5653, 0.3929, 0.5915, 0.5265, 0.5106, 0.5112],\n",
      "        [0.4897, 0.2530, 0.4947, 0.2899, 0.6321, 0.6024, 0.5698, 0.6726, 0.4085,\n",
      "         0.5708, 0.4282, 0.2320, 0.4974, 0.5630, 0.4485, 0.2981, 0.2459, 0.3752,\n",
      "         0.5607, 0.6439, 0.5915, 0.6087, 0.6604, 0.5860, 0.3732, 0.2598, 0.6417,\n",
      "         0.1389, 0.4766, 0.5138, 0.2842, 0.5771, 0.6961]], device='cuda:0')\n",
      "indices = <built-in method indices of Tensor object at 0x000002E69B283380>\n",
      "pred = tensor([[0.4100, 0.3845, 0.4972, 0.5758, 0.4819, 0.4652, 0.5236, 0.4999, 0.4949,\n",
      "         0.4916, 0.4938, 0.5389, 0.5383, 0.5144, 0.5822, 0.4941, 0.3734, 0.5639,\n",
      "         0.5721, 0.6426, 0.4250, 0.5987, 0.4698, 0.4350, 0.5235, 0.5555, 0.5029,\n",
      "         0.6328, 0.4657, 0.5001, 0.5760, 0.5136, 0.4788],\n",
      "        [0.3972, 0.4636, 0.4430, 0.4902, 0.4143, 0.6357, 0.3874, 0.6621, 0.4472,\n",
      "         0.4442, 0.5687, 0.5024, 0.5509, 0.3608, 0.6107, 0.5522, 0.7323, 0.5372,\n",
      "         0.4906, 0.3124, 0.3956, 0.4018, 0.2427, 0.4386, 0.4824, 0.4392, 0.4288,\n",
      "         0.5767, 0.4899, 0.3779, 0.3835, 0.3418, 0.5017],\n",
      "        [0.4989, 0.6439, 0.3410, 0.5313, 0.4529, 0.6178, 0.4626, 0.3262, 0.4357,\n",
      "         0.4263, 0.5166, 0.2519, 0.5770, 0.4607, 0.5723, 0.3503, 0.5448, 0.4941,\n",
      "         0.4961, 0.5773, 0.4742, 0.5521, 0.5715, 0.4372, 0.5392, 0.4126, 0.4911,\n",
      "         0.3047, 0.4540, 0.4540, 0.3174, 0.5488, 0.3662],\n",
      "        [0.5091, 0.4579, 0.4955, 0.5085, 0.5147, 0.7060, 0.5162, 0.6417, 0.6349,\n",
      "         0.6959, 0.3822, 0.5875, 0.3566, 0.4669, 0.6272, 0.6309, 0.4565, 0.4588,\n",
      "         0.5013, 0.6640, 0.6426, 0.5260, 0.5557, 0.5128, 0.6093, 0.6000, 0.5706,\n",
      "         0.4200, 0.5629, 0.5901, 0.8059, 0.5688, 0.4153],\n",
      "        [0.4696, 0.4400, 0.4677, 0.5356, 0.5301, 0.5861, 0.4733, 0.4648, 0.5362,\n",
      "         0.5698, 0.4023, 0.5014, 0.5932, 0.4966, 0.5190, 0.5110, 0.4395, 0.5072,\n",
      "         0.4692, 0.6117, 0.5263, 0.5405, 0.7586, 0.4469, 0.5319, 0.4751, 0.4933,\n",
      "         0.5341, 0.5314, 0.4636, 0.5585, 0.6151, 0.4267],\n",
      "        [0.5075, 0.4403, 0.4296, 0.5421, 0.5301, 0.5517, 0.5175, 0.4486, 0.5124,\n",
      "         0.5150, 0.4276, 0.5077, 0.6667, 0.4976, 0.5259, 0.4637, 0.4505, 0.4990,\n",
      "         0.5006, 0.6367, 0.5197, 0.5360, 0.7285, 0.4438, 0.5184, 0.4708, 0.5153,\n",
      "         0.5290, 0.5143, 0.4531, 0.5290, 0.6632, 0.3962],\n",
      "        [0.4568, 0.5014, 0.4085, 0.4877, 0.5620, 0.5729, 0.4686, 0.4534, 0.5876,\n",
      "         0.4895, 0.5215, 0.4923, 0.4550, 0.4975, 0.4144, 0.4697, 0.5757, 0.4801,\n",
      "         0.4334, 0.4913, 0.4392, 0.4699, 0.6142, 0.4718, 0.4398, 0.4251, 0.5006,\n",
      "         0.4662, 0.4680, 0.5055, 0.3849, 0.5122, 0.4588],\n",
      "        [0.3554, 0.3937, 0.4742, 0.5281, 0.4767, 0.7007, 0.4691, 0.5590, 0.5980,\n",
      "         0.6611, 0.3546, 0.5027, 0.3195, 0.4707, 0.6559, 0.5570, 0.3052, 0.4842,\n",
      "         0.5006, 0.6321, 0.5267, 0.5951, 0.5557, 0.3773, 0.5220, 0.5814, 0.4876,\n",
      "         0.4655, 0.5064, 0.5391, 0.6938, 0.4247, 0.4993],\n",
      "        [0.4014, 0.4726, 0.4232, 0.5098, 0.5041, 0.6347, 0.5790, 0.4977, 0.5216,\n",
      "         0.4511, 0.4758, 0.4870, 0.3854, 0.5153, 0.5143, 0.4269, 0.3183, 0.5585,\n",
      "         0.5916, 0.6532, 0.4091, 0.5257, 0.2266, 0.4617, 0.4710, 0.5980, 0.4844,\n",
      "         0.3862, 0.3760, 0.5667, 0.6459, 0.4239, 0.4676],\n",
      "        [0.5238, 0.4894, 0.3782, 0.4965, 0.5313, 0.4697, 0.5209, 0.4502, 0.4318,\n",
      "         0.4389, 0.5364, 0.3797, 0.5635, 0.4858, 0.4733, 0.3451, 0.5597, 0.5318,\n",
      "         0.4933, 0.5783, 0.3938, 0.4782, 0.4146, 0.5291, 0.4996, 0.4630, 0.4474,\n",
      "         0.3586, 0.4612, 0.5448, 0.3911, 0.6016, 0.4974],\n",
      "        [0.5255, 0.5086, 0.5427, 0.5346, 0.4780, 0.4539, 0.4644, 0.5046, 0.4705,\n",
      "         0.4623, 0.5456, 0.4811, 0.4537, 0.5213, 0.4540, 0.5284, 0.4934, 0.5725,\n",
      "         0.4819, 0.5144, 0.5226, 0.4762, 0.3828, 0.5385, 0.5852, 0.4771, 0.5327,\n",
      "         0.4731, 0.4816, 0.4902, 0.6744, 0.5434, 0.4535],\n",
      "        [0.5049, 0.6099, 0.3423, 0.5136, 0.4775, 0.5686, 0.4353, 0.3687, 0.4292,\n",
      "         0.4664, 0.4464, 0.3070, 0.6166, 0.4757, 0.4961, 0.3984, 0.5015, 0.4827,\n",
      "         0.4428, 0.5699, 0.4814, 0.5206, 0.6102, 0.4839, 0.5296, 0.4059, 0.4812,\n",
      "         0.3156, 0.4891, 0.4491, 0.3961, 0.6060, 0.3928],\n",
      "        [0.6279, 0.5746, 0.4897, 0.5226, 0.4926, 0.5396, 0.5246, 0.5589, 0.4976,\n",
      "         0.4924, 0.5224, 0.5254, 0.4510, 0.5026, 0.4469, 0.5614, 0.5401, 0.5370,\n",
      "         0.4975, 0.5546, 0.6068, 0.4404, 0.3468, 0.6034, 0.6270, 0.5116, 0.5906,\n",
      "         0.3717, 0.5161, 0.5340, 0.7937, 0.6199, 0.3913],\n",
      "        [0.4431, 0.4134, 0.5312, 0.4972, 0.5062, 0.4844, 0.4793, 0.4824, 0.5661,\n",
      "         0.4877, 0.5678, 0.5303, 0.3840, 0.5258, 0.3980, 0.4597, 0.5477, 0.5374,\n",
      "         0.4811, 0.4230, 0.4532, 0.4323, 0.4684, 0.4754, 0.4880, 0.4303, 0.4922,\n",
      "         0.5368, 0.4388, 0.5182, 0.5091, 0.4694, 0.4855],\n",
      "        [0.4754, 0.3703, 0.4809, 0.5151, 0.5009, 0.3797, 0.5693, 0.4992, 0.4941,\n",
      "         0.4012, 0.5236, 0.6143, 0.6143, 0.5286, 0.4822, 0.4451, 0.4202, 0.5442,\n",
      "         0.6061, 0.6372, 0.4354, 0.5327, 0.4958, 0.4966, 0.5136, 0.4524, 0.5356,\n",
      "         0.6295, 0.4325, 0.4416, 0.4973, 0.5836, 0.4464],\n",
      "        [0.5546, 0.5436, 0.3235, 0.4186, 0.5772, 0.4126, 0.4138, 0.4535, 0.5352,\n",
      "         0.5186, 0.6116, 0.5621, 0.5073, 0.5181, 0.4693, 0.3589, 0.6231, 0.4859,\n",
      "         0.3774, 0.3439, 0.3892, 0.6215, 0.3365, 0.5389, 0.5111, 0.4727, 0.5672,\n",
      "         0.5447, 0.4962, 0.5185, 0.4061, 0.5951, 0.5505],\n",
      "        [0.5028, 0.6710, 0.3263, 0.5130, 0.4444, 0.5803, 0.4342, 0.3527, 0.4084,\n",
      "         0.4688, 0.4552, 0.2196, 0.6363, 0.4827, 0.5487, 0.3679, 0.4963, 0.4807,\n",
      "         0.4848, 0.5788, 0.5032, 0.5606, 0.5967, 0.4882, 0.5636, 0.3897, 0.4863,\n",
      "         0.2429, 0.4851, 0.4645, 0.3397, 0.6074, 0.3649],\n",
      "        [0.4954, 0.6658, 0.3412, 0.5321, 0.4364, 0.6235, 0.4435, 0.3098, 0.4290,\n",
      "         0.4268, 0.4949, 0.2437, 0.5874, 0.4538, 0.5677, 0.3592, 0.5301, 0.4884,\n",
      "         0.4820, 0.5771, 0.4920, 0.5521, 0.6058, 0.4291, 0.5454, 0.4005, 0.4964,\n",
      "         0.3040, 0.4511, 0.4245, 0.3241, 0.5453, 0.3435],\n",
      "        [0.5017, 0.5057, 0.4825, 0.4968, 0.5469, 0.8383, 0.5053, 0.4966, 0.4781,\n",
      "         0.5683, 0.4085, 0.3532, 0.3275, 0.4804, 0.5029, 0.3651, 0.2352, 0.5511,\n",
      "         0.5210, 0.6746, 0.5585, 0.4610, 0.4637, 0.3998, 0.3540, 0.5759, 0.5107,\n",
      "         0.2657, 0.4087, 0.6051, 0.7075, 0.3724, 0.5491],\n",
      "        [0.4607, 0.4804, 0.5661, 0.5382, 0.5138, 0.4485, 0.4461, 0.5089, 0.5226,\n",
      "         0.5040, 0.5830, 0.5092, 0.4357, 0.5601, 0.4298, 0.5174, 0.5182, 0.5808,\n",
      "         0.5115, 0.4698, 0.4735, 0.4752, 0.4580, 0.5278, 0.5630, 0.4509, 0.4931,\n",
      "         0.5536, 0.4748, 0.5494, 0.5841, 0.5168, 0.4810],\n",
      "        [0.4604, 0.5083, 0.5885, 0.5526, 0.5392, 0.4184, 0.4660, 0.5307, 0.5035,\n",
      "         0.5118, 0.6068, 0.5152, 0.4708, 0.5815, 0.4641, 0.5236, 0.5266, 0.6144,\n",
      "         0.5664, 0.5354, 0.4486, 0.5093, 0.3700, 0.5781, 0.6074, 0.5129, 0.4859,\n",
      "         0.5636, 0.4668, 0.6271, 0.5838, 0.5364, 0.4884],\n",
      "        [0.4418, 0.3612, 0.4891, 0.3845, 0.5213, 0.4101, 0.4905, 0.5403, 0.5559,\n",
      "         0.5014, 0.4393, 0.5913, 0.5739, 0.5993, 0.4436, 0.4415, 0.2605, 0.4145,\n",
      "         0.6024, 0.5672, 0.5685, 0.5500, 0.7074, 0.5041, 0.4764, 0.2367, 0.5934,\n",
      "         0.5179, 0.4434, 0.3942, 0.4451, 0.6038, 0.4654],\n",
      "        [0.4845, 0.7177, 0.3464, 0.5433, 0.4351, 0.6841, 0.4021, 0.2988, 0.4589,\n",
      "         0.4826, 0.4435, 0.2405, 0.6096, 0.4670, 0.5650, 0.4279, 0.5017, 0.4650,\n",
      "         0.4491, 0.5686, 0.5503, 0.5760, 0.7392, 0.4250, 0.5627, 0.3844, 0.5183,\n",
      "         0.3038, 0.4889, 0.4108, 0.3578, 0.5617, 0.3163],\n",
      "        [0.4755, 0.4378, 0.5408, 0.5152, 0.5270, 0.4341, 0.5033, 0.4744, 0.5072,\n",
      "         0.4282, 0.6184, 0.5290, 0.4238, 0.5387, 0.4165, 0.4466, 0.5521, 0.5656,\n",
      "         0.5155, 0.4880, 0.4267, 0.4509, 0.3831, 0.4960, 0.5205, 0.4558, 0.4918,\n",
      "         0.5556, 0.4128, 0.5283, 0.5293, 0.5036, 0.4999],\n",
      "        [0.4349, 0.3297, 0.5304, 0.4742, 0.4550, 0.4991, 0.4806, 0.4770, 0.5821,\n",
      "         0.4952, 0.4962, 0.5562, 0.3515, 0.4524, 0.4123, 0.4757, 0.5563, 0.4846,\n",
      "         0.4219, 0.3854, 0.4781, 0.4511, 0.4266, 0.4315, 0.4415, 0.4687, 0.5570,\n",
      "         0.5148, 0.4291, 0.4644, 0.4819, 0.4023, 0.4554],\n",
      "        [0.4358, 0.2746, 0.3899, 0.2913, 0.5562, 0.4448, 0.5876, 0.6327, 0.4192,\n",
      "         0.4523, 0.4599, 0.3350, 0.5306, 0.5570, 0.4437, 0.2949, 0.2846, 0.3722,\n",
      "         0.6037, 0.5956, 0.4941, 0.5789, 0.4893, 0.5931, 0.4314, 0.2348, 0.6128,\n",
      "         0.1819, 0.4524, 0.4448, 0.2468, 0.6025, 0.6122],\n",
      "        [0.5221, 0.4473, 0.5673, 0.5811, 0.4567, 0.4760, 0.5043, 0.3969, 0.4598,\n",
      "         0.3647, 0.5695, 0.5066, 0.4317, 0.5711, 0.3803, 0.5467, 0.4769, 0.4993,\n",
      "         0.4604, 0.3666, 0.5324, 0.5217, 0.2977, 0.4303, 0.4930, 0.4525, 0.6445,\n",
      "         0.5318, 0.4561, 0.4592, 0.6778, 0.4882, 0.4398],\n",
      "        [0.5383, 0.4660, 0.6339, 0.4983, 0.5745, 0.4257, 0.5216, 0.5174, 0.4392,\n",
      "         0.4395, 0.6081, 0.4887, 0.5225, 0.6246, 0.4452, 0.3711, 0.2742, 0.6476,\n",
      "         0.6177, 0.6522, 0.5430, 0.5114, 0.4282, 0.5231, 0.4149, 0.4155, 0.5887,\n",
      "         0.5328, 0.4150, 0.5272, 0.5599, 0.4499, 0.5910],\n",
      "        [0.6393, 0.4734, 0.7390, 0.4724, 0.6756, 0.5711, 0.5052, 0.5633, 0.5119,\n",
      "         0.5808, 0.5587, 0.5209, 0.5772, 0.6792, 0.4574, 0.4281, 0.2300, 0.6220,\n",
      "         0.5968, 0.7187, 0.7513, 0.5503, 0.8084, 0.5242, 0.4123, 0.3203, 0.7086,\n",
      "         0.5682, 0.4794, 0.5010, 0.6361, 0.4974, 0.6292],\n",
      "        [0.4698, 0.4636, 0.5193, 0.5018, 0.5405, 0.4202, 0.5056, 0.4983, 0.4906,\n",
      "         0.4626, 0.5986, 0.5080, 0.4542, 0.5151, 0.4487, 0.4224, 0.5642, 0.5868,\n",
      "         0.5288, 0.5667, 0.3893, 0.4589, 0.3623, 0.5450, 0.5349, 0.5024, 0.4513,\n",
      "         0.5306, 0.4185, 0.5767, 0.4732, 0.5127, 0.5122]], device='cuda:0')\n",
      "indices = <built-in method indices of Tensor object at 0x000002E69B281260>\n",
      "pred = tensor([[0.5380, 0.4975, 0.3366, 0.4651, 0.5382, 0.4438, 0.5216, 0.4765, 0.4195,\n",
      "         0.4488, 0.5191, 0.3414, 0.5967, 0.5069, 0.4930, 0.3329, 0.5436, 0.4959,\n",
      "         0.5132, 0.5914, 0.4084, 0.5043, 0.3984, 0.5728, 0.5127, 0.4291, 0.4635,\n",
      "         0.2690, 0.4779, 0.5570, 0.3475, 0.6523, 0.5169],\n",
      "        [0.4742, 0.4581, 0.5461, 0.5347, 0.4894, 0.4710, 0.4423, 0.4772, 0.5217,\n",
      "         0.4710, 0.5638, 0.5079, 0.4154, 0.5386, 0.4096, 0.5176, 0.5037, 0.5526,\n",
      "         0.4632, 0.4283, 0.4937, 0.4550, 0.5058, 0.4814, 0.5224, 0.4106, 0.5105,\n",
      "         0.5478, 0.4822, 0.4727, 0.5927, 0.5014, 0.4687],\n",
      "        [0.4250, 0.4756, 0.5813, 0.5435, 0.5468, 0.4154, 0.4965, 0.5430, 0.5044,\n",
      "         0.5254, 0.5660, 0.5109, 0.4818, 0.5555, 0.4987, 0.4905, 0.4998, 0.6219,\n",
      "         0.5765, 0.6153, 0.4123, 0.5316, 0.3665, 0.5536, 0.5915, 0.5574, 0.4785,\n",
      "         0.5772, 0.4154, 0.6104, 0.5549, 0.5027, 0.5058],\n",
      "        [0.5515, 0.4833, 0.6557, 0.5272, 0.5830, 0.5874, 0.4555, 0.4857, 0.4422,\n",
      "         0.5518, 0.5139, 0.3974, 0.4976, 0.5943, 0.4998, 0.3881, 0.2203, 0.6233,\n",
      "         0.5398, 0.6581, 0.6235, 0.5360, 0.6384, 0.4339, 0.3919, 0.4295, 0.5847,\n",
      "         0.5014, 0.4563, 0.5243, 0.6321, 0.4257, 0.6078],\n",
      "        [0.5289, 0.5034, 0.5801, 0.5855, 0.4961, 0.4442, 0.4651, 0.4744, 0.4744,\n",
      "         0.4391, 0.6249, 0.4940, 0.4766, 0.5927, 0.4419, 0.5476, 0.5042, 0.5759,\n",
      "         0.5048, 0.4333, 0.5509, 0.5011, 0.3866, 0.5024, 0.5813, 0.4459, 0.5743,\n",
      "         0.5362, 0.4987, 0.5111, 0.6836, 0.5620, 0.4619],\n",
      "        [0.2439, 0.7485, 0.4851, 0.3586, 0.3721, 0.5782, 0.3246, 0.5232, 0.5176,\n",
      "         0.6299, 0.3738, 0.3434, 0.6627, 0.4170, 0.5370, 0.4381, 0.5397, 0.5611,\n",
      "         0.5999, 0.2522, 0.4568, 0.5345, 0.7129, 0.3525, 0.4734, 0.3877, 0.4320,\n",
      "         0.5589, 0.4375, 0.3812, 0.2744, 0.2489, 0.2226],\n",
      "        [0.4716, 0.5098, 0.5413, 0.5316, 0.5443, 0.4501, 0.4813, 0.5428, 0.5195,\n",
      "         0.5449, 0.5671, 0.4951, 0.4941, 0.5446, 0.4774, 0.4886, 0.5416, 0.6071,\n",
      "         0.5375, 0.5841, 0.4403, 0.4916, 0.4529, 0.5812, 0.5649, 0.5188, 0.4682,\n",
      "         0.5327, 0.4835, 0.6157, 0.5153, 0.5376, 0.4991],\n",
      "        [0.6186, 0.6577, 0.4169, 0.5130, 0.4624, 0.6883, 0.4653, 0.3077, 0.3327,\n",
      "         0.3406, 0.5536, 0.2894, 0.5780, 0.3995, 0.5845, 0.3128, 0.5492, 0.5521,\n",
      "         0.4615, 0.6613, 0.5675, 0.5262, 0.6535, 0.3663, 0.5671, 0.4700, 0.5416,\n",
      "         0.3004, 0.4599, 0.2969, 0.2933, 0.6051, 0.3968],\n",
      "        [0.4294, 0.4587, 0.5531, 0.5559, 0.5337, 0.4128, 0.5275, 0.5274, 0.4934,\n",
      "         0.4825, 0.5741, 0.5213, 0.5185, 0.5618, 0.5031, 0.4778, 0.4775, 0.6218,\n",
      "         0.5970, 0.6263, 0.3954, 0.5484, 0.3522, 0.5371, 0.5649, 0.5570, 0.4878,\n",
      "         0.5921, 0.4173, 0.5943, 0.5418, 0.5092, 0.4990],\n",
      "        [0.4420, 0.3850, 0.4952, 0.4653, 0.5057, 0.4848, 0.4889, 0.4768, 0.5654,\n",
      "         0.4739, 0.5456, 0.5356, 0.3654, 0.4667, 0.4044, 0.4215, 0.5725, 0.5157,\n",
      "         0.4519, 0.4582, 0.4147, 0.4153, 0.4662, 0.4642, 0.4451, 0.4439, 0.4786,\n",
      "         0.5241, 0.4130, 0.4888, 0.4341, 0.4406, 0.4941]], device='cuda:0')\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(test_loader, model, criterion)\n",
    "\n",
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
