{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Facial Recognition using PyTorch and OpenCV\n",
    "\n",
    "https://ritik12.medium.com/facial-recognition-using-pytorch-and-opencv-467c4e41d1f\n",
    "\n",
    "\n",
    "Machine Learning - Face Recognition CNN Pytorch.ipynb\n",
    "https://github.com/rubencg195/Pytorch-Tutorials/blob/master/Machine%20Learning%20-%20Face%20Recognition%20CNN%20Pytorch.ipynb\n",
    "\n",
    "\n",
    "\n",
    "Face Recognition Using Pytorch\n",
    "https://github.com/timesler/facenet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Landmarks Detection With PyTorch\n",
    "\n",
    "https://towardsdatascience.com/face-landmarks-detection-with-pytorch-4b4852f5e9c4\n",
    "\n",
    "\n",
    "\n",
    "다중입력 deep neural network\n",
    "https://rosenfelder.ai/multi-input-neural-network-pytorch/\n",
    "\n",
    "\n",
    "\n",
    "Understanding dimensions in PyTorch\n",
    "https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.init import *\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from FaceFeatureDataset import FaceFeatureDataset\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 68])\n",
      "output_2d tensor([[[-6.1806e-01, -7.7384e-02,  1.9195e-01, -1.0017e+00,  1.2797e-01,\n",
      "          -7.1703e-02,  1.4624e-01, -7.8517e-01, -5.6697e-01, -1.0013e-01,\n",
      "           4.2946e-01, -2.2345e-01,  1.2505e-01, -4.7891e-01,  6.8265e-02,\n",
      "          -8.6848e-02,  2.4225e-01,  1.6318e-01,  1.7623e-01,  5.0248e-02,\n",
      "          -5.3683e-02,  4.1974e-02, -1.2864e-01, -5.5282e-01, -4.7931e-01,\n",
      "           2.7521e-01, -2.0208e-01,  6.2883e-01,  9.1397e-02, -1.9679e-01,\n",
      "          -2.5712e-01,  4.7575e-01,  1.7274e-02,  5.8329e-01,  7.9755e-01,\n",
      "          -1.6319e-02,  4.3476e-01, -5.5405e-01, -2.6931e-01, -5.3151e-01,\n",
      "          -3.2860e-01,  1.3785e-01, -5.0351e-02,  1.0057e+00,  1.7901e-01,\n",
      "          -7.3359e-01,  8.3160e-02,  3.9779e-01,  5.1801e-01,  6.9527e-02,\n",
      "          -3.0596e-01,  6.8492e-01, -6.4788e-04,  6.8850e-01, -3.3462e-02,\n",
      "           5.4772e-01, -1.8067e-01, -5.5819e-03,  2.5021e-01, -4.6806e-01,\n",
      "           5.4527e-01,  8.3101e-02, -2.0863e-01,  3.0555e-01,  7.7920e-01,\n",
      "           2.7790e-01, -2.1536e-01,  3.4354e-01,  6.8382e-01, -2.3120e-01,\n",
      "          -1.6217e+00,  2.3618e-01,  1.2840e+00,  8.2806e-01,  6.9598e-02,\n",
      "           2.5019e-01, -7.0343e-01,  8.2466e-02,  4.8755e-01,  3.2453e-01,\n",
      "           4.7596e-01, -4.9874e-01, -6.7266e-01, -1.8020e-01, -3.8798e-01,\n",
      "          -1.3076e-01,  2.2330e-01,  4.4435e-01,  7.2817e-01,  5.6881e-01,\n",
      "           5.3863e-01,  2.4692e-01, -6.5557e-01, -4.0383e-01,  5.4775e-01,\n",
      "           6.5357e-01, -6.3641e-01,  7.1686e-01,  3.1389e-01, -2.0080e-01,\n",
      "           4.4027e-01, -8.1040e-01, -1.3485e+00, -9.2089e-02,  5.3795e-01,\n",
      "          -2.2045e-01, -8.3188e-01,  5.9960e-01, -3.7787e-01,  2.3361e-01,\n",
      "          -3.0426e-01, -5.8539e-01,  3.7092e-02,  6.1313e-01,  1.5560e-01,\n",
      "          -5.5545e-01,  4.1401e-01, -5.6934e-02,  4.1248e-01,  4.3112e-01,\n",
      "           1.0216e-01,  5.9390e-01,  9.4471e-02,  4.3177e-02, -1.2876e-02,\n",
      "           3.1257e-01, -3.3716e-01,  5.0298e-01],\n",
      "         [ 3.3209e-01,  4.2837e-01,  7.5602e-02, -2.4726e-01, -2.5332e-01,\n",
      "           1.0183e+00, -5.0200e-01, -4.6397e-01,  1.9737e-01, -7.5734e-01,\n",
      "          -6.6301e-01, -8.4215e-01,  5.9852e-01, -7.7787e-01, -8.4204e-03,\n",
      "          -6.1795e-01, -1.0742e-01, -7.9611e-01,  9.9524e-01,  6.6226e-01,\n",
      "          -3.0267e-01,  5.6134e-01,  9.1669e-02,  6.2516e-01,  2.7055e-01,\n",
      "          -1.5138e-01, -4.6572e-02,  5.2293e-01, -8.6047e-01, -1.2661e-01,\n",
      "          -6.0470e-01, -4.1004e-01, -6.2183e-02, -4.2132e-02,  9.9329e-01,\n",
      "          -8.1870e-01, -2.7844e-01, -2.1964e-01,  7.0412e-02, -6.4646e-01,\n",
      "          -4.7435e-02,  7.4809e-01,  1.8301e-01, -6.4641e-01, -4.2429e-02,\n",
      "          -1.6621e-02, -5.3932e-02, -2.3982e-01,  7.8657e-01,  3.5989e-01,\n",
      "           2.6368e-01, -5.2122e-01,  4.5509e-01,  6.7978e-01, -7.1328e-01,\n",
      "           2.3532e-01,  4.6889e-01,  7.0667e-02,  6.3632e-01, -6.2796e-01,\n",
      "          -3.1325e-01, -1.1879e+00, -5.5054e-02,  7.4709e-02,  3.3739e-01,\n",
      "          -5.5252e-01,  6.0573e-01,  3.9009e-01,  9.4625e-01, -1.1474e+00,\n",
      "          -2.9282e-01,  6.4248e-01,  4.9674e-01,  5.8510e-01,  6.9527e-01,\n",
      "           5.0039e-01, -3.7998e-01, -4.3785e-01, -4.3501e-01, -7.4740e-01,\n",
      "          -1.8461e-01, -2.5899e-01,  8.4771e-01,  9.6423e-03, -9.9331e-01,\n",
      "           2.3834e-01,  1.3591e+00, -5.4365e-01, -9.9832e-01, -1.0859e+00,\n",
      "          -1.6008e-01,  6.4593e-02, -2.7496e-01, -5.2515e-01,  4.9985e-01,\n",
      "           1.1345e+00,  3.4003e-01,  1.6698e-02,  1.2701e+00,  1.6369e-01,\n",
      "           4.5576e-01, -7.1660e-01,  6.0121e-01, -4.6397e-01, -9.1463e-01,\n",
      "           9.9705e-01,  4.8013e-01,  9.9092e-02, -5.3806e-02, -2.8687e-01,\n",
      "          -6.0165e-01, -2.0445e-01,  1.1585e-01, -7.5596e-01,  3.6054e-01,\n",
      "          -1.3733e-01,  5.4306e-01, -4.3116e-01, -2.2358e-01,  7.4724e-02,\n",
      "          -4.4389e-01, -5.0056e-01, -4.2640e-01, -3.9031e-01, -3.8388e-01,\n",
      "          -4.9267e-03,  1.8273e-01, -1.6363e-01]],\n",
      "\n",
      "        [[-6.7036e-02, -1.4520e-01,  4.3913e-01,  8.1765e-02,  6.7593e-01,\n",
      "           3.1861e-01, -6.9204e-02,  6.8011e-01,  5.0560e-01,  1.8207e-01,\n",
      "          -2.4043e-01, -7.4134e-01, -6.8328e-01, -5.9601e-01,  6.5352e-01,\n",
      "          -5.9757e-01, -6.5330e-01,  2.9280e-01,  3.1960e-01, -1.1957e+00,\n",
      "          -1.3720e-01, -4.3938e-02,  4.8383e-01, -4.8885e-01, -3.1736e-01,\n",
      "           4.4335e-01,  4.1858e-01,  5.0567e-01,  6.1573e-01,  5.4241e-01,\n",
      "          -1.2960e-01, -9.7385e-01,  3.2900e-01,  8.4303e-01, -5.5762e-01,\n",
      "           5.9207e-01,  1.6122e-01,  6.2236e-01, -1.9113e-02,  3.7603e-01,\n",
      "          -5.6870e-01, -8.1643e-01, -2.0814e-02, -4.3913e-01,  4.1399e-01,\n",
      "           1.2807e+00,  8.0767e-01,  9.1468e-01,  4.1164e-01,  7.8331e-01,\n",
      "           2.2376e-01, -2.6894e-01,  2.9036e-01, -1.4071e-01, -1.1067e-01,\n",
      "          -2.4410e-01,  4.3225e-01,  7.2487e-01, -3.9483e-01,  7.0117e-01,\n",
      "          -8.2130e-01, -4.1779e-01,  2.3972e-01, -9.5018e-01,  2.2859e-01,\n",
      "          -3.3274e-02,  5.5569e-01,  5.7477e-01,  1.0123e+00, -1.2746e-02,\n",
      "          -1.0480e-01,  2.6394e-02,  1.6796e-01,  2.2928e-01,  5.3928e-01,\n",
      "          -5.8130e-02,  1.4793e-01,  7.4414e-01,  7.5277e-01, -6.2831e-01,\n",
      "          -3.5105e-01, -9.6299e-01,  1.2724e-01,  2.5200e-01,  1.0940e+00,\n",
      "           2.2790e-01,  4.4129e-01, -2.8833e-01, -9.7706e-02, -6.7717e-01,\n",
      "           2.7167e-01,  6.1367e-01, -8.6641e-01, -4.5875e-01,  7.2575e-01,\n",
      "           1.1282e+00, -7.4515e-01, -7.0305e-01,  6.4158e-02, -6.5339e-02,\n",
      "          -1.0102e+00,  3.4191e-01, -4.1947e-01, -1.3056e-01,  2.3084e-01,\n",
      "          -9.6456e-01,  6.7498e-02,  4.1453e-01,  2.0939e-01, -1.5083e-01,\n",
      "           3.7152e-01, -8.4967e-01,  4.2419e-01,  5.9274e-01,  4.0839e-01,\n",
      "          -9.5830e-01,  1.4587e+00, -3.9560e-01,  3.3489e-01, -1.9920e-01,\n",
      "           4.1165e-01,  2.8483e-01, -3.8878e-01, -1.2366e-01,  8.4813e-01,\n",
      "           4.5087e-01,  6.6429e-01,  3.0381e-01],\n",
      "         [ 1.7441e-01, -6.7211e-01, -1.5640e-01, -1.1580e+00, -1.0435e-01,\n",
      "           1.4404e-01,  3.0745e-01, -1.7007e-01, -4.9850e-01, -7.4149e-01,\n",
      "           9.4434e-01,  3.7404e-01, -4.8738e-01, -1.1219e+00,  9.4047e-01,\n",
      "          -8.4908e-01,  6.3893e-01, -4.1423e-01, -8.4475e-01,  1.8214e-02,\n",
      "           5.4578e-01,  1.8847e-01,  6.5616e-01, -3.8372e-01, -2.4066e-01,\n",
      "           2.9473e-01, -1.1001e+00,  7.1834e-01, -5.1582e-01,  5.2085e-01,\n",
      "          -2.3029e-01, -1.7786e-01, -4.9320e-01, -1.0755e+00,  9.0674e-01,\n",
      "          -1.5440e-01,  2.4212e-01, -7.0689e-01,  1.7202e-01, -6.4171e-01,\n",
      "          -1.9212e-02,  7.0759e-01, -4.9292e-01,  7.2666e-01, -2.3915e-01,\n",
      "          -2.7479e-01,  2.3270e-01, -2.6458e-01, -7.9464e-02,  2.5548e-01,\n",
      "           2.4412e-01,  5.3418e-01,  9.0959e-02,  1.9184e-02, -6.3232e-02,\n",
      "           2.4601e-01, -1.4417e-01, -8.3248e-01, -7.0132e-01, -7.8853e-02,\n",
      "           3.6274e-01,  1.2665e-01,  1.1365e-01,  7.6589e-02,  1.3073e+00,\n",
      "           3.1243e-01, -2.6718e-01,  1.7633e-01,  1.9089e-01, -2.9158e-01,\n",
      "          -5.4685e-01, -3.5308e-01, -3.8852e-01,  3.6935e-01, -2.6628e-01,\n",
      "           8.4288e-02,  1.0111e+00,  1.2403e-01,  1.3054e+00,  2.7179e-01,\n",
      "           5.9444e-02,  3.8569e-01, -2.8197e-01, -3.6878e-01, -6.0088e-01,\n",
      "           4.3430e-02, -3.1068e-01, -5.3109e-02,  9.0455e-01, -2.3532e-01,\n",
      "          -2.5053e-01, -6.6691e-01,  2.0090e-01,  4.9650e-01, -1.9409e-01,\n",
      "          -2.6725e-01, -6.3967e-01,  7.6954e-02, -6.5682e-01, -6.7110e-01,\n",
      "          -1.0062e-02, -7.7553e-02, -2.1728e-01, -3.2565e-01,  2.2729e-01,\n",
      "          -6.5244e-02,  8.6072e-02,  2.9054e-02, -4.4487e-01, -9.6924e-01,\n",
      "           8.3247e-02,  1.1063e+00, -8.3119e-01, -1.7607e-01, -7.3985e-01,\n",
      "           1.0361e-01, -1.1531e+00, -1.0227e-01,  4.7752e-01,  8.6900e-01,\n",
      "           1.6644e-01,  2.7401e-01, -3.6733e-01, -9.3070e-02, -4.0377e-01,\n",
      "           4.6048e-01, -3.2923e-01, -1.1278e-01]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "linear_layer_2d = nn.Linear(in_features=68, out_features=128)\n",
    "flatten = nn.Flatten()\n",
    "input_2d = torch.randn(2, 2, 68) # n, channel, features\n",
    "#print(input_2d)\n",
    "print(input_2d.shape)\n",
    "output_2d = linear_layer_2d(input_2d)\n",
    "print('output_2d' , output_2d)\n",
    "#print(output_2d.size())\n",
    "\n",
    "#output_1d = flatten(input_2d)\n",
    "#print(output_1d.size())\n",
    "#linear_layer_2d(output_1d)\n",
    "#print(\"1D \",  output_1d)\n",
    "\n",
    "#test_sequence = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Linear(32,10))\n",
    "#out = test_sequence(input_2d)\n",
    "#print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntestload = pd.read_csv(\"./outimg/Train/facefeature.csv\")\\nlandmarks = np.array(testload.iloc[0, 1:])\\nlandmarks = landmarks.astype(\\'float\\').reshape(-1, 2)\\nprint(landmarks)\\n\\ndataiter = iter(testload)\\nlandmark = next(dataiter)\\nprint(landmark)\\n# print(landmarks.shape)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testload = pd.read_csv(\"./outimg/Train/facefeature.csv\")\n",
    "landmarks = np.array(testload.iloc[0, 1:])\n",
    "landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "print(landmarks)\n",
    "\n",
    "dataiter = iter(testload)\n",
    "landmark = next(dataiter)\n",
    "print(landmark)\n",
    "# print(landmarks.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, F, C]: torch.Size([10, 136])\n",
      "Shape of Tensor y: torch.Size([10, 33]) torch.float32\n",
      "X type torch.float32\n",
      "y type torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader \n",
    "\n",
    "training_data = FaceFeatureDataset(feature_file=\"./outimg/Train/facefeature.csv\", label_file=\"./Dataset/Train/csv/train.csv\")\n",
    "test_data = FaceFeatureDataset(feature_file=\"./outimg/Test/facefeature.csv\", label_file=\"./Dataset/Test/csv/test.csv\")\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터 로드 확인 \n",
    "for X, y in train_loader:\n",
    "    print(f\"Shape of X [N, F, C]: {X.shape}\") # N , Channel, H= width W = height\n",
    "    print(f\"Shape of Tensor y: {y.shape} {y.dtype}\")       \n",
    "    break\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "# print(f'Traing dat length {n_total_steps}')\n",
    "# print(y)\n",
    "print('X type', X.dtype)\n",
    "print('y type', y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#dataiter = iter(train_loader)\n",
    "#landmark, labels = next(dataiter)\n",
    "#print(\"landmark Shape \", landmark.shape)\n",
    "#print(landmark)\n",
    "#flatten = nn.Flatten()\n",
    "#linear1 = nn.Linear(68, 32)\n",
    "#x = flatten(landmark)\n",
    "#print(x)\n",
    "#print(x.size())\n",
    "# print(landmark.shape)\n",
    "# print('linear1', x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=136, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=33, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 33\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(68 * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes),\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # print(pred)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('batch',  batch)\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.280875  [    0/  100]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.265239  [    0/  100]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.217329  [    0/  100]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.198985  [    0/  100]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.165768  [    0/  100]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.122368  [    0/  100]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.086326  [    0/  100]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.062391  [    0/  100]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.040026  [    0/  100]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.032136  [    0/  100]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.032590  [    0/  100]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.032267  [    0/  100]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.032503  [    0/  100]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.033684  [    0/  100]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.033126  [    0/  100]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.033026  [    0/  100]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.027764  [    0/  100]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.029419  [    0/  100]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.028455  [    0/  100]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.029396  [    0/  100]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.030226  [    0/  100]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.031052  [    0/  100]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.028170  [    0/  100]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.029360  [    0/  100]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.032208  [    0/  100]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.029522  [    0/  100]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.030705  [    0/  100]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.032163  [    0/  100]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.033088  [    0/  100]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.028127  [    0/  100]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.030869  [    0/  100]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.031408  [    0/  100]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.026900  [    0/  100]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.029101  [    0/  100]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.030123  [    0/  100]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.032758  [    0/  100]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.031304  [    0/  100]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.030488  [    0/  100]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.029989  [    0/  100]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.029218  [    0/  100]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.030570  [    0/  100]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.028044  [    0/  100]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.027894  [    0/  100]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.030241  [    0/  100]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.031010  [    0/  100]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.030061  [    0/  100]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.030964  [    0/  100]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.032609  [    0/  100]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.029140  [    0/  100]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.033842  [    0/  100]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.029195  [    0/  100]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.033230  [    0/  100]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.033349  [    0/  100]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.032017  [    0/  100]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.027672  [    0/  100]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.031467  [    0/  100]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.031384  [    0/  100]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.031401  [    0/  100]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.031465  [    0/  100]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.030750  [    0/  100]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.033547  [    0/  100]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.030437  [    0/  100]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.028295  [    0/  100]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.031327  [    0/  100]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.032063  [    0/  100]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.030538  [    0/  100]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.030959  [    0/  100]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.028921  [    0/  100]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.032193  [    0/  100]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.031408  [    0/  100]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.030408  [    0/  100]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.028216  [    0/  100]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.029252  [    0/  100]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.029557  [    0/  100]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.032686  [    0/  100]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.030923  [    0/  100]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.029555  [    0/  100]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.029887  [    0/  100]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.031326  [    0/  100]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.031742  [    0/  100]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.030321  [    0/  100]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.030585  [    0/  100]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.030095  [    0/  100]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.031593  [    0/  100]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.028249  [    0/  100]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.030121  [    0/  100]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.027883  [    0/  100]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.028678  [    0/  100]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.028766  [    0/  100]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.031794  [    0/  100]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.030639  [    0/  100]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.030243  [    0/  100]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.031545  [    0/  100]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.032056  [    0/  100]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.029395  [    0/  100]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.029724  [    0/  100]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.029323  [    0/  100]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.030995  [    0/  100]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.030920  [    0/  100]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.028163  [    0/  100]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.032500  [    0/  100]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.029766  [    0/  100]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.031449  [    0/  100]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.030606  [    0/  100]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.030821  [    0/  100]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.029245  [    0/  100]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.028936  [    0/  100]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.030666  [    0/  100]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.029770  [    0/  100]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.028478  [    0/  100]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.032412  [    0/  100]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.029812  [    0/  100]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.032933  [    0/  100]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.029022  [    0/  100]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.031215  [    0/  100]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.029263  [    0/  100]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.030146  [    0/  100]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.030657  [    0/  100]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.029432  [    0/  100]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.031362  [    0/  100]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.030534  [    0/  100]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.027741  [    0/  100]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.032195  [    0/  100]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.032487  [    0/  100]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.029695  [    0/  100]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.030393  [    0/  100]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.033623  [    0/  100]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.027694  [    0/  100]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.029983  [    0/  100]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.030834  [    0/  100]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.027817  [    0/  100]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.029569  [    0/  100]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.029782  [    0/  100]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.029465  [    0/  100]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.028471  [    0/  100]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.030624  [    0/  100]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.031719  [    0/  100]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.029481  [    0/  100]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.029280  [    0/  100]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.029004  [    0/  100]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.027836  [    0/  100]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.030760  [    0/  100]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.027299  [    0/  100]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.032051  [    0/  100]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.028949  [    0/  100]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.029021  [    0/  100]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.032641  [    0/  100]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.030714  [    0/  100]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.030685  [    0/  100]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.029967  [    0/  100]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.031737  [    0/  100]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.030315  [    0/  100]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.032327  [    0/  100]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.031425  [    0/  100]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.029897  [    0/  100]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.029473  [    0/  100]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.031853  [    0/  100]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.027483  [    0/  100]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.028819  [    0/  100]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.029706  [    0/  100]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.030556  [    0/  100]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.031104  [    0/  100]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.029631  [    0/  100]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.029367  [    0/  100]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.031362  [    0/  100]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.030571  [    0/  100]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.030605  [    0/  100]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.029836  [    0/  100]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.032779  [    0/  100]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.030775  [    0/  100]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.031251  [    0/  100]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.027620  [    0/  100]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.031349  [    0/  100]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.028189  [    0/  100]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.032836  [    0/  100]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.029448  [    0/  100]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.029991  [    0/  100]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.028254  [    0/  100]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.030753  [    0/  100]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.029952  [    0/  100]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.031874  [    0/  100]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.032000  [    0/  100]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.029185  [    0/  100]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.030435  [    0/  100]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.031352  [    0/  100]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.027933  [    0/  100]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.031140  [    0/  100]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.030531  [    0/  100]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.031643  [    0/  100]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.029064  [    0/  100]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.032161  [    0/  100]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.032123  [    0/  100]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.030030  [    0/  100]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.028163  [    0/  100]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.030566  [    0/  100]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.030229  [    0/  100]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.032278  [    0/  100]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.031106  [    0/  100]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.029146  [    0/  100]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.029622  [    0/  100]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.030930  [    0/  100]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.028142  [    0/  100]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.032462  [    0/  100]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.029771  [    0/  100]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.029762  [    0/  100]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.030130  [    0/  100]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.029169  [    0/  100]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.031272  [    0/  100]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.031320  [    0/  100]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.031007  [    0/  100]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.030148  [    0/  100]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.030977  [    0/  100]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.030455  [    0/  100]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.031730  [    0/  100]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.034865  [    0/  100]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.029025  [    0/  100]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.029727  [    0/  100]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.031625  [    0/  100]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.029611  [    0/  100]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.030945  [    0/  100]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.031290  [    0/  100]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.029039  [    0/  100]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.030614  [    0/  100]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.030581  [    0/  100]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.029610  [    0/  100]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.033272  [    0/  100]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.030334  [    0/  100]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.030544  [    0/  100]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.031111  [    0/  100]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.029602  [    0/  100]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.029489  [    0/  100]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.028612  [    0/  100]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.029897  [    0/  100]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.029075  [    0/  100]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.028846  [    0/  100]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.032312  [    0/  100]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.030159  [    0/  100]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.028094  [    0/  100]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.028412  [    0/  100]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.029873  [    0/  100]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.027950  [    0/  100]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.032021  [    0/  100]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.030579  [    0/  100]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.029950  [    0/  100]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.030405  [    0/  100]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.027841  [    0/  100]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.033128  [    0/  100]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.028578  [    0/  100]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.031578  [    0/  100]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.032264  [    0/  100]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.029728  [    0/  100]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.030498  [    0/  100]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.032290  [    0/  100]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.031448  [    0/  100]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.031338  [    0/  100]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.028347  [    0/  100]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.026413  [    0/  100]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.029568  [    0/  100]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.031075  [    0/  100]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.031115  [    0/  100]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.030223  [    0/  100]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.028609  [    0/  100]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.029769  [    0/  100]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.031112  [    0/  100]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.030088  [    0/  100]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.030376  [    0/  100]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.030612  [    0/  100]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.028949  [    0/  100]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.029328  [    0/  100]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.029298  [    0/  100]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.033143  [    0/  100]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.030201  [    0/  100]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.031146  [    0/  100]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.028462  [    0/  100]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.030963  [    0/  100]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.028646  [    0/  100]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.030474  [    0/  100]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.031079  [    0/  100]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.030100  [    0/  100]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.029123  [    0/  100]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.029574  [    0/  100]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.030736  [    0/  100]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.032458  [    0/  100]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.028765  [    0/  100]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.030056  [    0/  100]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.031859  [    0/  100]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.029729  [    0/  100]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.030825  [    0/  100]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.029509  [    0/  100]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.032267  [    0/  100]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.032752  [    0/  100]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.030844  [    0/  100]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.031055  [    0/  100]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.029158  [    0/  100]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.032072  [    0/  100]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.032475  [    0/  100]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.028454  [    0/  100]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.030855  [    0/  100]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.028667  [    0/  100]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.032586  [    0/  100]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.028295  [    0/  100]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.030242  [    0/  100]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.028963  [    0/  100]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.030111  [    0/  100]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.032023  [    0/  100]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.032124  [    0/  100]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.031031  [    0/  100]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.030281  [    0/  100]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.030950  [    0/  100]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.029536  [    0/  100]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.029191  [    0/  100]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.031738  [    0/  100]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.034043  [    0/  100]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.029324  [    0/  100]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.031091  [    0/  100]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.030463  [    0/  100]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.030391  [    0/  100]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.029780  [    0/  100]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.028753  [    0/  100]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.028017  [    0/  100]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.028025  [    0/  100]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.028527  [    0/  100]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.031727  [    0/  100]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.032694  [    0/  100]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.030874  [    0/  100]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.029128  [    0/  100]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.029905  [    0/  100]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.032922  [    0/  100]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.031732  [    0/  100]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.030714  [    0/  100]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.027970  [    0/  100]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.031967  [    0/  100]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.031065  [    0/  100]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.033028  [    0/  100]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.029081  [    0/  100]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.029200  [    0/  100]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.032160  [    0/  100]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.030861  [    0/  100]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.030077  [    0/  100]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.032434  [    0/  100]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.031112  [    0/  100]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.029885  [    0/  100]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.032279  [    0/  100]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.030837  [    0/  100]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.030394  [    0/  100]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.031092  [    0/  100]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.028892  [    0/  100]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.028172  [    0/  100]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.029209  [    0/  100]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.030993  [    0/  100]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.030708  [    0/  100]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.031427  [    0/  100]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.029396  [    0/  100]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.028558  [    0/  100]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.030499  [    0/  100]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.031369  [    0/  100]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.031810  [    0/  100]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.033283  [    0/  100]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.031944  [    0/  100]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.029998  [    0/  100]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.029223  [    0/  100]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.028747  [    0/  100]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.027716  [    0/  100]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.032109  [    0/  100]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.034007  [    0/  100]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.030479  [    0/  100]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.030645  [    0/  100]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.031129  [    0/  100]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.032329  [    0/  100]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.029236  [    0/  100]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.031077  [    0/  100]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.031330  [    0/  100]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.028087  [    0/  100]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.028901  [    0/  100]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.030507  [    0/  100]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.029581  [    0/  100]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.028777  [    0/  100]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.030901  [    0/  100]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.030758  [    0/  100]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.029806  [    0/  100]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.031619  [    0/  100]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.032383  [    0/  100]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.031234  [    0/  100]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.034480  [    0/  100]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.029765  [    0/  100]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.030933  [    0/  100]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.030486  [    0/  100]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.029037  [    0/  100]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.029273  [    0/  100]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.029421  [    0/  100]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.033511  [    0/  100]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.028955  [    0/  100]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.029549  [    0/  100]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.029018  [    0/  100]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.031791  [    0/  100]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.029732  [    0/  100]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.029636  [    0/  100]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.032270  [    0/  100]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.028576  [    0/  100]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.030796  [    0/  100]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.030630  [    0/  100]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.029970  [    0/  100]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.033472  [    0/  100]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.029237  [    0/  100]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.029661  [    0/  100]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.030415  [    0/  100]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.030407  [    0/  100]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.028270  [    0/  100]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.030711  [    0/  100]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.029265  [    0/  100]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.028074  [    0/  100]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.030540  [    0/  100]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.027474  [    0/  100]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.032220  [    0/  100]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.030304  [    0/  100]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.031389  [    0/  100]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.028011  [    0/  100]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.031329  [    0/  100]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.027819  [    0/  100]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.032496  [    0/  100]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.030204  [    0/  100]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.028623  [    0/  100]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.029542  [    0/  100]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.029219  [    0/  100]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.027798  [    0/  100]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.029084  [    0/  100]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.029331  [    0/  100]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.031649  [    0/  100]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.030218  [    0/  100]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.030525  [    0/  100]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.030258  [    0/  100]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.031220  [    0/  100]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.029715  [    0/  100]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.032445  [    0/  100]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.031739  [    0/  100]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.031976  [    0/  100]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.030487  [    0/  100]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.028979  [    0/  100]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.030785  [    0/  100]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.030528  [    0/  100]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.030474  [    0/  100]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.029803  [    0/  100]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.028401  [    0/  100]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.030779  [    0/  100]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.029439  [    0/  100]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.030331  [    0/  100]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.030157  [    0/  100]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.029181  [    0/  100]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.029706  [    0/  100]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.031787  [    0/  100]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.032042  [    0/  100]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.031605  [    0/  100]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.032275  [    0/  100]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.031029  [    0/  100]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.029452  [    0/  100]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.031159  [    0/  100]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.030100  [    0/  100]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.029614  [    0/  100]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.030062  [    0/  100]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.029258  [    0/  100]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.028513  [    0/  100]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.031324  [    0/  100]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.030113  [    0/  100]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.028589  [    0/  100]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.032701  [    0/  100]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.029583  [    0/  100]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.030710  [    0/  100]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.029110  [    0/  100]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.028874  [    0/  100]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.029178  [    0/  100]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.032922  [    0/  100]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.031620  [    0/  100]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.033220  [    0/  100]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.029648  [    0/  100]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.026219  [    0/  100]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.031311  [    0/  100]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.033130  [    0/  100]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.027059  [    0/  100]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.031451  [    0/  100]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.027938  [    0/  100]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.029370  [    0/  100]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.026857  [    0/  100]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.030630  [    0/  100]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.029992  [    0/  100]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.028369  [    0/  100]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.030162  [    0/  100]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.030193  [    0/  100]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.028761  [    0/  100]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.032708  [    0/  100]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.030050  [    0/  100]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.031310  [    0/  100]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.030686  [    0/  100]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.027439  [    0/  100]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.028480  [    0/  100]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.030910  [    0/  100]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.031886  [    0/  100]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.030828  [    0/  100]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.031248  [    0/  100]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.029675  [    0/  100]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.028618  [    0/  100]\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.031845  [    0/  100]\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.032030  [    0/  100]\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.031155  [    0/  100]\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.030749  [    0/  100]\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.027952  [    0/  100]\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.031092  [    0/  100]\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.029991  [    0/  100]\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.033708  [    0/  100]\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.032952  [    0/  100]\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.028947  [    0/  100]\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.029200  [    0/  100]\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.031134  [    0/  100]\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.028992  [    0/  100]\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.029381  [    0/  100]\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.030694  [    0/  100]\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.030889  [    0/  100]\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.029778  [    0/  100]\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.032829  [    0/  100]\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.028889  [    0/  100]\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.028669  [    0/  100]\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.029716  [    0/  100]\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.028854  [    0/  100]\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.027580  [    0/  100]\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.031879  [    0/  100]\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.029216  [    0/  100]\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.029255  [    0/  100]\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.032568  [    0/  100]\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.031008  [    0/  100]\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.028086  [    0/  100]\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.031545  [    0/  100]\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.032542  [    0/  100]\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.028573  [    0/  100]\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.030372  [    0/  100]\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.031473  [    0/  100]\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.031250  [    0/  100]\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.030404  [    0/  100]\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.030942  [    0/  100]\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.029281  [    0/  100]\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.028219  [    0/  100]\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.031360  [    0/  100]\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.029566  [    0/  100]\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.032990  [    0/  100]\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.030556  [    0/  100]\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.031862  [    0/  100]\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.027354  [    0/  100]\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.030487  [    0/  100]\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.034004  [    0/  100]\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.032608  [    0/  100]\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.028545  [    0/  100]\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.032180  [    0/  100]\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.029153  [    0/  100]\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.029748  [    0/  100]\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.033007  [    0/  100]\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.031483  [    0/  100]\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.030176  [    0/  100]\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.030292  [    0/  100]\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.029054  [    0/  100]\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.030470  [    0/  100]\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.032654  [    0/  100]\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.030135  [    0/  100]\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.030432  [    0/  100]\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.029121  [    0/  100]\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.029982  [    0/  100]\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.030069  [    0/  100]\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.031736  [    0/  100]\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.031531  [    0/  100]\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.028947  [    0/  100]\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.030479  [    0/  100]\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.029651  [    0/  100]\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.029632  [    0/  100]\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.031128  [    0/  100]\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.032317  [    0/  100]\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.028354  [    0/  100]\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.031795  [    0/  100]\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.031272  [    0/  100]\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.030164  [    0/  100]\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.030124  [    0/  100]\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.030738  [    0/  100]\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.029139  [    0/  100]\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.029598  [    0/  100]\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.033362  [    0/  100]\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.028171  [    0/  100]\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.031894  [    0/  100]\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.031008  [    0/  100]\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.030948  [    0/  100]\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.031255  [    0/  100]\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.031132  [    0/  100]\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.031078  [    0/  100]\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.029949  [    0/  100]\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.029248  [    0/  100]\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.029161  [    0/  100]\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.028577  [    0/  100]\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.031939  [    0/  100]\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.030043  [    0/  100]\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.031757  [    0/  100]\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.030884  [    0/  100]\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.029583  [    0/  100]\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.032091  [    0/  100]\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.028791  [    0/  100]\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.030521  [    0/  100]\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.030811  [    0/  100]\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.031041  [    0/  100]\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.034602  [    0/  100]\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.031122  [    0/  100]\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.027535  [    0/  100]\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.029616  [    0/  100]\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.030324  [    0/  100]\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.030075  [    0/  100]\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.030042  [    0/  100]\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.029234  [    0/  100]\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.030917  [    0/  100]\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.027805  [    0/  100]\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.030169  [    0/  100]\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.029771  [    0/  100]\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.032575  [    0/  100]\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.031519  [    0/  100]\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.029636  [    0/  100]\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.030638  [    0/  100]\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.029833  [    0/  100]\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.032356  [    0/  100]\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.027926  [    0/  100]\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.029876  [    0/  100]\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.028901  [    0/  100]\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.032033  [    0/  100]\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.032350  [    0/  100]\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.030754  [    0/  100]\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.030367  [    0/  100]\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.031381  [    0/  100]\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.030973  [    0/  100]\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.029468  [    0/  100]\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.029048  [    0/  100]\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.031812  [    0/  100]\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.032202  [    0/  100]\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.028701  [    0/  100]\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.030618  [    0/  100]\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.029842  [    0/  100]\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.030663  [    0/  100]\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.029589  [    0/  100]\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.032518  [    0/  100]\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.029076  [    0/  100]\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.030905  [    0/  100]\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.030420  [    0/  100]\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.031017  [    0/  100]\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.033347  [    0/  100]\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.029293  [    0/  100]\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.028107  [    0/  100]\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.031485  [    0/  100]\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.028644  [    0/  100]\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.028153  [    0/  100]\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.031373  [    0/  100]\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.029004  [    0/  100]\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.030202  [    0/  100]\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.032746  [    0/  100]\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.029025  [    0/  100]\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.029135  [    0/  100]\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.028749  [    0/  100]\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.030725  [    0/  100]\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.030098  [    0/  100]\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.028194  [    0/  100]\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.030202  [    0/  100]\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.030380  [    0/  100]\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.029038  [    0/  100]\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.029644  [    0/  100]\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.028154  [    0/  100]\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.031028  [    0/  100]\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.028974  [    0/  100]\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.031296  [    0/  100]\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.030566  [    0/  100]\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.030429  [    0/  100]\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.029318  [    0/  100]\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.032843  [    0/  100]\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.032455  [    0/  100]\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.028942  [    0/  100]\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.029607  [    0/  100]\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.030935  [    0/  100]\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.030748  [    0/  100]\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.030555  [    0/  100]\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.032111  [    0/  100]\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.030672  [    0/  100]\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.033194  [    0/  100]\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.031635  [    0/  100]\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.030027  [    0/  100]\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.029541  [    0/  100]\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.030532  [    0/  100]\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.030392  [    0/  100]\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.031438  [    0/  100]\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.030027  [    0/  100]\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.028532  [    0/  100]\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.031079  [    0/  100]\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.029522  [    0/  100]\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.026732  [    0/  100]\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.029130  [    0/  100]\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.030990  [    0/  100]\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.030616  [    0/  100]\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.030867  [    0/  100]\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.030039  [    0/  100]\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.030014  [    0/  100]\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.030229  [    0/  100]\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.030839  [    0/  100]\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.032452  [    0/  100]\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.028380  [    0/  100]\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.029510  [    0/  100]\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.030664  [    0/  100]\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.030177  [    0/  100]\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.029365  [    0/  100]\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.030948  [    0/  100]\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.032487  [    0/  100]\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.029546  [    0/  100]\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.030321  [    0/  100]\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.029931  [    0/  100]\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.032173  [    0/  100]\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.030306  [    0/  100]\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.033275  [    0/  100]\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.030537  [    0/  100]\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.030157  [    0/  100]\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.029924  [    0/  100]\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.032058  [    0/  100]\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.031051  [    0/  100]\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.031582  [    0/  100]\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.028923  [    0/  100]\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.030082  [    0/  100]\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.030371  [    0/  100]\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.031335  [    0/  100]\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.027510  [    0/  100]\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.029696  [    0/  100]\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.029840  [    0/  100]\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.029483  [    0/  100]\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.029848  [    0/  100]\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.033726  [    0/  100]\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.028741  [    0/  100]\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.032380  [    0/  100]\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.030729  [    0/  100]\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.028833  [    0/  100]\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.027986  [    0/  100]\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.027897  [    0/  100]\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.029093  [    0/  100]\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.028387  [    0/  100]\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.031091  [    0/  100]\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.032371  [    0/  100]\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.031898  [    0/  100]\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.029658  [    0/  100]\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.028873  [    0/  100]\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.030457  [    0/  100]\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.030378  [    0/  100]\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.030918  [    0/  100]\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.030295  [    0/  100]\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.030894  [    0/  100]\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.031289  [    0/  100]\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.028533  [    0/  100]\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.030548  [    0/  100]\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.029074  [    0/  100]\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.028257  [    0/  100]\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.030158  [    0/  100]\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.031948  [    0/  100]\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.031448  [    0/  100]\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.033283  [    0/  100]\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.030614  [    0/  100]\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.030477  [    0/  100]\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.031112  [    0/  100]\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.028450  [    0/  100]\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.032289  [    0/  100]\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.031009  [    0/  100]\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.030569  [    0/  100]\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.030076  [    0/  100]\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.029959  [    0/  100]\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.031872  [    0/  100]\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.030505  [    0/  100]\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.032045  [    0/  100]\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.030850  [    0/  100]\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.031599  [    0/  100]\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.031525  [    0/  100]\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.030641  [    0/  100]\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.030268  [    0/  100]\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.031826  [    0/  100]\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.030818  [    0/  100]\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.031742  [    0/  100]\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.031971  [    0/  100]\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.029149  [    0/  100]\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.030426  [    0/  100]\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.028720  [    0/  100]\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.028956  [    0/  100]\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.030082  [    0/  100]\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.028834  [    0/  100]\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.032400  [    0/  100]\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.028049  [    0/  100]\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.029939  [    0/  100]\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.031384  [    0/  100]\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.030119  [    0/  100]\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.029266  [    0/  100]\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.030210  [    0/  100]\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.029647  [    0/  100]\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.028289  [    0/  100]\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.031849  [    0/  100]\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.032257  [    0/  100]\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.032473  [    0/  100]\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.028194  [    0/  100]\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.032423  [    0/  100]\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.030207  [    0/  100]\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.031844  [    0/  100]\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.026787  [    0/  100]\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.030446  [    0/  100]\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.031370  [    0/  100]\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.029532  [    0/  100]\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.032798  [    0/  100]\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.030805  [    0/  100]\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.031005  [    0/  100]\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.031206  [    0/  100]\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.027966  [    0/  100]\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.031150  [    0/  100]\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.032410  [    0/  100]\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.032203  [    0/  100]\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.027898  [    0/  100]\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.032283  [    0/  100]\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.030558  [    0/  100]\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.030169  [    0/  100]\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.032110  [    0/  100]\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.031181  [    0/  100]\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.029853  [    0/  100]\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.029601  [    0/  100]\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.029193  [    0/  100]\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.030304  [    0/  100]\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.028076  [    0/  100]\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.029047  [    0/  100]\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.030972  [    0/  100]\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.030797  [    0/  100]\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.030099  [    0/  100]\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.029726  [    0/  100]\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.031527  [    0/  100]\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.032356  [    0/  100]\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.030988  [    0/  100]\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.029907  [    0/  100]\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.033075  [    0/  100]\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.029835  [    0/  100]\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.030771  [    0/  100]\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.028577  [    0/  100]\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.027312  [    0/  100]\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.031460  [    0/  100]\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.030488  [    0/  100]\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.029006  [    0/  100]\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.032716  [    0/  100]\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.030715  [    0/  100]\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.031479  [    0/  100]\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.028912  [    0/  100]\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.031592  [    0/  100]\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.031313  [    0/  100]\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.028060  [    0/  100]\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.028930  [    0/  100]\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.032191  [    0/  100]\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.028751  [    0/  100]\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.030062  [    0/  100]\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.031501  [    0/  100]\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.028945  [    0/  100]\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.028168  [    0/  100]\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.031664  [    0/  100]\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.028288  [    0/  100]\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.028650  [    0/  100]\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.031121  [    0/  100]\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.028637  [    0/  100]\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.029996  [    0/  100]\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.029302  [    0/  100]\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.031472  [    0/  100]\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.029134  [    0/  100]\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.032163  [    0/  100]\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.031171  [    0/  100]\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.031180  [    0/  100]\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.032502  [    0/  100]\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.031624  [    0/  100]\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.030035  [    0/  100]\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.030983  [    0/  100]\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.029227  [    0/  100]\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.032346  [    0/  100]\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.031458  [    0/  100]\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.031747  [    0/  100]\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.030996  [    0/  100]\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.031401  [    0/  100]\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.028822  [    0/  100]\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.029540  [    0/  100]\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.033879  [    0/  100]\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.028915  [    0/  100]\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.031011  [    0/  100]\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.028953  [    0/  100]\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.031006  [    0/  100]\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.027972  [    0/  100]\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.029754  [    0/  100]\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.030171  [    0/  100]\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.031991  [    0/  100]\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.029846  [    0/  100]\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.032966  [    0/  100]\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.030986  [    0/  100]\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.029263  [    0/  100]\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.030301  [    0/  100]\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.032075  [    0/  100]\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.028577  [    0/  100]\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.028511  [    0/  100]\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.028079  [    0/  100]\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.031327  [    0/  100]\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.032335  [    0/  100]\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.030960  [    0/  100]\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.031820  [    0/  100]\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.027655  [    0/  100]\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.029174  [    0/  100]\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.029651  [    0/  100]\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.030584  [    0/  100]\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.029843  [    0/  100]\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.031600  [    0/  100]\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.031094  [    0/  100]\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.029483  [    0/  100]\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.030353  [    0/  100]\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.029666  [    0/  100]\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.029687  [    0/  100]\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.029241  [    0/  100]\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.031110  [    0/  100]\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.029888  [    0/  100]\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.029269  [    0/  100]\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.029698  [    0/  100]\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.030758  [    0/  100]\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.030752  [    0/  100]\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.031225  [    0/  100]\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.029985  [    0/  100]\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.031114  [    0/  100]\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.028674  [    0/  100]\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.027290  [    0/  100]\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.031316  [    0/  100]\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.031218  [    0/  100]\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.029088  [    0/  100]\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.029534  [    0/  100]\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.031915  [    0/  100]\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.031903  [    0/  100]\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.029466  [    0/  100]\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.030649  [    0/  100]\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.028709  [    0/  100]\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.028702  [    0/  100]\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.028977  [    0/  100]\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.032428  [    0/  100]\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.030791  [    0/  100]\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.030237  [    0/  100]\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.031374  [    0/  100]\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.027480  [    0/  100]\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.029924  [    0/  100]\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.029752  [    0/  100]\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.030459  [    0/  100]\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.029300  [    0/  100]\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.031085  [    0/  100]\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.030393  [    0/  100]\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.030039  [    0/  100]\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.026667  [    0/  100]\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.030667  [    0/  100]\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.031007  [    0/  100]\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.029439  [    0/  100]\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.031953  [    0/  100]\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.028765  [    0/  100]\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.029434  [    0/  100]\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.029675  [    0/  100]\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.030007  [    0/  100]\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.031614  [    0/  100]\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.028342  [    0/  100]\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.029476  [    0/  100]\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.031143  [    0/  100]\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.031538  [    0/  100]\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.030236  [    0/  100]\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.031810  [    0/  100]\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.030912  [    0/  100]\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.029939  [    0/  100]\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.030862  [    0/  100]\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.029509  [    0/  100]\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.031008  [    0/  100]\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.032292  [    0/  100]\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.029093  [    0/  100]\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.030496  [    0/  100]\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.029961  [    0/  100]\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.029791  [    0/  100]\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.028848  [    0/  100]\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.030758  [    0/  100]\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.030209  [    0/  100]\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.029121  [    0/  100]\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.026095  [    0/  100]\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.027926  [    0/  100]\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.030143  [    0/  100]\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.032176  [    0/  100]\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.031008  [    0/  100]\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.029767  [    0/  100]\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.030620  [    0/  100]\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.031196  [    0/  100]\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.028356  [    0/  100]\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.029336  [    0/  100]\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.030903  [    0/  100]\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.028657  [    0/  100]\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.029108  [    0/  100]\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.029680  [    0/  100]\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.029030  [    0/  100]\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.030639  [    0/  100]\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.030394  [    0/  100]\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.028750  [    0/  100]\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.030158  [    0/  100]\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.029578  [    0/  100]\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.029495  [    0/  100]\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.028923  [    0/  100]\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.031062  [    0/  100]\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.029886  [    0/  100]\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.027858  [    0/  100]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 1000\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print('test size', size )\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)            \n",
    "            print('pred =', pred)\n",
    "            #print('loss', loss)\n",
    "            #print('real', y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size 100\n",
      "pred = tensor([[0.4884, 0.4862, 0.4923, 0.5085, 0.5192, 0.5185, 0.4763, 0.5034, 0.5230,\n",
      "         0.5138, 0.5209, 0.5012, 0.4917, 0.5166, 0.4849, 0.4951, 0.5101, 0.5320,\n",
      "         0.4967, 0.5214, 0.4975, 0.5065, 0.4967, 0.5018, 0.5170, 0.4897, 0.5260,\n",
      "         0.4863, 0.4821, 0.5072, 0.5250, 0.5167, 0.4802],\n",
      "        [0.4920, 0.4882, 0.4950, 0.5091, 0.5206, 0.5220, 0.4753, 0.5012, 0.5247,\n",
      "         0.5127, 0.5220, 0.5015, 0.4946, 0.5160, 0.4855, 0.4925, 0.5120, 0.5376,\n",
      "         0.4959, 0.5207, 0.4994, 0.5097, 0.4957, 0.5017, 0.5200, 0.4923, 0.5276,\n",
      "         0.4896, 0.4837, 0.5108, 0.5245, 0.5171, 0.4827],\n",
      "        [0.4885, 0.4850, 0.4926, 0.5069, 0.5180, 0.5209, 0.4739, 0.5000, 0.5215,\n",
      "         0.5102, 0.5197, 0.5001, 0.4921, 0.5144, 0.4830, 0.4909, 0.5100, 0.5343,\n",
      "         0.4944, 0.5195, 0.4983, 0.5068, 0.4944, 0.4994, 0.5174, 0.4898, 0.5252,\n",
      "         0.4863, 0.4819, 0.5068, 0.5226, 0.5148, 0.4809],\n",
      "        [0.4870, 0.4815, 0.4897, 0.5044, 0.5160, 0.5181, 0.4707, 0.4955, 0.5182,\n",
      "         0.5064, 0.5168, 0.4976, 0.4903, 0.5092, 0.4787, 0.4857, 0.5066, 0.5330,\n",
      "         0.4909, 0.5175, 0.4964, 0.5049, 0.4918, 0.4957, 0.5147, 0.4863, 0.5231,\n",
      "         0.4850, 0.4786, 0.5046, 0.5198, 0.5120, 0.4794],\n",
      "        [0.4889, 0.4847, 0.4924, 0.5069, 0.5178, 0.5194, 0.4730, 0.4986, 0.5212,\n",
      "         0.5093, 0.5188, 0.4995, 0.4926, 0.5127, 0.4815, 0.4890, 0.5096, 0.5352,\n",
      "         0.4933, 0.5188, 0.4979, 0.5068, 0.4935, 0.4986, 0.5173, 0.4890, 0.5250,\n",
      "         0.4873, 0.4813, 0.5069, 0.5223, 0.5143, 0.4806],\n",
      "        [0.4913, 0.4857, 0.4932, 0.5082, 0.5199, 0.5200, 0.4740, 0.4994, 0.5224,\n",
      "         0.5099, 0.5203, 0.5010, 0.4946, 0.5144, 0.4826, 0.4898, 0.5098, 0.5363,\n",
      "         0.4945, 0.5192, 0.4983, 0.5083, 0.4939, 0.4995, 0.5190, 0.4898, 0.5263,\n",
      "         0.4887, 0.4829, 0.5082, 0.5235, 0.5160, 0.4816],\n",
      "        [0.4871, 0.4845, 0.4919, 0.5058, 0.5159, 0.5213, 0.4721, 0.4992, 0.5202,\n",
      "         0.5085, 0.5186, 0.4980, 0.4907, 0.5133, 0.4824, 0.4895, 0.5096, 0.5335,\n",
      "         0.4925, 0.5192, 0.4983, 0.5069, 0.4933, 0.4988, 0.5159, 0.4894, 0.5241,\n",
      "         0.4851, 0.4807, 0.5066, 0.5216, 0.5130, 0.4802],\n",
      "        [0.4838, 0.4759, 0.4851, 0.5007, 0.5111, 0.5142, 0.4653, 0.4889, 0.5110,\n",
      "         0.4988, 0.5109, 0.4952, 0.4876, 0.5028, 0.4707, 0.4784, 0.5017, 0.5293,\n",
      "         0.4862, 0.5146, 0.4941, 0.5013, 0.4869, 0.4892, 0.5107, 0.4807, 0.5187,\n",
      "         0.4819, 0.4751, 0.4984, 0.5154, 0.5071, 0.4768],\n",
      "        [0.4884, 0.4849, 0.4922, 0.5082, 0.5193, 0.5182, 0.4756, 0.5022, 0.5227,\n",
      "         0.5125, 0.5205, 0.5007, 0.4919, 0.5153, 0.4836, 0.4939, 0.5094, 0.5327,\n",
      "         0.4960, 0.5207, 0.4970, 0.5059, 0.4965, 0.5000, 0.5174, 0.4884, 0.5257,\n",
      "         0.4861, 0.4818, 0.5060, 0.5244, 0.5161, 0.4804],\n",
      "        [0.4811, 0.4737, 0.4825, 0.4995, 0.5095, 0.5091, 0.4637, 0.4875, 0.5083,\n",
      "         0.4976, 0.5077, 0.4936, 0.4860, 0.4996, 0.4672, 0.4761, 0.4978, 0.5263,\n",
      "         0.4838, 0.5122, 0.4914, 0.4984, 0.4854, 0.4865, 0.5078, 0.4769, 0.5164,\n",
      "         0.4801, 0.4726, 0.4952, 0.5135, 0.5056, 0.4745]], device='cuda:0')\n",
      "pred = tensor([[0.4865, 0.4833, 0.4898, 0.5057, 0.5168, 0.5168, 0.4728, 0.4993, 0.5196,\n",
      "         0.5097, 0.5178, 0.4990, 0.4905, 0.5124, 0.4807, 0.4904, 0.5069, 0.5308,\n",
      "         0.4928, 0.5192, 0.4954, 0.5045, 0.4937, 0.4979, 0.5149, 0.4864, 0.5238,\n",
      "         0.4842, 0.4796, 0.5040, 0.5218, 0.5139, 0.4790],\n",
      "        [0.4931, 0.4931, 0.4982, 0.5128, 0.5259, 0.5248, 0.4830, 0.5114, 0.5323,\n",
      "         0.5233, 0.5284, 0.5052, 0.4954, 0.5251, 0.4945, 0.5053, 0.5165, 0.5368,\n",
      "         0.5034, 0.5263, 0.5007, 0.5112, 0.5036, 0.5090, 0.5225, 0.4964, 0.5318,\n",
      "         0.4891, 0.4872, 0.5139, 0.5304, 0.5229, 0.4843],\n",
      "        [0.4922, 0.4876, 0.4944, 0.5106, 0.5227, 0.5184, 0.4777, 0.5042, 0.5256,\n",
      "         0.5151, 0.5231, 0.5033, 0.4953, 0.5177, 0.4861, 0.4954, 0.5111, 0.5356,\n",
      "         0.4981, 0.5213, 0.4980, 0.5084, 0.4978, 0.5023, 0.5207, 0.4906, 0.5283,\n",
      "         0.4897, 0.4842, 0.5089, 0.5268, 0.5192, 0.4818],\n",
      "        [0.4941, 0.4926, 0.4985, 0.5137, 0.5271, 0.5231, 0.4834, 0.5115, 0.5327,\n",
      "         0.5229, 0.5287, 0.5064, 0.4973, 0.5249, 0.4938, 0.5047, 0.5161, 0.5379,\n",
      "         0.5036, 0.5255, 0.5001, 0.5109, 0.5036, 0.5086, 0.5240, 0.4957, 0.5325,\n",
      "         0.4907, 0.4876, 0.5137, 0.5310, 0.5238, 0.4840],\n",
      "        [0.4809, 0.4767, 0.4852, 0.5014, 0.5115, 0.5121, 0.4680, 0.4921, 0.5117,\n",
      "         0.5035, 0.5112, 0.4947, 0.4859, 0.5040, 0.4724, 0.4832, 0.5022, 0.5260,\n",
      "         0.4881, 0.5159, 0.4934, 0.4997, 0.4890, 0.4900, 0.5092, 0.4807, 0.5188,\n",
      "         0.4805, 0.4750, 0.4974, 0.5161, 0.5080, 0.4758],\n",
      "        [0.4840, 0.4803, 0.4872, 0.5024, 0.5121, 0.5160, 0.4690, 0.4950, 0.5147,\n",
      "         0.5046, 0.5140, 0.4961, 0.4882, 0.5084, 0.4763, 0.4859, 0.5051, 0.5296,\n",
      "         0.4888, 0.5168, 0.4944, 0.5027, 0.4904, 0.4943, 0.5123, 0.4844, 0.5205,\n",
      "         0.4818, 0.4768, 0.5010, 0.5189, 0.5099, 0.4771],\n",
      "        [0.4836, 0.4757, 0.4861, 0.5022, 0.5133, 0.5116, 0.4669, 0.4903, 0.5118,\n",
      "         0.5010, 0.5113, 0.4955, 0.4885, 0.5029, 0.4709, 0.4796, 0.5011, 0.5288,\n",
      "         0.4873, 0.5146, 0.4938, 0.5008, 0.4878, 0.4889, 0.5109, 0.4796, 0.5197,\n",
      "         0.4832, 0.4760, 0.4982, 0.5161, 0.5087, 0.4765],\n",
      "        [0.4912, 0.4876, 0.4956, 0.5085, 0.5204, 0.5229, 0.4754, 0.5022, 0.5243,\n",
      "         0.5124, 0.5219, 0.5004, 0.4947, 0.5173, 0.4856, 0.4928, 0.5127, 0.5377,\n",
      "         0.4954, 0.5210, 0.5000, 0.5101, 0.4951, 0.5020, 0.5200, 0.4926, 0.5278,\n",
      "         0.4892, 0.4842, 0.5104, 0.5245, 0.5168, 0.4821],\n",
      "        [0.4864, 0.4830, 0.4893, 0.5048, 0.5167, 0.5159, 0.4729, 0.4985, 0.5188,\n",
      "         0.5096, 0.5170, 0.4989, 0.4909, 0.5116, 0.4796, 0.4904, 0.5065, 0.5313,\n",
      "         0.4923, 0.5187, 0.4943, 0.5040, 0.4934, 0.4970, 0.5148, 0.4857, 0.5237,\n",
      "         0.4837, 0.4790, 0.5036, 0.5214, 0.5135, 0.4785],\n",
      "        [0.4903, 0.4874, 0.4944, 0.5082, 0.5199, 0.5224, 0.4764, 0.5028, 0.5242,\n",
      "         0.5139, 0.5228, 0.5004, 0.4937, 0.5174, 0.4864, 0.4949, 0.5132, 0.5360,\n",
      "         0.4960, 0.5218, 0.4989, 0.5091, 0.4959, 0.5022, 0.5197, 0.4923, 0.5279,\n",
      "         0.4879, 0.4835, 0.5094, 0.5252, 0.5170, 0.4820]], device='cuda:0')\n",
      "pred = tensor([[0.4827, 0.4746, 0.4848, 0.4993, 0.5099, 0.5143, 0.4639, 0.4872, 0.5097,\n",
      "         0.4979, 0.5098, 0.4933, 0.4862, 0.5009, 0.4693, 0.4770, 0.5009, 0.5286,\n",
      "         0.4846, 0.5140, 0.4945, 0.5014, 0.4857, 0.4876, 0.5089, 0.4805, 0.5176,\n",
      "         0.4808, 0.4739, 0.4983, 0.5132, 0.5059, 0.4762],\n",
      "        [0.4881, 0.4848, 0.4912, 0.5069, 0.5184, 0.5183, 0.4746, 0.5003, 0.5214,\n",
      "         0.5114, 0.5194, 0.5004, 0.4917, 0.5140, 0.4822, 0.4927, 0.5081, 0.5327,\n",
      "         0.4947, 0.5196, 0.4960, 0.5056, 0.4953, 0.4990, 0.5163, 0.4880, 0.5249,\n",
      "         0.4850, 0.4807, 0.5061, 0.5227, 0.5152, 0.4797],\n",
      "        [0.4914, 0.4880, 0.4946, 0.5091, 0.5210, 0.5223, 0.4766, 0.5029, 0.5246,\n",
      "         0.5141, 0.5231, 0.5021, 0.4942, 0.5180, 0.4866, 0.4959, 0.5120, 0.5356,\n",
      "         0.4970, 0.5222, 0.4987, 0.5091, 0.4966, 0.5022, 0.5201, 0.4918, 0.5281,\n",
      "         0.4880, 0.4841, 0.5100, 0.5255, 0.5180, 0.4824],\n",
      "        [0.4915, 0.4899, 0.4957, 0.5103, 0.5220, 0.5239, 0.4794, 0.5069, 0.5276,\n",
      "         0.5175, 0.5255, 0.5032, 0.4942, 0.5216, 0.4902, 0.5006, 0.5140, 0.5359,\n",
      "         0.4996, 0.5237, 0.4991, 0.5097, 0.4998, 0.5059, 0.5209, 0.4940, 0.5292,\n",
      "         0.4875, 0.4846, 0.5119, 0.5276, 0.5198, 0.4825],\n",
      "        [0.4826, 0.4754, 0.4860, 0.5010, 0.5113, 0.5139, 0.4655, 0.4894, 0.5114,\n",
      "         0.4998, 0.5110, 0.4940, 0.4868, 0.5023, 0.4711, 0.4788, 0.5018, 0.5287,\n",
      "         0.4865, 0.5145, 0.4946, 0.5010, 0.4874, 0.4888, 0.5101, 0.4805, 0.5187,\n",
      "         0.4819, 0.4749, 0.4983, 0.5152, 0.5069, 0.4768],\n",
      "        [0.4888, 0.4857, 0.4929, 0.5070, 0.5188, 0.5207, 0.4743, 0.5005, 0.5224,\n",
      "         0.5117, 0.5201, 0.4998, 0.4919, 0.5143, 0.4833, 0.4927, 0.5092, 0.5340,\n",
      "         0.4946, 0.5203, 0.4976, 0.5071, 0.4952, 0.4999, 0.5166, 0.4895, 0.5258,\n",
      "         0.4853, 0.4813, 0.5081, 0.5222, 0.5152, 0.4808],\n",
      "        [0.4870, 0.4848, 0.4919, 0.5074, 0.5189, 0.5187, 0.4758, 0.5022, 0.5222,\n",
      "         0.5133, 0.5201, 0.5005, 0.4905, 0.5151, 0.4838, 0.4950, 0.5093, 0.5313,\n",
      "         0.4964, 0.5211, 0.4969, 0.5051, 0.4970, 0.4995, 0.5161, 0.4882, 0.5254,\n",
      "         0.4844, 0.4814, 0.5051, 0.5233, 0.5155, 0.4804],\n",
      "        [0.4942, 0.4912, 0.4977, 0.5129, 0.5242, 0.5242, 0.4799, 0.5084, 0.5294,\n",
      "         0.5177, 0.5271, 0.5048, 0.4963, 0.5240, 0.4918, 0.5000, 0.5156, 0.5374,\n",
      "         0.5011, 0.5242, 0.5011, 0.5121, 0.4997, 0.5074, 0.5237, 0.4954, 0.5308,\n",
      "         0.4911, 0.4873, 0.5133, 0.5297, 0.5218, 0.4840],\n",
      "        [0.4901, 0.4841, 0.4940, 0.5080, 0.5195, 0.5199, 0.4730, 0.4979, 0.5212,\n",
      "         0.5090, 0.5193, 0.4992, 0.4931, 0.5124, 0.4815, 0.4880, 0.5099, 0.5358,\n",
      "         0.4941, 0.5193, 0.4996, 0.5082, 0.4932, 0.4978, 0.5181, 0.4892, 0.5261,\n",
      "         0.4891, 0.4826, 0.5078, 0.5223, 0.5147, 0.4820],\n",
      "        [0.4866, 0.4812, 0.4895, 0.5062, 0.5162, 0.5156, 0.4716, 0.4977, 0.5178,\n",
      "         0.5068, 0.5174, 0.4991, 0.4902, 0.5114, 0.4789, 0.4878, 0.5067, 0.5301,\n",
      "         0.4926, 0.5184, 0.4959, 0.5042, 0.4921, 0.4963, 0.5156, 0.4852, 0.5230,\n",
      "         0.4854, 0.4798, 0.5027, 0.5220, 0.5135, 0.4787]], device='cuda:0')\n",
      "pred = tensor([[0.4933, 0.4888, 0.4962, 0.5099, 0.5221, 0.5238, 0.4775, 0.5043, 0.5260,\n",
      "         0.5143, 0.5247, 0.5021, 0.4959, 0.5197, 0.4883, 0.4952, 0.5144, 0.5380,\n",
      "         0.4976, 0.5228, 0.5006, 0.5116, 0.4965, 0.5043, 0.5219, 0.4942, 0.5293,\n",
      "         0.4906, 0.4857, 0.5118, 0.5272, 0.5190, 0.4832],\n",
      "        [0.4921, 0.4893, 0.4962, 0.5103, 0.5216, 0.5239, 0.4775, 0.5049, 0.5266,\n",
      "         0.5151, 0.5245, 0.5021, 0.4946, 0.5202, 0.4888, 0.4968, 0.5139, 0.5371,\n",
      "         0.4981, 0.5226, 0.5002, 0.5106, 0.4976, 0.5046, 0.5212, 0.4942, 0.5287,\n",
      "         0.4891, 0.4851, 0.5120, 0.5267, 0.5189, 0.4829],\n",
      "        [0.4938, 0.4901, 0.4969, 0.5109, 0.5232, 0.5248, 0.4784, 0.5050, 0.5281,\n",
      "         0.5155, 0.5257, 0.5036, 0.4959, 0.5205, 0.4897, 0.4968, 0.5147, 0.5389,\n",
      "         0.4992, 0.5227, 0.5007, 0.5112, 0.4986, 0.5053, 0.5226, 0.4949, 0.5299,\n",
      "         0.4905, 0.4860, 0.5132, 0.5275, 0.5199, 0.4839],\n",
      "        [0.4976, 0.4968, 0.5012, 0.5154, 0.5290, 0.5281, 0.4856, 0.5137, 0.5367,\n",
      "         0.5256, 0.5322, 0.5082, 0.4989, 0.5289, 0.4985, 0.5087, 0.5198, 0.5415,\n",
      "         0.5061, 0.5275, 0.5020, 0.5145, 0.5058, 0.5128, 0.5269, 0.5000, 0.5348,\n",
      "         0.4917, 0.4899, 0.5187, 0.5335, 0.5260, 0.4863],\n",
      "        [0.4853, 0.4835, 0.4905, 0.5049, 0.5148, 0.5185, 0.4721, 0.4987, 0.5189,\n",
      "         0.5087, 0.5169, 0.4977, 0.4903, 0.5119, 0.4806, 0.4889, 0.5086, 0.5324,\n",
      "         0.4919, 0.5178, 0.4965, 0.5047, 0.4932, 0.4976, 0.5148, 0.4880, 0.5230,\n",
      "         0.4845, 0.4792, 0.5043, 0.5210, 0.5126, 0.4791],\n",
      "        [0.4909, 0.4894, 0.4951, 0.5104, 0.5217, 0.5207, 0.4787, 0.5067, 0.5266,\n",
      "         0.5170, 0.5238, 0.5027, 0.4942, 0.5201, 0.4886, 0.4985, 0.5132, 0.5352,\n",
      "         0.4986, 0.5224, 0.4987, 0.5091, 0.4989, 0.5047, 0.5203, 0.4928, 0.5283,\n",
      "         0.4884, 0.4843, 0.5102, 0.5275, 0.5193, 0.4817],\n",
      "        [0.4893, 0.4874, 0.4944, 0.5065, 0.5177, 0.5246, 0.4741, 0.5015, 0.5238,\n",
      "         0.5113, 0.5211, 0.4999, 0.4931, 0.5165, 0.4856, 0.4919, 0.5124, 0.5373,\n",
      "         0.4941, 0.5198, 0.4993, 0.5088, 0.4951, 0.5021, 0.5186, 0.4930, 0.5262,\n",
      "         0.4870, 0.4821, 0.5100, 0.5231, 0.5154, 0.4816],\n",
      "        [0.4866, 0.4831, 0.4896, 0.5054, 0.5167, 0.5172, 0.4726, 0.4986, 0.5188,\n",
      "         0.5093, 0.5176, 0.4988, 0.4904, 0.5122, 0.4802, 0.4908, 0.5063, 0.5303,\n",
      "         0.4925, 0.5196, 0.4954, 0.5046, 0.4931, 0.4974, 0.5145, 0.4861, 0.5238,\n",
      "         0.4833, 0.4797, 0.5042, 0.5211, 0.5134, 0.4786],\n",
      "        [0.4942, 0.4942, 0.4992, 0.5142, 0.5267, 0.5240, 0.4839, 0.5131, 0.5338,\n",
      "         0.5244, 0.5294, 0.5061, 0.4968, 0.5263, 0.4957, 0.5059, 0.5175, 0.5383,\n",
      "         0.5042, 0.5255, 0.5008, 0.5119, 0.5045, 0.5104, 0.5241, 0.4975, 0.5324,\n",
      "         0.4908, 0.4878, 0.5148, 0.5318, 0.5241, 0.4843],\n",
      "        [0.4931, 0.4919, 0.4980, 0.5121, 0.5243, 0.5247, 0.4817, 0.5096, 0.5311,\n",
      "         0.5205, 0.5279, 0.5043, 0.4958, 0.5234, 0.4930, 0.5027, 0.5171, 0.5383,\n",
      "         0.5017, 0.5246, 0.5005, 0.5111, 0.5023, 0.5080, 0.5231, 0.4963, 0.5312,\n",
      "         0.4898, 0.4862, 0.5136, 0.5299, 0.5216, 0.4837]], device='cuda:0')\n",
      "pred = tensor([[0.4866, 0.4819, 0.4900, 0.5052, 0.5162, 0.5166, 0.4714, 0.4966, 0.5180,\n",
      "         0.5072, 0.5163, 0.4981, 0.4911, 0.5099, 0.4785, 0.4861, 0.5069, 0.5327,\n",
      "         0.4914, 0.5171, 0.4962, 0.5047, 0.4918, 0.4957, 0.5152, 0.4862, 0.5233,\n",
      "         0.4860, 0.4793, 0.5038, 0.5204, 0.5127, 0.4793],\n",
      "        [0.4911, 0.4877, 0.4939, 0.5096, 0.5206, 0.5204, 0.4770, 0.5041, 0.5245,\n",
      "         0.5143, 0.5231, 0.5023, 0.4938, 0.5187, 0.4867, 0.4958, 0.5127, 0.5346,\n",
      "         0.4976, 0.5223, 0.4986, 0.5089, 0.4969, 0.5033, 0.5203, 0.4919, 0.5277,\n",
      "         0.4889, 0.4840, 0.5088, 0.5271, 0.5184, 0.4819],\n",
      "        [0.4863, 0.4798, 0.4888, 0.5042, 0.5142, 0.5172, 0.4691, 0.4940, 0.5156,\n",
      "         0.5036, 0.5153, 0.4975, 0.4894, 0.5085, 0.4765, 0.4845, 0.5057, 0.5311,\n",
      "         0.4906, 0.5170, 0.4963, 0.5041, 0.4906, 0.4936, 0.5141, 0.4847, 0.5216,\n",
      "         0.4841, 0.4785, 0.5021, 0.5193, 0.5108, 0.4790],\n",
      "        [0.4874, 0.4830, 0.4909, 0.5061, 0.5178, 0.5169, 0.4733, 0.4980, 0.5197,\n",
      "         0.5094, 0.5179, 0.4994, 0.4915, 0.5112, 0.4801, 0.4897, 0.5079, 0.5326,\n",
      "         0.4935, 0.5188, 0.4963, 0.5049, 0.4940, 0.4965, 0.5159, 0.4867, 0.5245,\n",
      "         0.4856, 0.4801, 0.5042, 0.5215, 0.5137, 0.4798],\n",
      "        [0.4848, 0.4808, 0.4884, 0.5028, 0.5137, 0.5182, 0.4694, 0.4951, 0.5166,\n",
      "         0.5054, 0.5151, 0.4962, 0.4883, 0.5083, 0.4776, 0.4857, 0.5053, 0.5309,\n",
      "         0.4897, 0.5171, 0.4958, 0.5038, 0.4911, 0.4949, 0.5123, 0.4854, 0.5213,\n",
      "         0.4819, 0.4771, 0.5033, 0.5181, 0.5101, 0.4782],\n",
      "        [0.4839, 0.4773, 0.4866, 0.5010, 0.5118, 0.5153, 0.4659, 0.4908, 0.5123,\n",
      "         0.5002, 0.5120, 0.4941, 0.4879, 0.5042, 0.4729, 0.4797, 0.5030, 0.5299,\n",
      "         0.4861, 0.5153, 0.4950, 0.5029, 0.4869, 0.4910, 0.5112, 0.4825, 0.5196,\n",
      "         0.4825, 0.4760, 0.5002, 0.5163, 0.5077, 0.4768],\n",
      "        [0.4984, 0.4942, 0.5008, 0.5158, 0.5286, 0.5270, 0.4833, 0.5109, 0.5340,\n",
      "         0.5222, 0.5315, 0.5076, 0.4997, 0.5277, 0.4955, 0.5045, 0.5189, 0.5406,\n",
      "         0.5051, 0.5274, 0.5028, 0.5149, 0.5023, 0.5103, 0.5273, 0.4985, 0.5345,\n",
      "         0.4943, 0.4906, 0.5168, 0.5328, 0.5255, 0.4866],\n",
      "        [0.4801, 0.4719, 0.4826, 0.4983, 0.5077, 0.5108, 0.4616, 0.4856, 0.5063,\n",
      "         0.4950, 0.5068, 0.4919, 0.4846, 0.4982, 0.4662, 0.4740, 0.4980, 0.5255,\n",
      "         0.4826, 0.5122, 0.4927, 0.4987, 0.4840, 0.4845, 0.5070, 0.4766, 0.5154,\n",
      "         0.4794, 0.4724, 0.4944, 0.5122, 0.5039, 0.4745],\n",
      "        [0.4808, 0.4743, 0.4834, 0.4990, 0.5091, 0.5117, 0.4641, 0.4884, 0.5089,\n",
      "         0.4979, 0.5086, 0.4929, 0.4858, 0.5008, 0.4688, 0.4771, 0.4994, 0.5270,\n",
      "         0.4839, 0.5129, 0.4924, 0.4993, 0.4856, 0.4878, 0.5081, 0.4788, 0.5167,\n",
      "         0.4797, 0.4728, 0.4965, 0.5136, 0.5054, 0.4744],\n",
      "        [0.4817, 0.4747, 0.4842, 0.4993, 0.5088, 0.5120, 0.4638, 0.4882, 0.5083,\n",
      "         0.4975, 0.5084, 0.4925, 0.4863, 0.5013, 0.4688, 0.4771, 0.4998, 0.5273,\n",
      "         0.4833, 0.5133, 0.4932, 0.5005, 0.4849, 0.4878, 0.5087, 0.4794, 0.5171,\n",
      "         0.4803, 0.4738, 0.4967, 0.5140, 0.5054, 0.4749]], device='cuda:0')\n",
      "pred = tensor([[0.4952, 0.4929, 0.4992, 0.5139, 0.5265, 0.5243, 0.4823, 0.5104, 0.5320,\n",
      "         0.5216, 0.5288, 0.5059, 0.4978, 0.5250, 0.4939, 0.5030, 0.5171, 0.5389,\n",
      "         0.5030, 0.5252, 0.5015, 0.5126, 0.5023, 0.5086, 0.5248, 0.4968, 0.5324,\n",
      "         0.4923, 0.4884, 0.5146, 0.5312, 0.5237, 0.4847],\n",
      "        [0.4866, 0.4838, 0.4913, 0.5046, 0.5154, 0.5219, 0.4724, 0.4990, 0.5197,\n",
      "         0.5085, 0.5186, 0.4977, 0.4896, 0.5127, 0.4823, 0.4900, 0.5097, 0.5331,\n",
      "         0.4925, 0.5191, 0.4980, 0.5063, 0.4936, 0.4985, 0.5153, 0.4892, 0.5239,\n",
      "         0.4836, 0.4798, 0.5059, 0.5208, 0.5123, 0.4801],\n",
      "        [0.4860, 0.4806, 0.4895, 0.5045, 0.5158, 0.5160, 0.4707, 0.4953, 0.5174,\n",
      "         0.5059, 0.5157, 0.4978, 0.4902, 0.5084, 0.4771, 0.4857, 0.5059, 0.5320,\n",
      "         0.4911, 0.5172, 0.4955, 0.5034, 0.4918, 0.4944, 0.5145, 0.4846, 0.5226,\n",
      "         0.4848, 0.4785, 0.5027, 0.5198, 0.5117, 0.4789],\n",
      "        [0.4797, 0.4719, 0.4811, 0.4978, 0.5070, 0.5099, 0.4618, 0.4855, 0.5061,\n",
      "         0.4950, 0.5066, 0.4924, 0.4844, 0.4983, 0.4657, 0.4746, 0.4974, 0.5251,\n",
      "         0.4824, 0.5119, 0.4912, 0.4976, 0.4841, 0.4852, 0.5066, 0.4763, 0.5148,\n",
      "         0.4783, 0.4711, 0.4940, 0.5125, 0.5038, 0.4735],\n",
      "        [0.4841, 0.4769, 0.4860, 0.5025, 0.5135, 0.5112, 0.4674, 0.4909, 0.5123,\n",
      "         0.5021, 0.5112, 0.4958, 0.4888, 0.5033, 0.4717, 0.4803, 0.5012, 0.5287,\n",
      "         0.4872, 0.5142, 0.4937, 0.5013, 0.4880, 0.4895, 0.5112, 0.4804, 0.5199,\n",
      "         0.4828, 0.4758, 0.4989, 0.5163, 0.5089, 0.4766],\n",
      "        [0.4846, 0.4773, 0.4863, 0.5015, 0.5122, 0.5149, 0.4658, 0.4902, 0.5127,\n",
      "         0.5002, 0.5119, 0.4953, 0.4879, 0.5039, 0.4722, 0.4799, 0.5016, 0.5297,\n",
      "         0.4866, 0.5149, 0.4947, 0.5025, 0.4875, 0.4909, 0.5107, 0.4820, 0.5192,\n",
      "         0.4821, 0.4756, 0.5008, 0.5155, 0.5081, 0.4766],\n",
      "        [0.4896, 0.4874, 0.4943, 0.5083, 0.5192, 0.5223, 0.4758, 0.5029, 0.5238,\n",
      "         0.5130, 0.5217, 0.5008, 0.4938, 0.5174, 0.4860, 0.4937, 0.5126, 0.5358,\n",
      "         0.4956, 0.5207, 0.4990, 0.5087, 0.4956, 0.5019, 0.5193, 0.4920, 0.5270,\n",
      "         0.4878, 0.4833, 0.5090, 0.5247, 0.5167, 0.4817],\n",
      "        [0.4873, 0.4818, 0.4908, 0.5050, 0.5162, 0.5193, 0.4707, 0.4957, 0.5185,\n",
      "         0.5062, 0.5171, 0.4972, 0.4910, 0.5093, 0.4791, 0.4850, 0.5075, 0.5342,\n",
      "         0.4910, 0.5171, 0.4978, 0.5061, 0.4915, 0.4958, 0.5151, 0.4872, 0.5235,\n",
      "         0.4857, 0.4795, 0.5057, 0.5195, 0.5117, 0.4798],\n",
      "        [0.4951, 0.4942, 0.4993, 0.5147, 0.5277, 0.5242, 0.4846, 0.5127, 0.5342,\n",
      "         0.5247, 0.5300, 0.5074, 0.4978, 0.5266, 0.4955, 0.5065, 0.5182, 0.5388,\n",
      "         0.5052, 0.5265, 0.5009, 0.5117, 0.5048, 0.5103, 0.5252, 0.4972, 0.5334,\n",
      "         0.4917, 0.4885, 0.5149, 0.5329, 0.5249, 0.4851],\n",
      "        [0.4845, 0.4791, 0.4874, 0.5029, 0.5145, 0.5145, 0.4696, 0.4939, 0.5153,\n",
      "         0.5051, 0.5141, 0.4969, 0.4885, 0.5065, 0.4752, 0.4849, 0.5040, 0.5297,\n",
      "         0.4897, 0.5169, 0.4942, 0.5020, 0.4907, 0.4926, 0.5124, 0.4827, 0.5212,\n",
      "         0.4827, 0.4769, 0.5008, 0.5184, 0.5105, 0.4776]], device='cuda:0')\n",
      "pred = tensor([[0.4891, 0.4853, 0.4930, 0.5062, 0.5166, 0.5225, 0.4734, 0.5000, 0.5211,\n",
      "         0.5089, 0.5206, 0.4987, 0.4924, 0.5155, 0.4839, 0.4907, 0.5119, 0.5357,\n",
      "         0.4931, 0.5198, 0.4984, 0.5085, 0.4933, 0.5005, 0.5188, 0.4913, 0.5254,\n",
      "         0.4869, 0.4817, 0.5081, 0.5237, 0.5146, 0.4808],\n",
      "        [0.4894, 0.4849, 0.4929, 0.5071, 0.5179, 0.5216, 0.4735, 0.4998, 0.5213,\n",
      "         0.5090, 0.5202, 0.4996, 0.4925, 0.5151, 0.4832, 0.4907, 0.5100, 0.5346,\n",
      "         0.4937, 0.5201, 0.4986, 0.5081, 0.4934, 0.4999, 0.5181, 0.4902, 0.5255,\n",
      "         0.4867, 0.4822, 0.5080, 0.5228, 0.5148, 0.4806],\n",
      "        [0.4807, 0.4754, 0.4836, 0.4995, 0.5093, 0.5117, 0.4647, 0.4892, 0.5093,\n",
      "         0.4996, 0.5088, 0.4935, 0.4853, 0.5013, 0.4696, 0.4791, 0.4997, 0.5260,\n",
      "         0.4848, 0.5140, 0.4924, 0.4993, 0.4866, 0.4881, 0.5079, 0.4791, 0.5170,\n",
      "         0.4792, 0.4734, 0.4963, 0.5140, 0.5058, 0.4750],\n",
      "        [0.4956, 0.4921, 0.4983, 0.5129, 0.5256, 0.5248, 0.4808, 0.5076, 0.5304,\n",
      "         0.5191, 0.5277, 0.5051, 0.4974, 0.5231, 0.4919, 0.5006, 0.5159, 0.5396,\n",
      "         0.5016, 0.5242, 0.5012, 0.5128, 0.5004, 0.5073, 0.5240, 0.4963, 0.5317,\n",
      "         0.4918, 0.4876, 0.5150, 0.5294, 0.5221, 0.4847],\n",
      "        [0.4793, 0.4729, 0.4827, 0.4977, 0.5064, 0.5124, 0.4618, 0.4867, 0.5066,\n",
      "         0.4951, 0.5071, 0.4913, 0.4842, 0.4995, 0.4675, 0.4748, 0.4998, 0.5260,\n",
      "         0.4823, 0.5123, 0.4931, 0.4991, 0.4841, 0.4861, 0.5072, 0.4783, 0.5152,\n",
      "         0.4791, 0.4722, 0.4947, 0.5129, 0.5033, 0.4742],\n",
      "        [0.4795, 0.4721, 0.4821, 0.4984, 0.5078, 0.5090, 0.4622, 0.4857, 0.5062,\n",
      "         0.4953, 0.5060, 0.4921, 0.4852, 0.4979, 0.4657, 0.4733, 0.4979, 0.5256,\n",
      "         0.4823, 0.5115, 0.4919, 0.4978, 0.4837, 0.4849, 0.5070, 0.4762, 0.5155,\n",
      "         0.4800, 0.4722, 0.4933, 0.5125, 0.5039, 0.4742],\n",
      "        [0.4942, 0.4897, 0.4968, 0.5115, 0.5245, 0.5226, 0.4791, 0.5050, 0.5287,\n",
      "         0.5170, 0.5257, 0.5044, 0.4964, 0.5198, 0.4889, 0.4976, 0.5145, 0.5386,\n",
      "         0.5000, 0.5232, 0.5001, 0.5105, 0.4992, 0.5048, 0.5226, 0.4939, 0.5303,\n",
      "         0.4913, 0.4860, 0.5124, 0.5282, 0.5207, 0.4838],\n",
      "        [0.4785, 0.4712, 0.4805, 0.4975, 0.5065, 0.5083, 0.4610, 0.4847, 0.5050,\n",
      "         0.4942, 0.5050, 0.4920, 0.4840, 0.4968, 0.4646, 0.4730, 0.4964, 0.5236,\n",
      "         0.4816, 0.5113, 0.4909, 0.4965, 0.4833, 0.4836, 0.5057, 0.4748, 0.5143,\n",
      "         0.4781, 0.4710, 0.4917, 0.5116, 0.5029, 0.4735],\n",
      "        [0.4842, 0.4800, 0.4873, 0.5038, 0.5132, 0.5142, 0.4696, 0.4952, 0.5153,\n",
      "         0.5048, 0.5140, 0.4971, 0.4890, 0.5080, 0.4761, 0.4847, 0.5047, 0.5295,\n",
      "         0.4895, 0.5159, 0.4944, 0.5024, 0.4905, 0.4940, 0.5128, 0.4837, 0.5207,\n",
      "         0.4834, 0.4772, 0.5009, 0.5193, 0.5107, 0.4773],\n",
      "        [0.4878, 0.4824, 0.4901, 0.5055, 0.5168, 0.5179, 0.4714, 0.4965, 0.5191,\n",
      "         0.5070, 0.5173, 0.4986, 0.4912, 0.5102, 0.4791, 0.4873, 0.5061, 0.5332,\n",
      "         0.4917, 0.5178, 0.4960, 0.5052, 0.4925, 0.4960, 0.5152, 0.4861, 0.5234,\n",
      "         0.4845, 0.4794, 0.5051, 0.5203, 0.5127, 0.4794]], device='cuda:0')\n",
      "pred = tensor([[0.4896, 0.4834, 0.4917, 0.5073, 0.5186, 0.5180, 0.4726, 0.4978, 0.5205,\n",
      "         0.5082, 0.5187, 0.5003, 0.4932, 0.5120, 0.4803, 0.4876, 0.5083, 0.5347,\n",
      "         0.4934, 0.5184, 0.4972, 0.5063, 0.4930, 0.4972, 0.5176, 0.4874, 0.5251,\n",
      "         0.4880, 0.4814, 0.5054, 0.5223, 0.5146, 0.4808],\n",
      "        [0.4875, 0.4861, 0.4919, 0.5072, 0.5183, 0.5195, 0.4754, 0.5025, 0.5226,\n",
      "         0.5130, 0.5202, 0.5002, 0.4916, 0.5158, 0.4846, 0.4942, 0.5103, 0.5326,\n",
      "         0.4953, 0.5206, 0.4969, 0.5061, 0.4962, 0.5007, 0.5169, 0.4894, 0.5256,\n",
      "         0.4852, 0.4815, 0.5063, 0.5240, 0.5156, 0.4804],\n",
      "        [0.4842, 0.4783, 0.4868, 0.5017, 0.5128, 0.5141, 0.4676, 0.4916, 0.5134,\n",
      "         0.5028, 0.5123, 0.4956, 0.4887, 0.5047, 0.4731, 0.4823, 0.5030, 0.5300,\n",
      "         0.4877, 0.5159, 0.4941, 0.5021, 0.4890, 0.4913, 0.5114, 0.4824, 0.5203,\n",
      "         0.4826, 0.4760, 0.5003, 0.5169, 0.5091, 0.4772],\n",
      "        [0.4898, 0.4884, 0.4942, 0.5096, 0.5221, 0.5189, 0.4787, 0.5058, 0.5263,\n",
      "         0.5176, 0.5226, 0.5023, 0.4934, 0.5183, 0.4873, 0.4983, 0.5114, 0.5341,\n",
      "         0.4986, 0.5220, 0.4976, 0.5074, 0.4995, 0.5032, 0.5186, 0.4911, 0.5279,\n",
      "         0.4868, 0.4831, 0.5089, 0.5264, 0.5186, 0.4812],\n",
      "        [0.4918, 0.4860, 0.4938, 0.5086, 0.5213, 0.5213, 0.4757, 0.5006, 0.5242,\n",
      "         0.5113, 0.5220, 0.5024, 0.4944, 0.5156, 0.4841, 0.4923, 0.5105, 0.5370,\n",
      "         0.4964, 0.5203, 0.4982, 0.5084, 0.4960, 0.5008, 0.5198, 0.4902, 0.5273,\n",
      "         0.4882, 0.4830, 0.5097, 0.5242, 0.5170, 0.4818],\n",
      "        [0.4861, 0.4824, 0.4895, 0.5054, 0.5160, 0.5172, 0.4722, 0.4981, 0.5187,\n",
      "         0.5085, 0.5173, 0.4988, 0.4899, 0.5115, 0.4799, 0.4895, 0.5065, 0.5308,\n",
      "         0.4926, 0.5186, 0.4955, 0.5041, 0.4934, 0.4968, 0.5145, 0.4861, 0.5230,\n",
      "         0.4837, 0.4791, 0.5040, 0.5212, 0.5131, 0.4789],\n",
      "        [0.4831, 0.4735, 0.4835, 0.4997, 0.5093, 0.5110, 0.4627, 0.4854, 0.5080,\n",
      "         0.4954, 0.5079, 0.4934, 0.4877, 0.4992, 0.4666, 0.4730, 0.4995, 0.5290,\n",
      "         0.4831, 0.5117, 0.4931, 0.5005, 0.4835, 0.4855, 0.5095, 0.4785, 0.5166,\n",
      "         0.4824, 0.4736, 0.4962, 0.5133, 0.5051, 0.4758],\n",
      "        [0.4804, 0.4746, 0.4832, 0.5006, 0.5098, 0.5092, 0.4659, 0.4901, 0.5089,\n",
      "         0.4998, 0.5092, 0.4942, 0.4856, 0.5020, 0.4694, 0.4799, 0.4999, 0.5250,\n",
      "         0.4857, 0.5140, 0.4916, 0.4984, 0.4868, 0.4881, 0.5088, 0.4781, 0.5171,\n",
      "         0.4802, 0.4738, 0.4952, 0.5154, 0.5068, 0.4743],\n",
      "        [0.4926, 0.4932, 0.4985, 0.5108, 0.5219, 0.5276, 0.4793, 0.5084, 0.5295,\n",
      "         0.5188, 0.5264, 0.5025, 0.4960, 0.5235, 0.4929, 0.5010, 0.5174, 0.5388,\n",
      "         0.4991, 0.5245, 0.5018, 0.5129, 0.4995, 0.5078, 0.5225, 0.4979, 0.5303,\n",
      "         0.4892, 0.4869, 0.5147, 0.5284, 0.5201, 0.4841],\n",
      "        [0.4854, 0.4797, 0.4889, 0.5047, 0.5159, 0.5141, 0.4709, 0.4950, 0.5161,\n",
      "         0.5063, 0.5148, 0.4977, 0.4900, 0.5080, 0.4761, 0.4857, 0.5050, 0.5304,\n",
      "         0.4912, 0.5171, 0.4955, 0.5030, 0.4911, 0.4933, 0.5135, 0.4835, 0.5224,\n",
      "         0.4847, 0.4786, 0.5013, 0.5194, 0.5117, 0.4783]], device='cuda:0')\n",
      "pred = tensor([[0.4826, 0.4749, 0.4856, 0.5001, 0.5109, 0.5146, 0.4649, 0.4886, 0.5108,\n",
      "         0.4987, 0.5106, 0.4943, 0.4863, 0.5021, 0.4706, 0.4782, 0.5012, 0.5284,\n",
      "         0.4861, 0.5145, 0.4947, 0.5009, 0.4869, 0.4885, 0.5095, 0.4804, 0.5182,\n",
      "         0.4811, 0.4747, 0.4980, 0.5143, 0.5066, 0.4766],\n",
      "        [0.4920, 0.4900, 0.4964, 0.5094, 0.5213, 0.5257, 0.4773, 0.5046, 0.5270,\n",
      "         0.5152, 0.5244, 0.5019, 0.4943, 0.5200, 0.4892, 0.4971, 0.5143, 0.5377,\n",
      "         0.4979, 0.5229, 0.5005, 0.5109, 0.4976, 0.5050, 0.5207, 0.4948, 0.5288,\n",
      "         0.4883, 0.4848, 0.5127, 0.5259, 0.5182, 0.4832],\n",
      "        [0.4819, 0.4762, 0.4850, 0.5020, 0.5123, 0.5107, 0.4675, 0.4918, 0.5117,\n",
      "         0.5021, 0.5111, 0.4958, 0.4872, 0.5038, 0.4716, 0.4816, 0.5011, 0.5265,\n",
      "         0.4877, 0.5150, 0.4926, 0.4993, 0.4886, 0.4897, 0.5102, 0.4794, 0.5191,\n",
      "         0.4817, 0.4752, 0.4968, 0.5166, 0.5086, 0.4758],\n",
      "        [0.4908, 0.4915, 0.4966, 0.5107, 0.5213, 0.5243, 0.4794, 0.5085, 0.5282,\n",
      "         0.5187, 0.5250, 0.5026, 0.4943, 0.5226, 0.4912, 0.5010, 0.5156, 0.5359,\n",
      "         0.4994, 0.5238, 0.5001, 0.5102, 0.4998, 0.5065, 0.5209, 0.4953, 0.5290,\n",
      "         0.4879, 0.4855, 0.5117, 0.5280, 0.5198, 0.4830],\n",
      "        [0.4847, 0.4777, 0.4869, 0.5025, 0.5135, 0.5141, 0.4676, 0.4915, 0.5131,\n",
      "         0.5026, 0.5128, 0.4957, 0.4881, 0.5046, 0.4732, 0.4823, 0.5025, 0.5294,\n",
      "         0.4883, 0.5161, 0.4947, 0.5025, 0.4889, 0.4908, 0.5115, 0.4818, 0.5204,\n",
      "         0.4826, 0.4766, 0.5003, 0.5169, 0.5091, 0.4775],\n",
      "        [0.4866, 0.4820, 0.4899, 0.5053, 0.5168, 0.5169, 0.4720, 0.4973, 0.5194,\n",
      "         0.5080, 0.5170, 0.4991, 0.4911, 0.5104, 0.4792, 0.4874, 0.5074, 0.5325,\n",
      "         0.4922, 0.5178, 0.4958, 0.5039, 0.4930, 0.4962, 0.5156, 0.4859, 0.5235,\n",
      "         0.4855, 0.4791, 0.5034, 0.5213, 0.5132, 0.4795],\n",
      "        [0.4781, 0.4687, 0.4797, 0.4959, 0.5062, 0.5066, 0.4591, 0.4812, 0.5025,\n",
      "         0.4923, 0.5028, 0.4899, 0.4836, 0.4930, 0.4609, 0.4693, 0.4943, 0.5237,\n",
      "         0.4794, 0.5101, 0.4909, 0.4964, 0.4811, 0.4804, 0.5039, 0.4734, 0.5133,\n",
      "         0.4784, 0.4698, 0.4912, 0.5086, 0.5014, 0.4729],\n",
      "        [0.4812, 0.4707, 0.4826, 0.4989, 0.5081, 0.5116, 0.4613, 0.4840, 0.5059,\n",
      "         0.4934, 0.5074, 0.4921, 0.4847, 0.4979, 0.4656, 0.4720, 0.4988, 0.5264,\n",
      "         0.4833, 0.5118, 0.4942, 0.4996, 0.4831, 0.4839, 0.5075, 0.4772, 0.5155,\n",
      "         0.4808, 0.4728, 0.4945, 0.5118, 0.5034, 0.4753],\n",
      "        [0.4872, 0.4825, 0.4904, 0.5059, 0.5177, 0.5153, 0.4722, 0.4975, 0.5195,\n",
      "         0.5086, 0.5167, 0.4991, 0.4912, 0.5099, 0.4791, 0.4879, 0.5060, 0.5323,\n",
      "         0.4922, 0.5174, 0.4955, 0.5042, 0.4933, 0.4958, 0.5150, 0.4854, 0.5237,\n",
      "         0.4851, 0.4793, 0.5040, 0.5206, 0.5136, 0.4791],\n",
      "        [0.4819, 0.4783, 0.4860, 0.5020, 0.5117, 0.5128, 0.4683, 0.4936, 0.5128,\n",
      "         0.5038, 0.5118, 0.4949, 0.4875, 0.5055, 0.4736, 0.4833, 0.5033, 0.5281,\n",
      "         0.4877, 0.5153, 0.4935, 0.5009, 0.4893, 0.4914, 0.5106, 0.4818, 0.5195,\n",
      "         0.4816, 0.4757, 0.4984, 0.5172, 0.5085, 0.4763]], device='cuda:0')\n",
      "pred = tensor([[0.4832, 0.4778, 0.4869, 0.5036, 0.5140, 0.5131, 0.4697, 0.4938, 0.5143,\n",
      "         0.5050, 0.5134, 0.4969, 0.4878, 0.5066, 0.4746, 0.4850, 0.5034, 0.5278,\n",
      "         0.4906, 0.5167, 0.4942, 0.5009, 0.4907, 0.4919, 0.5115, 0.4816, 0.5207,\n",
      "         0.4824, 0.4769, 0.4992, 0.5183, 0.5103, 0.4776],\n",
      "        [0.4862, 0.4823, 0.4906, 0.5058, 0.5162, 0.5183, 0.4726, 0.4990, 0.5190,\n",
      "         0.5084, 0.5181, 0.4988, 0.4901, 0.5128, 0.4808, 0.4898, 0.5084, 0.5313,\n",
      "         0.4932, 0.5192, 0.4968, 0.5047, 0.4933, 0.4976, 0.5156, 0.4871, 0.5235,\n",
      "         0.4849, 0.4802, 0.5040, 0.5219, 0.5134, 0.4793],\n",
      "        [0.4814, 0.4766, 0.4852, 0.5006, 0.5107, 0.5123, 0.4664, 0.4909, 0.5110,\n",
      "         0.5016, 0.5100, 0.4938, 0.4867, 0.5030, 0.4714, 0.4803, 0.5016, 0.5276,\n",
      "         0.4860, 0.5143, 0.4935, 0.5005, 0.4875, 0.4896, 0.5092, 0.4806, 0.5184,\n",
      "         0.4810, 0.4745, 0.4978, 0.5153, 0.5071, 0.4758],\n",
      "        [0.4806, 0.4727, 0.4824, 0.4975, 0.5072, 0.5111, 0.4613, 0.4846, 0.5069,\n",
      "         0.4950, 0.5064, 0.4920, 0.4852, 0.4974, 0.4657, 0.4731, 0.4984, 0.5271,\n",
      "         0.4817, 0.5116, 0.4925, 0.4989, 0.4837, 0.4850, 0.5068, 0.4779, 0.5151,\n",
      "         0.4798, 0.4715, 0.4954, 0.5114, 0.5036, 0.4745],\n",
      "        [0.4829, 0.4760, 0.4852, 0.5017, 0.5125, 0.5108, 0.4668, 0.4901, 0.5112,\n",
      "         0.5011, 0.5105, 0.4958, 0.4880, 0.5026, 0.4706, 0.4798, 0.5009, 0.5279,\n",
      "         0.4871, 0.5146, 0.4931, 0.4999, 0.4877, 0.4888, 0.5105, 0.4794, 0.5191,\n",
      "         0.4826, 0.4756, 0.4971, 0.5161, 0.5083, 0.4765],\n",
      "        [0.4970, 0.4982, 0.5025, 0.5165, 0.5292, 0.5308, 0.4870, 0.5165, 0.5381,\n",
      "         0.5280, 0.5337, 0.5086, 0.4987, 0.5319, 0.5014, 0.5118, 0.5221, 0.5410,\n",
      "         0.5079, 0.5291, 0.5039, 0.5152, 0.5073, 0.5149, 0.5273, 0.5022, 0.5357,\n",
      "         0.4917, 0.4912, 0.5201, 0.5344, 0.5269, 0.4874],\n",
      "        [0.4928, 0.4879, 0.4953, 0.5103, 0.5218, 0.5221, 0.4767, 0.5028, 0.5253,\n",
      "         0.5132, 0.5237, 0.5031, 0.4950, 0.5185, 0.4865, 0.4945, 0.5132, 0.5372,\n",
      "         0.4981, 0.5219, 0.4997, 0.5097, 0.4968, 0.5027, 0.5216, 0.4923, 0.5284,\n",
      "         0.4903, 0.4850, 0.5100, 0.5268, 0.5185, 0.4831],\n",
      "        [0.4917, 0.4881, 0.4958, 0.5101, 0.5220, 0.5238, 0.4777, 0.5042, 0.5261,\n",
      "         0.5149, 0.5247, 0.5025, 0.4937, 0.5195, 0.4883, 0.4970, 0.5136, 0.5361,\n",
      "         0.4989, 0.5232, 0.5001, 0.5098, 0.4979, 0.5035, 0.5208, 0.4930, 0.5287,\n",
      "         0.4886, 0.4849, 0.5111, 0.5263, 0.5186, 0.4830],\n",
      "        [0.4844, 0.4781, 0.4871, 0.5030, 0.5132, 0.5140, 0.4681, 0.4924, 0.5142,\n",
      "         0.5024, 0.5131, 0.4965, 0.4886, 0.5054, 0.4738, 0.4821, 0.5037, 0.5301,\n",
      "         0.4887, 0.5153, 0.4944, 0.5018, 0.4897, 0.4915, 0.5124, 0.4822, 0.5202,\n",
      "         0.4831, 0.4765, 0.4997, 0.5178, 0.5093, 0.4776],\n",
      "        [0.4906, 0.4894, 0.4953, 0.5096, 0.5220, 0.5215, 0.4782, 0.5056, 0.5267,\n",
      "         0.5171, 0.5235, 0.5017, 0.4940, 0.5186, 0.4885, 0.4976, 0.5128, 0.5357,\n",
      "         0.4979, 0.5223, 0.4990, 0.5092, 0.4985, 0.5038, 0.5195, 0.4927, 0.5285,\n",
      "         0.4879, 0.4842, 0.5106, 0.5261, 0.5186, 0.4820]], device='cuda:0')\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(test_loader, model, criterion)\n",
    "\n",
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
