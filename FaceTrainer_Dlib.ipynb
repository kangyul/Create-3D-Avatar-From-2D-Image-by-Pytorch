{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Facial Recognition using PyTorch and OpenCV\n",
    "\n",
    "https://ritik12.medium.com/facial-recognition-using-pytorch-and-opencv-467c4e41d1f\n",
    "\n",
    "\n",
    "Machine Learning - Face Recognition CNN Pytorch.ipynb\n",
    "https://github.com/rubencg195/Pytorch-Tutorials/blob/master/Machine%20Learning%20-%20Face%20Recognition%20CNN%20Pytorch.ipynb\n",
    "\n",
    "\n",
    "\n",
    "Face Recognition Using Pytorch\n",
    "https://github.com/timesler/facenet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Landmarks Detection With PyTorch\n",
    "\n",
    "https://towardsdatascience.com/face-landmarks-detection-with-pytorch-4b4852f5e9c4\n",
    "\n",
    "\n",
    "\n",
    "다중입력 deep neural network\n",
    "https://rosenfelder.ai/multi-input-neural-network-pytorch/\n",
    "\n",
    "\n",
    "\n",
    "Understanding dimensions in PyTorch\n",
    "https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하기 \n",
    "https://github.com/deeplearningzerotoall/PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.init import *\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from FaceFeatureDataset import FaceFeatureDataset\n",
    "import dlib_index\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, F, C]: torch.Size([30, 2, 68])\n",
      "Shape of Tensor y: torch.Size([30, 33]) torch.float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "training_data = FaceFeatureDataset(\n",
    "    feature_file=\"./outimg/Train/facefeature.csv\", label_file=\"./Dataset/Train/csv/train.csv\")\n",
    "test_data = FaceFeatureDataset(\n",
    "    feature_file=\"./outimg/Test/facefeature.csv\", label_file=\"./Dataset/Test/csv/test.csv\")\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터 로드 확인\n",
    "for X, y in test_loader:\n",
    "    # N , Channel, H= width W = height\n",
    "    print(f\"Shape of X [N, F, C]: {X.shape}\")\n",
    "    print(f\"Shape of Tensor y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "n_total_steps = len(test_loader)\n",
    "\n",
    "plt.scatter(X[0][0], X[0][1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y[0])\n",
    "plt.show()\n",
    "\n",
    "# print(f'Traing dat length {n_total_steps}')\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=136, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Linear(in_features=64, out_features=33, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 33\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(68 * 2, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, num_classes),            \n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)        \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader : DataLoader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)        \n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('batch',  batch)\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.294740  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.274812  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.258624  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.230928  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.172697  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.081802  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.071895  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.040049  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.040252  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.033933  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.034047  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031372  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.032822  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031404  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.032359  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.033234  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029652  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031150  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031051  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029749  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031472  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030817  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030795  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031168  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031272  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030183  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030932  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030438  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029928  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030974  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030247  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030598  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029657  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031437  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031663  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030127  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030727  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031217  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030323  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030674  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030706  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029683  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031652  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029659  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029876  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030960  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028823  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030932  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029947  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030979  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030579  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030735  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.032448  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030846  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030321  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030354  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030533  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030797  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029899  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030383  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030519  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029155  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029755  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.032426  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029121  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030419  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029592  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030441  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030988  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030751  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029321  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031263  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031660  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030531  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030562  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029666  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029766  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030085  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029596  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030596  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030564  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031392  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030812  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030435  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029904  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030713  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030032  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029413  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029406  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031545  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030038  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030664  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031403  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031058  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030835  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029820  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029497  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030225  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031149  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030835  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029359  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029749  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029700  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031755  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030901  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030066  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030036  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029237  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031249  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031041  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030047  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030191  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029709  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029698  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029699  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030985  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031612  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030137  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030773  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029231  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030362  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031067  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029511  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031349  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030098  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029914  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028813  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030824  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030622  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029387  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028252  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029264  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029681  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028999  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030408  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029371  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031899  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030215  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030018  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029903  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029650  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030942  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030361  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.032227  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030450  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029368  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029588  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030477  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030498  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030815  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029547  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030911  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031659  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030295  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030623  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031166  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030135  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028815  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029757  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029960  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029095  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031041  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031453  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029506  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030198  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029320  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030841  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030810  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030166  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029836  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029750  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029906  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030735  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029685  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030866  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030762  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028989  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028313  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029940  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030097  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029496  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030423  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028893  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029999  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030428  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028916  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029304  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029549  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028962  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030613  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029101  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029217  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028647  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030535  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029459  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029337  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030587  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030406  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029161  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028636  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029563  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030222  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028297  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029246  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029377  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030880  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029328  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028963  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030353  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029015  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029571  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029640  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030192  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028085  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028473  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028416  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029226  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029403  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027919  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027857  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030182  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028613  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030385  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030665  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029313  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029420  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030068  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029201  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028934  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028642  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028754  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028545  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029009  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029533  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029338  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029001  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030185  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029293  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028767  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027453  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028572  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030070  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028931  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029086  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029603  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027854  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028563  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029334  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029742  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028706  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028833  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029778  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029643  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029434  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029494  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029143  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029596  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029376  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028500  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027817  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029058  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029014  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029068  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027509  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028800  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029712  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027685  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029184  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027619  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029541  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029085  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029090  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027562  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029408  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028089  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029211  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027812  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027969  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027949  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028551  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028423  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029974  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029006  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029882  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028361  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.031091  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029621  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028217  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029552  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028624  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028544  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029465  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027967  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028054  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029213  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029362  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030141  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029319  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028513  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028307  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028394  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029583  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028285  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028469  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028633  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027782  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027619  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028407  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028239  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028435  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029838  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027688  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029632  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028504  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029907  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027419  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027110  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029256  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028417  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028549  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029051  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029409  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027107  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027846  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029438  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028440  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028434  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029919  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027854  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028948  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027945  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028453  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028168  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029347  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029084  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028620  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029695  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028275  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030453  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028815  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030406  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029711  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028742  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030778  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029085  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029452  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028813  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029185  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029573  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030045  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027791  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028458  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028670  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028973  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027732  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029019  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029059  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028725  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027892  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028798  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028847  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027686  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027745  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029260  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028518  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028584  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029234  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028306  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028526  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027674  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029985  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029576  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027765  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028442  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028208  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027763  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028275  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027203  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027864  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029671  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028955  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028616  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027579  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027625  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029068  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028981  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028784  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027555  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027856  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026202  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027788  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029679  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028662  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028098  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027888  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027220  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027579  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028101  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029102  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028541  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026760  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026635  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026801  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028865  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028199  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028294  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028286  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028329  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027990  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028431  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026389  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028788  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027890  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029789  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028849  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028609  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027669  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028064  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027076  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027978  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027755  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027265  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028080  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027641  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028312  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029418  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027271  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027599  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027983  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027209  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.030576  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027437  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029322  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028316  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028949  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028647  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028219  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028961  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027783  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029214  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028324  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028467  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026216  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026855  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029285  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027646  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028308  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026917  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027890  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028508  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027942  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028777  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028169  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028551  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028977  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028509  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029020  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026968  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026420  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026631  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025954  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026812  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027962  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028711  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029334  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028542  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028744  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028201  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028244  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027596  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027707  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027284  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027570  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026399  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028200  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027267  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025979  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027056  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028431  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027645  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027073  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027925  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027845  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027558  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027558  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027880  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028898  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028332  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028293  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026763  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027551  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026324  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027557  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026666  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025312  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027321  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026867  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.029343  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028126  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027009  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028334  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027676  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025639  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026523  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027421  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026802  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026783  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028323  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026886  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027782  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028657  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027198  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027066  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027583  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025359  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025464  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026087  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026194  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025327  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026647  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027362  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026266  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026757  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026788  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027342  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026882  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024460  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024830  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026851  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025863  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025002  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026163  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025300  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025587  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025281  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026683  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.028017  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025847  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026383  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025931  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025875  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026312  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026168  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027341  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027651  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027340  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027177  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026261  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026320  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025803  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025717  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026446  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026032  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026739  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025748  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025947  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026027  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024505  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026579  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026627  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025023  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026008  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027085  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024608  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025072  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024828  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025091  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024130  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026452  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027109  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025127  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.027409  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026361  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025046  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024882  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025393  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025623  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024324  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025268  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026641  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024044  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024397  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024278  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026084  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024037  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.026698  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025285  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023132  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025109  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025358  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025447  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023806  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023969  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024747  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025262  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025292  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024007  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023153  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023499  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024433  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023759  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024791  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022345  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023764  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025589  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025986  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024824  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023302  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021385  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025206  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023729  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025206  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022517  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023021  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023948  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024534  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023228  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023340  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022317  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025465  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023496  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.025785  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022243  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024551  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023736  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024567  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023822  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022903  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023104  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023194  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022908  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021885  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021657  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022711  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022295  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022966  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022601  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024573  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021527  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023860  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024358  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023626  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023219  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022144  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023254  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023228  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023245  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023662  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022789  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023472  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022269  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023371  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024810  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024586  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022813  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021410  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022928  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023586  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022306  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022835  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022390  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024026  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023459  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024480  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022724  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023184  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024047  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024676  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023661  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024075  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022262  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021906  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022101  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020827  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022075  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023442  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023230  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022499  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021734  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022727  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021748  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022345  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021282  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.024107  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021061  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023303  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021235  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022557  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022077  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022308  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022655  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022550  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022990  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022188  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023508  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022080  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023043  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021925  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019749  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021839  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022327  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022914  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020482  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021568  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021659  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022528  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.023114  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022812  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021065  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020600  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022079  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020613  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018519  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021702  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021135  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020206  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020360  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020741  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019481  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021599  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022115  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020849  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019088  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020412  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021521  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020536  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022201  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021185  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021424  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021824  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020471  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020582  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018975  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021317  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021141  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020499  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019878  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020949  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022049  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021308  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021280  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021199  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022096  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021045  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020669  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021906  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021311  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017963  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022329  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020189  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021870  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020753  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021289  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020892  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020059  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020390  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021231  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020333  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019051  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020713  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019042  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018873  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021539  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020444  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021091  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021721  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022072  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020080  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021609  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020247  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020572  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019552  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018890  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018954  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019796  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.022114  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020404  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020782  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021266  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019973  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020470  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019160  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018032  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019912  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018555  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020625  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019642  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018109  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018762  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019591  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019705  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020446  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017257  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016917  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015950  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017040  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018802  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018567  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017314  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018617  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018478  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017529  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021158  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019204  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019414  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019769  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019108  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018187  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017658  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017391  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016611  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017881  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.021791  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017072  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017521  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.020976  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018925  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019626  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017495  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017809  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018804  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019605  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018588  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019966  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019406  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017680  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017169  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017133  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019103  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017342  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019081  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019331  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017637  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017036  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019662  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017904  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018321  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018246  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016488  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018312  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017780  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016555  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018270  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018133  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017761  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017400  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016817  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017946  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017427  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014908  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018608  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017756  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018570  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017007  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016264  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015585  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017197  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017505  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018785  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014850  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018305  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016439  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017106  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018090  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017476  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018415  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016987  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016988  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018281  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018033  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016545  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016232  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015588  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016443  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017444  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.019037  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018410  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017539  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017618  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018396  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017441  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018362  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016123  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016215  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017813  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015942  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015356  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015890  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017285  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016504  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017417  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014225  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017459  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016388  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016008  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018004  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015566  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016555  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016522  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016128  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016080  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014867  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016351  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015414  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013261  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016569  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017553  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015677  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017580  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016028  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017088  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016259  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014338  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016028  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014467  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014824  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017329  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015827  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013640  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015944  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016481  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016059  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016535  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015376  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015030  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014362  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015564  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016213  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014499  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014518  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015323  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015286  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015155  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016773  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015728  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015988  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015514  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015797  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015955  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015572  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015318  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014264  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016090  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018586  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017650  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017741  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.018770  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015591  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017052  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016764  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015972  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.017373  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015744  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014447  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015173  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012870  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013875  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016287  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016561  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.011561  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013855  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016248  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013382  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015092  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.011808  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014156  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013098  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015007  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015524  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015401  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016201  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013412  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014326  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014965  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015098  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013973  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015228  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014475  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012088  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014345  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.016701  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015269  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012996  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013205  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012419  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013869  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012414  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015019  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014984  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015395  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013179  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012561  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012275  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012567  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.014623  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013716  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.015612  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012274  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.012786  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "batch 0\n",
      "loss: 0.013055  [    0/  100]\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight tensor([[-0.0484, -0.0562, -0.0226,  ..., -0.0224,  0.0375,  0.0740],\n",
      "        [ 0.0219,  0.0469,  0.0417,  ...,  0.0332, -0.0734,  0.0275],\n",
      "        [-0.0286, -0.1105, -0.0183,  ..., -0.1089, -0.0743, -0.0335],\n",
      "        ...,\n",
      "        [-0.0663,  0.0653, -0.0503,  ..., -0.0393, -0.0163,  0.0058],\n",
      "        [ 0.0359, -0.0553, -0.0008,  ..., -0.0458, -0.0026, -0.0927],\n",
      "        [-0.0501, -0.0205,  0.0401,  ...,  0.0662,  0.0781,  0.0895]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.0.bias tensor([-0.0652, -0.0577,  0.0725,  0.0392, -0.0701,  0.0403,  0.0790, -0.0243,\n",
      "        -0.0758, -0.0579, -0.0436,  0.0372, -0.0426,  0.0678,  0.0418,  0.0723,\n",
      "         0.0058, -0.0633, -0.1307,  0.0507,  0.0627, -0.0888,  0.0627, -0.0935,\n",
      "         0.0669,  0.0520,  0.0205, -0.0469, -0.0581,  0.0901,  0.0687,  0.0235,\n",
      "         0.0488,  0.0377, -0.0416, -0.0393,  0.0315,  0.0832, -0.0913,  0.1018,\n",
      "         0.0796, -0.0869, -0.1043,  0.0675,  0.0630,  0.0555, -0.0063,  0.0559,\n",
      "         0.0253,  0.0874, -0.0839, -0.0866,  0.0582, -0.0211, -0.0408,  0.1035,\n",
      "         0.0658,  0.0337, -0.0068, -0.0319,  0.0579, -0.0854, -0.0006, -0.0495,\n",
      "        -0.0186, -0.0169,  0.0224,  0.0586, -0.1027, -0.0415,  0.0247, -0.1067,\n",
      "        -0.0527, -0.0255, -0.0977, -0.0171, -0.0953, -0.0128,  0.0005,  0.0753,\n",
      "         0.0710, -0.0407,  0.0863,  0.0716, -0.0794, -0.0769,  0.0311, -0.0188,\n",
      "         0.0604, -0.0908, -0.0265,  0.0310,  0.0376,  0.0378,  0.0280, -0.0063,\n",
      "         0.0541, -0.0503,  0.0043, -0.0863,  0.0170, -0.0507, -0.0343, -0.0135,\n",
      "         0.0019, -0.0926,  0.0675, -0.0725, -0.0389, -0.1085,  0.0580,  0.0219,\n",
      "         0.0156,  0.0547,  0.0643,  0.0156, -0.0168, -0.0597,  0.0253, -0.0414,\n",
      "        -0.0631, -0.1240, -0.0399,  0.0357,  0.0137,  0.0693,  0.0902,  0.0061],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.2.weight tensor([[-0.0782, -0.0523,  0.0517,  ...,  0.0482,  0.0390, -0.0620],\n",
      "        [-0.1246, -0.0524, -0.0979,  ...,  0.1149,  0.0642,  0.1538],\n",
      "        [-0.0407, -0.0388, -0.0250,  ...,  0.1374,  0.0779, -0.0158],\n",
      "        ...,\n",
      "        [ 0.0071, -0.1029,  0.0885,  ..., -0.1865, -0.0531, -0.0723],\n",
      "        [-0.0180, -0.0652, -0.0336,  ..., -0.0204,  0.0393, -0.0846],\n",
      "        [ 0.0412, -0.1022,  0.0612,  ...,  0.1047,  0.1010, -0.0483]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.2.bias tensor([ 0.0711,  0.0877,  0.0764, -0.0543,  0.0181, -0.0214, -0.1160,  0.1466,\n",
      "        -0.0204,  0.0202, -0.0114,  0.0915,  0.1265,  0.0840, -0.0365,  0.0013,\n",
      "        -0.1115,  0.0060,  0.0814,  0.0391,  0.0537,  0.0540, -0.0107,  0.0908,\n",
      "        -0.0864,  0.0584, -0.1188, -0.0691, -0.0491, -0.0470,  0.0341,  0.0638,\n",
      "        -0.0078, -0.1005,  0.1037, -0.0955, -0.0601,  0.0721,  0.0415,  0.0735,\n",
      "        -0.0657,  0.1129, -0.1027, -0.0566, -0.0155,  0.1048,  0.0704,  0.0051,\n",
      "         0.0420, -0.0023, -0.0009, -0.0537,  0.1107, -0.0759, -0.0259,  0.1250,\n",
      "         0.1296, -0.1309,  0.0397,  0.1128,  0.0265,  0.0657,  0.0318,  0.0091,\n",
      "        -0.1060,  0.1318,  0.0347, -0.1135, -0.0196,  0.0074, -0.1153,  0.0122,\n",
      "        -0.0199,  0.0451, -0.0810, -0.0475, -0.0232, -0.0947, -0.0699,  0.1205,\n",
      "         0.0550, -0.0931,  0.0291, -0.0738,  0.0876, -0.0674,  0.0185, -0.0748,\n",
      "        -0.1199,  0.1192, -0.0626, -0.0308,  0.1126,  0.0654,  0.0858,  0.0780,\n",
      "        -0.0842,  0.0219,  0.1103, -0.0906, -0.0384, -0.1180,  0.0704, -0.1278,\n",
      "        -0.0027,  0.0120,  0.0778,  0.1219,  0.1013, -0.0726, -0.0689, -0.0256,\n",
      "        -0.1216, -0.0530,  0.0514, -0.0045, -0.0700, -0.0333, -0.0182, -0.0729,\n",
      "         0.0810, -0.0868,  0.0609,  0.0066, -0.0638, -0.0099,  0.0464,  0.0967],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.4.weight tensor([[ 0.0456, -0.1545, -0.0230,  ..., -0.0232, -0.0239, -0.0167],\n",
      "        [-0.0077,  0.1743,  0.0993,  ..., -0.0754,  0.0771, -0.0892],\n",
      "        [-0.0230,  0.0513, -0.0283,  ...,  0.1677,  0.0813, -0.0506],\n",
      "        ...,\n",
      "        [-0.0155, -0.0476,  0.0080,  ...,  0.0034, -0.0285,  0.0570],\n",
      "        [ 0.0193,  0.0222, -0.0477,  ...,  0.1492,  0.0640,  0.0553],\n",
      "        [ 0.0042,  0.2575,  0.1023,  ..., -0.0658, -0.0142, -0.1173]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.4.bias tensor([-0.1153,  0.0533, -0.0413,  0.1223,  0.1607,  0.0348, -0.1032, -0.1417,\n",
      "        -0.0831,  0.0978, -0.1013, -0.0244, -0.0029,  0.0701,  0.0332,  0.0438,\n",
      "         0.0427, -0.0034, -0.0231, -0.1428,  0.0505,  0.0790, -0.0115,  0.0599,\n",
      "         0.1217,  0.0400,  0.0416, -0.1645, -0.0103, -0.0920,  0.0901,  0.0312,\n",
      "        -0.0263,  0.1011,  0.0479,  0.1649, -0.0312,  0.1534,  0.0344,  0.0058,\n",
      "         0.1309,  0.1890, -0.0277,  0.0287, -0.0031, -0.0259,  0.0681,  0.0284,\n",
      "         0.0009,  0.0744, -0.0055, -0.0037, -0.1058, -0.0777, -0.0495, -0.0571,\n",
      "         0.0703, -0.0088,  0.0957,  0.0619, -0.0750, -0.0133,  0.1140, -0.0103],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.6.weight tensor([[ 0.0498, -0.0138, -0.1067,  ..., -0.0956, -0.1069,  0.0060],\n",
      "        [ 0.0525, -0.0209, -0.0127,  ...,  0.0749,  0.1134, -0.0968],\n",
      "        [ 0.0797, -0.2193,  0.0911,  ..., -0.0237, -0.0507, -0.3182],\n",
      "        ...,\n",
      "        [ 0.0924,  0.0349, -0.0137,  ...,  0.0388,  0.0442,  0.1421],\n",
      "        [-0.0737,  0.1042, -0.0180,  ...,  0.0501, -0.0757,  0.0565],\n",
      "        [-0.1159,  0.0362,  0.1571,  ..., -0.0746,  0.0730, -0.0370]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.6.bias tensor([-0.1154, -0.0058,  0.1320,  0.0577, -0.0561,  0.0048, -0.1307,  0.1259,\n",
      "        -0.1020,  0.1487,  0.1168,  0.0186, -0.0585,  0.2135, -0.0823, -0.1162,\n",
      "         0.1058, -0.0652,  0.1057,  0.1532,  0.1089,  0.1070, -0.1469, -0.0433,\n",
      "         0.1391,  0.1064,  0.0014,  0.0414,  0.1257,  0.0162, -0.1627,  0.0838,\n",
      "         0.1962, -0.1146, -0.1195, -0.0994,  0.1615, -0.1588, -0.1165,  0.1991,\n",
      "         0.1594,  0.0784, -0.0870,  0.1396,  0.0591,  0.0324,  0.0134, -0.0664,\n",
      "         0.0572, -0.1833,  0.1325, -0.1756, -0.1026,  0.1209, -0.0382,  0.1182,\n",
      "        -0.0228,  0.1383, -0.2095, -0.2275, -0.1593,  0.0799,  0.0387,  0.1431],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.8.weight tensor([[-0.1073, -0.0082,  0.1063,  ...,  0.0653, -0.1070,  0.0807],\n",
      "        [-0.1193,  0.1129,  0.0857,  ..., -0.0643,  0.1192, -0.0673],\n",
      "        [ 0.0424, -0.1121, -0.0274,  ...,  0.0140, -0.0304, -0.0303],\n",
      "        ...,\n",
      "        [-0.0826, -0.1364,  0.1389,  ...,  0.1169, -0.3752, -0.0707],\n",
      "        [ 0.0952, -0.0814,  0.2096,  ..., -0.1020, -0.1308, -0.1019],\n",
      "        [-0.1243,  0.1226, -0.0116,  ...,  0.0351, -0.0403, -0.0312]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.8.bias tensor([ 0.1166,  0.1501, -0.2145, -0.1398,  0.1881,  0.0655, -0.0049, -0.1193,\n",
      "         0.0153, -0.0478, -0.1304,  0.1298, -0.0954,  0.1157,  0.1196, -0.1253,\n",
      "        -0.1023,  0.0910,  0.1262, -0.1284,  0.0184, -0.0389, -0.1026,  0.0556,\n",
      "         0.0385,  0.1483,  0.1154,  0.0846,  0.1248, -0.0431, -0.1850, -0.0603,\n",
      "         0.0465,  0.0134,  0.1686,  0.1506, -0.0121, -0.1644,  0.0927, -0.0443,\n",
      "         0.0035, -0.1846,  0.0318,  0.0481,  0.1110, -0.0613, -0.0695, -0.0031,\n",
      "         0.0064,  0.0626, -0.0951, -0.0852,  0.0483, -0.1570, -0.0344, -0.0865,\n",
      "         0.0634,  0.0092,  0.1260, -0.1620,  0.0745,  0.0376, -0.1444,  0.1201],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.10.weight tensor([[ 0.1856,  0.1672, -0.1465,  ..., -0.3189,  0.0494, -0.1004],\n",
      "        [-0.0136, -0.0454, -0.0607,  ...,  0.3814, -0.1696,  0.0439],\n",
      "        [-0.0250,  0.1270,  0.1268,  ...,  0.0543,  0.0856,  0.0580],\n",
      "        ...,\n",
      "        [-0.0205,  0.0034, -0.1136,  ...,  0.0576,  0.1338,  0.1670],\n",
      "        [ 0.1541,  0.0285,  0.0838,  ...,  0.0012, -0.0716,  0.0163],\n",
      "        [-0.0630,  0.0566, -0.1716,  ...,  0.3350,  0.0212,  0.1832]],\n",
      "       device='cuda:0')\n",
      "linear_relu_stack.10.bias tensor([ 0.1366, -0.0505,  0.0933, -0.0518,  0.0756,  0.1219,  0.0334,  0.0557,\n",
      "        -0.0473,  0.0209, -0.0229,  0.0031,  0.0247, -0.0821, -0.0245, -0.0216,\n",
      "         0.1432, -0.0338,  0.1047, -0.0265,  0.0135, -0.0476,  0.0045,  0.1089,\n",
      "         0.0392,  0.0984,  0.1162,  0.0767,  0.0912,  0.0545, -0.0200,  0.0909,\n",
      "         0.1092], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader : DataLoader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print('test size', size, 'batch size :', dataloader.batch_size)\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)            \n",
    "            #print('pred =', pred)\n",
    "            #print('loss', loss)\n",
    "            #print('real', y)\n",
    "        print('pred :', pred[0])\n",
    "        print('real :', y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size 100 batch size : 30\n",
      "pred : tensor([0.6170, 0.5245, 0.3868, 0.5426, 0.5430, 0.5537, 0.5109, 0.4923, 0.4712,\n",
      "        0.2857, 0.6090, 0.4989, 0.5896, 0.4065, 0.3267, 0.3473, 0.5412, 0.4717,\n",
      "        0.4903, 0.6335, 0.4435, 0.5082, 0.3117, 0.5230, 0.4603, 0.5448, 0.3602,\n",
      "        0.4894, 0.4699, 0.6290, 0.3143, 0.5441, 0.3552], device='cuda:0')\n",
      "real : tensor([0.5443, 0.6617, 0.3433, 0.3282, 0.5710, 0.3587, 0.2824, 0.6020, 0.3589,\n",
      "        0.5217, 0.5342, 0.4075, 0.5104, 0.4524, 0.2554, 0.6097, 0.7619, 0.4054,\n",
      "        0.5712, 0.7425, 0.3372, 0.2125, 0.5214, 0.2131, 0.6711, 0.2132, 0.7441,\n",
      "        0.3801, 0.2628, 0.7938, 0.2873, 0.5116, 0.7034], device='cuda:0')\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(test_loader, model, criterion)\n",
    "\n",
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
