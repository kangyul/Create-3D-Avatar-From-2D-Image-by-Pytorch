{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from FaceFeatureDataset import FaceFeatureDataset\n",
    "import dlib_index as DI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10154363 -0.1885906 ]\n",
      " [ 0.14489932 -0.22053692]\n",
      " [ 0.19510067 -0.22281879]\n",
      " [ 0.2361745  -0.20456375]\n",
      " [ 0.19966443 -0.18174496]\n",
      " [ 0.14946309 -0.17946309]]\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('./outimg/Train/facefeature.csv')\n",
    "features = features.iloc[0, 1:]\n",
    "features = np.array(features, dtype=np.float32).reshape(-1,2);\n",
    "features = np.take(features, DI.LEFT_EYE, axis=0)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, F, C]: torch.Size([10, 6, 2])\n",
      "Shape of Tensor y: torch.Size([10, 6]) torch.float32\n",
      "tensor([[[ 0.1025, -0.1928],\n",
      "         [ 0.1473, -0.2224],\n",
      "         [ 0.1969, -0.2204],\n",
      "         [ 0.2376, -0.1959],\n",
      "         [ 0.1994, -0.1777],\n",
      "         [ 0.1476, -0.1796]],\n",
      "\n",
      "        [[ 0.0966, -0.1891],\n",
      "         [ 0.1428, -0.2245],\n",
      "         [ 0.1972, -0.2272],\n",
      "         [ 0.2407, -0.2054],\n",
      "         [ 0.2026, -0.1755],\n",
      "         [ 0.1455, -0.1755]],\n",
      "\n",
      "        [[ 0.0978, -0.1902],\n",
      "         [ 0.1444, -0.2234],\n",
      "         [ 0.1960, -0.2256],\n",
      "         [ 0.2395, -0.1995],\n",
      "         [ 0.2008, -0.1792],\n",
      "         [ 0.1466, -0.1770]],\n",
      "\n",
      "        [[ 0.0986, -0.1896],\n",
      "         [ 0.1428, -0.2249],\n",
      "         [ 0.1949, -0.2245],\n",
      "         [ 0.2385, -0.1994],\n",
      "         [ 0.2000, -0.1751],\n",
      "         [ 0.1451, -0.1755]],\n",
      "\n",
      "        [[ 0.0955, -0.1905],\n",
      "         [ 0.1412, -0.2270],\n",
      "         [ 0.1997, -0.2288],\n",
      "         [ 0.2444, -0.2015],\n",
      "         [ 0.2041, -0.1729],\n",
      "         [ 0.1457, -0.1738]],\n",
      "\n",
      "        [[ 0.0984, -0.1923],\n",
      "         [ 0.1419, -0.2281],\n",
      "         [ 0.1981, -0.2281],\n",
      "         [ 0.2416, -0.2000],\n",
      "         [ 0.2032, -0.1744],\n",
      "         [ 0.1444, -0.1744]],\n",
      "\n",
      "        [[ 0.1034, -0.1931],\n",
      "         [ 0.1470, -0.2207],\n",
      "         [ 0.1953, -0.2230],\n",
      "         [ 0.2343, -0.2023],\n",
      "         [ 0.1999, -0.1793],\n",
      "         [ 0.1516, -0.1793]],\n",
      "\n",
      "        [[ 0.0988, -0.1926],\n",
      "         [ 0.1412, -0.2239],\n",
      "         [ 0.1939, -0.2235],\n",
      "         [ 0.2385, -0.2021],\n",
      "         [ 0.2015, -0.1787],\n",
      "         [ 0.1461, -0.1765]],\n",
      "\n",
      "        [[ 0.1024, -0.1905],\n",
      "         [ 0.1452, -0.2227],\n",
      "         [ 0.1952, -0.2223],\n",
      "         [ 0.2350, -0.1970],\n",
      "         [ 0.1998, -0.1773],\n",
      "         [ 0.1473, -0.1777]],\n",
      "\n",
      "        [[ 0.1028, -0.1893],\n",
      "         [ 0.1448, -0.2188],\n",
      "         [ 0.1957, -0.2205],\n",
      "         [ 0.2371, -0.2014],\n",
      "         [ 0.1998, -0.1811],\n",
      "         [ 0.1512, -0.1794]]]) tensor([[0.3821, 0.3561, 0.5069, 0.2600, 0.7989, 0.6207],\n",
      "        [0.3304, 0.5331, 0.7803, 0.5384, 0.3035, 0.2496],\n",
      "        [0.5108, 0.5348, 0.7025, 0.5166, 0.5192, 0.3039],\n",
      "        [0.2181, 0.4742, 0.4566, 0.4672, 0.2229, 0.2340],\n",
      "        [0.5943, 0.3064, 0.5900, 0.2871, 0.2520, 0.5415],\n",
      "        [0.7034, 0.7780, 0.2570, 0.2428, 0.5408, 0.4863],\n",
      "        [0.2566, 0.6503, 0.4683, 0.5607, 0.7035, 0.3049],\n",
      "        [0.3804, 0.3785, 0.4771, 0.3595, 0.3230, 0.5857],\n",
      "        [0.7563, 0.2697, 0.4761, 0.4098, 0.7811, 0.5632],\n",
      "        [0.5914, 0.6879, 0.6963, 0.6673, 0.7836, 0.3711]])\n"
     ]
    }
   ],
   "source": [
    "# 머리      headSize =0, headWidth = 1,\n",
    "# 이마      foreheadPosition= 2,foreheadSize = 3,\n",
    "# 턱        jawsPosition =4,jawsSize = 5,\n",
    "# 아래턱    chinPosition = 6,chinSize = 7,chinPronounced = 8,\n",
    "# 뺨        lowCheek = 9, cheekPosition = 10, cheekSize = 11,\n",
    "# 귀        earsPosition = 12, earsRotation =13, earsSize = 14\n",
    "# 눈        eyeSize = 15, eyePosition= 16, eyeDepth = 17, eyeRotation = 18, eyeDistance = 19, eyeSquint= 20,\n",
    "# 코        noseSize,nosePosition,noseFlatten,nosePronounced,noseWidth,noseBridge,noseCurve,noseInclination,\n",
    "# 입        mouthSize,mouthPosition,mouthPronounced,lipsSize\n",
    "\n",
    "#eyeIndexes = ['eyeSize', 'eyePosition', 'eyeDepth', 'eyeRotation', 'eyeDistance', 'eyeSquint']\n",
    "featureIndexes = DI.LEFT_EYE\n",
    "#eyeIndexes = list(range(15, 21))\n",
    "eyeIndexes = [15]\n",
    "\n",
    "training_data = FaceFeatureDataset(feature_file=\"./outimg/Train/facefeature.csv\", feature_indexes=featureIndexes,\n",
    "                                   label_file=\"./Dataset/Train/csv/train.csv\", label_indexes=eyeIndexes)\n",
    "test_data = FaceFeatureDataset(feature_file=\"./outimg/Test/facefeature.csv\", feature_indexes=featureIndexes,\n",
    "                               label_file=\"./Dataset/Test/csv/test.csv\", label_indexes=eyeIndexes)\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터 로드 확인\n",
    "for X, y in train_loader:\n",
    "    # N , Channel, H= width W = height\n",
    "    print(f\"Shape of X [N, F, C]: {X.shape}\")\n",
    "    print(f\"Shape of Tensor y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "print(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(eyeIndexes)\n",
    "print(num_classes)\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(12, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, num_classes),\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)        \n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('batch',  batch)\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.299201  [    0/  100]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.296234  [    0/  100]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.244715  [    0/  100]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.261374  [    0/  100]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.223051  [    0/  100]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.190582  [    0/  100]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.184771  [    0/  100]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.163282  [    0/  100]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.152263  [    0/  100]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.114833  [    0/  100]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.116991  [    0/  100]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.108413  [    0/  100]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.085754  [    0/  100]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.063937  [    0/  100]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.078284  [    0/  100]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.069007  [    0/  100]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.067824  [    0/  100]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.049673  [    0/  100]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.039404  [    0/  100]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.049033  [    0/  100]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.045131  [    0/  100]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.047974  [    0/  100]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.034038  [    0/  100]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.034136  [    0/  100]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.027874  [    0/  100]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.036541  [    0/  100]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.035735  [    0/  100]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.030294  [    0/  100]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.033089  [    0/  100]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.036217  [    0/  100]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.026368  [    0/  100]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.032480  [    0/  100]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.030620  [    0/  100]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.037154  [    0/  100]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.032600  [    0/  100]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.027607  [    0/  100]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.027014  [    0/  100]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.024630  [    0/  100]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.032496  [    0/  100]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.033753  [    0/  100]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.025794  [    0/  100]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.024785  [    0/  100]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.027863  [    0/  100]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.029983  [    0/  100]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.030313  [    0/  100]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.026387  [    0/  100]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.028203  [    0/  100]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.027409  [    0/  100]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.026783  [    0/  100]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.030530  [    0/  100]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.028641  [    0/  100]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.031884  [    0/  100]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.029739  [    0/  100]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.028922  [    0/  100]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.021710  [    0/  100]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.031342  [    0/  100]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.023955  [    0/  100]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.027826  [    0/  100]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.028910  [    0/  100]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.023133  [    0/  100]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.034353  [    0/  100]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.026943  [    0/  100]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.033721  [    0/  100]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.025899  [    0/  100]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.028977  [    0/  100]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.029868  [    0/  100]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.029022  [    0/  100]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.033416  [    0/  100]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.029839  [    0/  100]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.021465  [    0/  100]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.028936  [    0/  100]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.028293  [    0/  100]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.032243  [    0/  100]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.024767  [    0/  100]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.025643  [    0/  100]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.026349  [    0/  100]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.025591  [    0/  100]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.028440  [    0/  100]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.030369  [    0/  100]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.029464  [    0/  100]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.028226  [    0/  100]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.024582  [    0/  100]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.025558  [    0/  100]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.032535  [    0/  100]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.030633  [    0/  100]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.024596  [    0/  100]\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.025965  [    0/  100]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.028047  [    0/  100]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.026264  [    0/  100]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.034080  [    0/  100]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.021968  [    0/  100]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.025299  [    0/  100]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.026304  [    0/  100]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.028176  [    0/  100]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.027284  [    0/  100]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.024471  [    0/  100]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.022669  [    0/  100]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.035141  [    0/  100]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.030277  [    0/  100]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.030304  [    0/  100]\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.029469  [    0/  100]\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.026361  [    0/  100]\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.030870  [    0/  100]\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.026640  [    0/  100]\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.029015  [    0/  100]\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.032391  [    0/  100]\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.027643  [    0/  100]\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.026121  [    0/  100]\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.029455  [    0/  100]\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.024256  [    0/  100]\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.032742  [    0/  100]\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.024545  [    0/  100]\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.027953  [    0/  100]\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.030934  [    0/  100]\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.028534  [    0/  100]\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.028509  [    0/  100]\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.024923  [    0/  100]\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.027113  [    0/  100]\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.030825  [    0/  100]\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.025532  [    0/  100]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.023115  [    0/  100]\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.028100  [    0/  100]\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.024653  [    0/  100]\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.033902  [    0/  100]\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.027915  [    0/  100]\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.023751  [    0/  100]\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.029421  [    0/  100]\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.029657  [    0/  100]\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.032965  [    0/  100]\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.023201  [    0/  100]\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.033680  [    0/  100]\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.029676  [    0/  100]\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.026156  [    0/  100]\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.032835  [    0/  100]\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.024141  [    0/  100]\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.031160  [    0/  100]\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.028976  [    0/  100]\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.022569  [    0/  100]\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.029539  [    0/  100]\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.030558  [    0/  100]\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.031054  [    0/  100]\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.031359  [    0/  100]\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.024528  [    0/  100]\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.024200  [    0/  100]\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.020603  [    0/  100]\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.026554  [    0/  100]\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.028321  [    0/  100]\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.031461  [    0/  100]\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.024925  [    0/  100]\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.029745  [    0/  100]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.031669  [    0/  100]\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.022784  [    0/  100]\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.022637  [    0/  100]\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.026015  [    0/  100]\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.028865  [    0/  100]\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.023843  [    0/  100]\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.027931  [    0/  100]\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.027283  [    0/  100]\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.024738  [    0/  100]\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.022401  [    0/  100]\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.024909  [    0/  100]\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.029340  [    0/  100]\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.027575  [    0/  100]\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.026106  [    0/  100]\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.025333  [    0/  100]\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.031054  [    0/  100]\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.032217  [    0/  100]\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.031378  [    0/  100]\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.032455  [    0/  100]\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.025669  [    0/  100]\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.024797  [    0/  100]\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.026336  [    0/  100]\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.028599  [    0/  100]\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.028602  [    0/  100]\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.025621  [    0/  100]\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.032089  [    0/  100]\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.027046  [    0/  100]\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.022260  [    0/  100]\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.025238  [    0/  100]\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.024021  [    0/  100]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.027436  [    0/  100]\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.029860  [    0/  100]\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.027847  [    0/  100]\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.024809  [    0/  100]\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.026977  [    0/  100]\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.030687  [    0/  100]\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.024825  [    0/  100]\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.031812  [    0/  100]\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.026084  [    0/  100]\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.032873  [    0/  100]\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.024406  [    0/  100]\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.029625  [    0/  100]\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.028122  [    0/  100]\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.026728  [    0/  100]\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.026956  [    0/  100]\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.033200  [    0/  100]\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.026968  [    0/  100]\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.030598  [    0/  100]\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.024034  [    0/  100]\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.029213  [    0/  100]\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.024678  [    0/  100]\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.022803  [    0/  100]\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.028275  [    0/  100]\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.035654  [    0/  100]\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.025405  [    0/  100]\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.033537  [    0/  100]\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.027054  [    0/  100]\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.025004  [    0/  100]\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.023994  [    0/  100]\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.026319  [    0/  100]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.023082  [    0/  100]\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.028417  [    0/  100]\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.022282  [    0/  100]\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.028279  [    0/  100]\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.026759  [    0/  100]\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.030777  [    0/  100]\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.027907  [    0/  100]\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.029771  [    0/  100]\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.025961  [    0/  100]\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.025734  [    0/  100]\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.030394  [    0/  100]\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.028050  [    0/  100]\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.021962  [    0/  100]\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.025975  [    0/  100]\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.028225  [    0/  100]\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.027204  [    0/  100]\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.024105  [    0/  100]\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.031426  [    0/  100]\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.030763  [    0/  100]\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.031439  [    0/  100]\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.027372  [    0/  100]\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.029801  [    0/  100]\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.028743  [    0/  100]\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.029616  [    0/  100]\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.028864  [    0/  100]\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.029047  [    0/  100]\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.031721  [    0/  100]\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.022897  [    0/  100]\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.029733  [    0/  100]\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.027212  [    0/  100]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.028709  [    0/  100]\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.025901  [    0/  100]\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.029675  [    0/  100]\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.028616  [    0/  100]\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.038731  [    0/  100]\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.026979  [    0/  100]\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.023847  [    0/  100]\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.024560  [    0/  100]\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.028626  [    0/  100]\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.026422  [    0/  100]\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.027770  [    0/  100]\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.035858  [    0/  100]\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.029824  [    0/  100]\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.025743  [    0/  100]\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.025413  [    0/  100]\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.033176  [    0/  100]\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.032134  [    0/  100]\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.026355  [    0/  100]\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.030332  [    0/  100]\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.037250  [    0/  100]\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.025271  [    0/  100]\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.025362  [    0/  100]\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.028981  [    0/  100]\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.028037  [    0/  100]\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.024265  [    0/  100]\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.027811  [    0/  100]\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.024429  [    0/  100]\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.024346  [    0/  100]\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.023671  [    0/  100]\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.027416  [    0/  100]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.023266  [    0/  100]\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.031651  [    0/  100]\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.026850  [    0/  100]\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.035106  [    0/  100]\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.033035  [    0/  100]\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.027088  [    0/  100]\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.034734  [    0/  100]\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.029494  [    0/  100]\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.029955  [    0/  100]\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.023634  [    0/  100]\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.025098  [    0/  100]\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.025636  [    0/  100]\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.029864  [    0/  100]\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.024607  [    0/  100]\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.022994  [    0/  100]\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.029146  [    0/  100]\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.027413  [    0/  100]\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.027223  [    0/  100]\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.028273  [    0/  100]\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.024667  [    0/  100]\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.024864  [    0/  100]\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.032520  [    0/  100]\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.030601  [    0/  100]\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.024368  [    0/  100]\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.023521  [    0/  100]\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.028016  [    0/  100]\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.027071  [    0/  100]\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.031699  [    0/  100]\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.026697  [    0/  100]\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.023091  [    0/  100]\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.025363  [    0/  100]\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.027366  [    0/  100]\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.033885  [    0/  100]\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.024276  [    0/  100]\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.026608  [    0/  100]\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.028785  [    0/  100]\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.027881  [    0/  100]\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.025855  [    0/  100]\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.027432  [    0/  100]\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.026395  [    0/  100]\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.031083  [    0/  100]\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.024248  [    0/  100]\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.031365  [    0/  100]\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.025809  [    0/  100]\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.024815  [    0/  100]\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.033236  [    0/  100]\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.028236  [    0/  100]\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.027170  [    0/  100]\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.029060  [    0/  100]\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.027548  [    0/  100]\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.030013  [    0/  100]\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.026157  [    0/  100]\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.027436  [    0/  100]\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.024076  [    0/  100]\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.029560  [    0/  100]\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.031256  [    0/  100]\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.032354  [    0/  100]\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.025677  [    0/  100]\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.026466  [    0/  100]\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.031964  [    0/  100]\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.027623  [    0/  100]\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.025907  [    0/  100]\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.029023  [    0/  100]\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.027993  [    0/  100]\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.029380  [    0/  100]\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.025964  [    0/  100]\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.030455  [    0/  100]\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.026969  [    0/  100]\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.029982  [    0/  100]\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.035137  [    0/  100]\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.026369  [    0/  100]\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.029068  [    0/  100]\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.027166  [    0/  100]\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.031540  [    0/  100]\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.028224  [    0/  100]\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.024139  [    0/  100]\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.028229  [    0/  100]\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.024028  [    0/  100]\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.028301  [    0/  100]\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.028324  [    0/  100]\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.024860  [    0/  100]\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.031789  [    0/  100]\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.025464  [    0/  100]\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.030343  [    0/  100]\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.033380  [    0/  100]\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.027366  [    0/  100]\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.023162  [    0/  100]\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.031884  [    0/  100]\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.021384  [    0/  100]\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.025320  [    0/  100]\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.021310  [    0/  100]\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.034362  [    0/  100]\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.026983  [    0/  100]\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.030062  [    0/  100]\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.022200  [    0/  100]\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.040463  [    0/  100]\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.027335  [    0/  100]\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.026589  [    0/  100]\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.024999  [    0/  100]\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.024506  [    0/  100]\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.030689  [    0/  100]\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.030699  [    0/  100]\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.023267  [    0/  100]\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.026130  [    0/  100]\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.024176  [    0/  100]\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.022223  [    0/  100]\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.031196  [    0/  100]\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.026687  [    0/  100]\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.025223  [    0/  100]\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.023715  [    0/  100]\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.032271  [    0/  100]\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.025404  [    0/  100]\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.027443  [    0/  100]\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.029150  [    0/  100]\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.026724  [    0/  100]\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.027681  [    0/  100]\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.023646  [    0/  100]\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.028105  [    0/  100]\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.024495  [    0/  100]\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.031926  [    0/  100]\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.024047  [    0/  100]\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.029696  [    0/  100]\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.028225  [    0/  100]\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.021776  [    0/  100]\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.027762  [    0/  100]\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.030073  [    0/  100]\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.029311  [    0/  100]\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.027794  [    0/  100]\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.025109  [    0/  100]\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.025807  [    0/  100]\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.028407  [    0/  100]\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.033688  [    0/  100]\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.022543  [    0/  100]\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.029740  [    0/  100]\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.025645  [    0/  100]\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.029683  [    0/  100]\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.030673  [    0/  100]\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.033439  [    0/  100]\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.025600  [    0/  100]\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.027514  [    0/  100]\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.027254  [    0/  100]\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.027280  [    0/  100]\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.027385  [    0/  100]\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.029876  [    0/  100]\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.025312  [    0/  100]\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.031638  [    0/  100]\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.030746  [    0/  100]\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.028219  [    0/  100]\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.031391  [    0/  100]\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.021388  [    0/  100]\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.033885  [    0/  100]\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.026324  [    0/  100]\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.020077  [    0/  100]\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.030604  [    0/  100]\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.033449  [    0/  100]\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.027795  [    0/  100]\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.027318  [    0/  100]\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.027512  [    0/  100]\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.025761  [    0/  100]\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.025055  [    0/  100]\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.021926  [    0/  100]\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.029112  [    0/  100]\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.024045  [    0/  100]\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.027945  [    0/  100]\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.027464  [    0/  100]\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.023699  [    0/  100]\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.029531  [    0/  100]\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.027656  [    0/  100]\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.027645  [    0/  100]\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.028676  [    0/  100]\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.026555  [    0/  100]\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.027081  [    0/  100]\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.033436  [    0/  100]\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.025227  [    0/  100]\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.026886  [    0/  100]\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.029470  [    0/  100]\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.025923  [    0/  100]\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.027003  [    0/  100]\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.027487  [    0/  100]\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.032905  [    0/  100]\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.031869  [    0/  100]\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.031476  [    0/  100]\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.026009  [    0/  100]\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.030123  [    0/  100]\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.029444  [    0/  100]\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.029641  [    0/  100]\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.025121  [    0/  100]\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.026180  [    0/  100]\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.027460  [    0/  100]\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.033930  [    0/  100]\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.026695  [    0/  100]\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.029931  [    0/  100]\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.027215  [    0/  100]\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.031619  [    0/  100]\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.024935  [    0/  100]\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.026538  [    0/  100]\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.026284  [    0/  100]\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.032007  [    0/  100]\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.027534  [    0/  100]\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.028160  [    0/  100]\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.023063  [    0/  100]\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.031604  [    0/  100]\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.030387  [    0/  100]\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.020881  [    0/  100]\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.028011  [    0/  100]\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.023901  [    0/  100]\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.030447  [    0/  100]\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.031037  [    0/  100]\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.024326  [    0/  100]\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.027403  [    0/  100]\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.027508  [    0/  100]\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.042164  [    0/  100]\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.025938  [    0/  100]\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.027892  [    0/  100]\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.024409  [    0/  100]\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.022180  [    0/  100]\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.025299  [    0/  100]\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.026652  [    0/  100]\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.028236  [    0/  100]\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.022082  [    0/  100]\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.022630  [    0/  100]\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.029387  [    0/  100]\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.027804  [    0/  100]\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.026786  [    0/  100]\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.026996  [    0/  100]\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.025600  [    0/  100]\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.030627  [    0/  100]\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.024626  [    0/  100]\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.034742  [    0/  100]\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.020352  [    0/  100]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './face_eye.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print('test size', size )\n",
    "    # num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)            \n",
    "            print('pred =', pred)\n",
    "            #print('loss', loss)\n",
    "            #print('real', y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size 100\n",
      "pred = tensor([[0.4881, 0.5094, 0.5319, 0.4936, 0.5220, 0.4966],\n",
      "        [0.4874, 0.5092, 0.5315, 0.4931, 0.5216, 0.4963],\n",
      "        [0.4883, 0.5099, 0.5324, 0.4940, 0.5224, 0.4968],\n",
      "        [0.4884, 0.5097, 0.5321, 0.4937, 0.5220, 0.4966],\n",
      "        [0.4884, 0.5096, 0.5320, 0.4937, 0.5219, 0.4967],\n",
      "        [0.4872, 0.5094, 0.5316, 0.4933, 0.5220, 0.4964],\n",
      "        [0.4883, 0.5097, 0.5322, 0.4938, 0.5222, 0.4965],\n",
      "        [0.4874, 0.5093, 0.5316, 0.4934, 0.5220, 0.4964],\n",
      "        [0.4884, 0.5095, 0.5318, 0.4938, 0.5221, 0.4964],\n",
      "        [0.4872, 0.5095, 0.5317, 0.4933, 0.5222, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4886, 0.5092, 0.5315, 0.4936, 0.5215, 0.4962],\n",
      "        [0.4875, 0.5093, 0.5316, 0.4933, 0.5217, 0.4966],\n",
      "        [0.4881, 0.5095, 0.5319, 0.4935, 0.5218, 0.4965],\n",
      "        [0.4886, 0.5099, 0.5324, 0.4940, 0.5223, 0.4967],\n",
      "        [0.4882, 0.5095, 0.5318, 0.4937, 0.5221, 0.4965],\n",
      "        [0.4878, 0.5092, 0.5315, 0.4934, 0.5218, 0.4964],\n",
      "        [0.4882, 0.5092, 0.5316, 0.4936, 0.5217, 0.4964],\n",
      "        [0.4873, 0.5098, 0.5322, 0.4934, 0.5222, 0.4968],\n",
      "        [0.4871, 0.5095, 0.5317, 0.4934, 0.5223, 0.4966],\n",
      "        [0.4881, 0.5094, 0.5317, 0.4936, 0.5220, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4883, 0.5099, 0.5325, 0.4938, 0.5223, 0.4966],\n",
      "        [0.4871, 0.5096, 0.5317, 0.4933, 0.5223, 0.4966],\n",
      "        [0.4879, 0.5091, 0.5314, 0.4934, 0.5217, 0.4963],\n",
      "        [0.4877, 0.5095, 0.5319, 0.4932, 0.5218, 0.4965],\n",
      "        [0.4880, 0.5094, 0.5318, 0.4936, 0.5219, 0.4964],\n",
      "        [0.4875, 0.5097, 0.5319, 0.4935, 0.5223, 0.4967],\n",
      "        [0.4875, 0.5094, 0.5315, 0.4933, 0.5220, 0.4967],\n",
      "        [0.4871, 0.5092, 0.5314, 0.4931, 0.5220, 0.4963],\n",
      "        [0.4881, 0.5096, 0.5320, 0.4936, 0.5220, 0.4965],\n",
      "        [0.4879, 0.5094, 0.5318, 0.4935, 0.5218, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4876, 0.5092, 0.5315, 0.4934, 0.5220, 0.4965],\n",
      "        [0.4873, 0.5096, 0.5320, 0.4934, 0.5223, 0.4966],\n",
      "        [0.4884, 0.5096, 0.5321, 0.4937, 0.5219, 0.4967],\n",
      "        [0.4886, 0.5100, 0.5326, 0.4940, 0.5222, 0.4970],\n",
      "        [0.4876, 0.5098, 0.5322, 0.4933, 0.5221, 0.4966],\n",
      "        [0.4873, 0.5094, 0.5315, 0.4932, 0.5219, 0.4965],\n",
      "        [0.4885, 0.5096, 0.5319, 0.4936, 0.5218, 0.4966],\n",
      "        [0.4884, 0.5096, 0.5321, 0.4937, 0.5218, 0.4966],\n",
      "        [0.4887, 0.5094, 0.5318, 0.4936, 0.5216, 0.4965],\n",
      "        [0.4879, 0.5100, 0.5324, 0.4937, 0.5223, 0.4968]], device='cuda:0')\n",
      "pred = tensor([[0.4879, 0.5097, 0.5320, 0.4936, 0.5219, 0.4965],\n",
      "        [0.4892, 0.5095, 0.5322, 0.4942, 0.5219, 0.4964],\n",
      "        [0.4871, 0.5094, 0.5317, 0.4932, 0.5220, 0.4966],\n",
      "        [0.4880, 0.5096, 0.5318, 0.4935, 0.5221, 0.4965],\n",
      "        [0.4883, 0.5093, 0.5317, 0.4936, 0.5218, 0.4962],\n",
      "        [0.4882, 0.5093, 0.5317, 0.4934, 0.5216, 0.4965],\n",
      "        [0.4871, 0.5094, 0.5317, 0.4933, 0.5222, 0.4965],\n",
      "        [0.4882, 0.5098, 0.5322, 0.4936, 0.5221, 0.4967],\n",
      "        [0.4875, 0.5097, 0.5321, 0.4935, 0.5223, 0.4966],\n",
      "        [0.4873, 0.5088, 0.5310, 0.4930, 0.5213, 0.4961]], device='cuda:0')\n",
      "pred = tensor([[0.4883, 0.5099, 0.5325, 0.4938, 0.5223, 0.4968],\n",
      "        [0.4879, 0.5095, 0.5319, 0.4935, 0.5219, 0.4967],\n",
      "        [0.4874, 0.5093, 0.5314, 0.4933, 0.5219, 0.4962],\n",
      "        [0.4876, 0.5095, 0.5318, 0.4934, 0.5218, 0.4967],\n",
      "        [0.4883, 0.5096, 0.5320, 0.4937, 0.5221, 0.4964],\n",
      "        [0.4878, 0.5094, 0.5316, 0.4932, 0.5217, 0.4964],\n",
      "        [0.4881, 0.5091, 0.5315, 0.4936, 0.5217, 0.4963],\n",
      "        [0.4877, 0.5092, 0.5313, 0.4933, 0.5218, 0.4963],\n",
      "        [0.4874, 0.5092, 0.5314, 0.4934, 0.5219, 0.4963],\n",
      "        [0.4871, 0.5093, 0.5315, 0.4931, 0.5218, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4874, 0.5090, 0.5311, 0.4930, 0.5215, 0.4961],\n",
      "        [0.4881, 0.5095, 0.5319, 0.4935, 0.5218, 0.4963],\n",
      "        [0.4873, 0.5096, 0.5318, 0.4932, 0.5221, 0.4967],\n",
      "        [0.4877, 0.5094, 0.5317, 0.4933, 0.5218, 0.4966],\n",
      "        [0.4881, 0.5093, 0.5316, 0.4935, 0.5216, 0.4964],\n",
      "        [0.4873, 0.5091, 0.5312, 0.4932, 0.5218, 0.4963],\n",
      "        [0.4876, 0.5096, 0.5320, 0.4934, 0.5221, 0.4965],\n",
      "        [0.4876, 0.5092, 0.5316, 0.4934, 0.5218, 0.4964],\n",
      "        [0.4875, 0.5091, 0.5314, 0.4933, 0.5218, 0.4962],\n",
      "        [0.4874, 0.5095, 0.5319, 0.4932, 0.5218, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4883, 0.5094, 0.5318, 0.4938, 0.5220, 0.4965],\n",
      "        [0.4876, 0.5094, 0.5317, 0.4932, 0.5218, 0.4965],\n",
      "        [0.4884, 0.5093, 0.5317, 0.4937, 0.5219, 0.4964],\n",
      "        [0.4878, 0.5092, 0.5315, 0.4934, 0.5216, 0.4963],\n",
      "        [0.4870, 0.5091, 0.5313, 0.4929, 0.5216, 0.4963],\n",
      "        [0.4875, 0.5090, 0.5312, 0.4933, 0.5218, 0.4963],\n",
      "        [0.4882, 0.5092, 0.5317, 0.4936, 0.5217, 0.4964],\n",
      "        [0.4880, 0.5098, 0.5321, 0.4936, 0.5221, 0.4967],\n",
      "        [0.4875, 0.5092, 0.5315, 0.4933, 0.5218, 0.4963],\n",
      "        [0.4874, 0.5098, 0.5321, 0.4937, 0.5227, 0.4967]], device='cuda:0')\n",
      "pred = tensor([[0.4877, 0.5098, 0.5321, 0.4934, 0.5220, 0.4967],\n",
      "        [0.4882, 0.5095, 0.5317, 0.4934, 0.5217, 0.4964],\n",
      "        [0.4877, 0.5094, 0.5316, 0.4932, 0.5217, 0.4965],\n",
      "        [0.4874, 0.5094, 0.5318, 0.4934, 0.5220, 0.4965],\n",
      "        [0.4886, 0.5098, 0.5323, 0.4939, 0.5222, 0.4967],\n",
      "        [0.4867, 0.5093, 0.5315, 0.4927, 0.5217, 0.4965],\n",
      "        [0.4885, 0.5093, 0.5318, 0.4937, 0.5217, 0.4965],\n",
      "        [0.4869, 0.5097, 0.5318, 0.4932, 0.5223, 0.4965],\n",
      "        [0.4872, 0.5091, 0.5313, 0.4930, 0.5217, 0.4963],\n",
      "        [0.4873, 0.5095, 0.5318, 0.4933, 0.5221, 0.4965]], device='cuda:0')\n",
      "pred = tensor([[0.4878, 0.5096, 0.5320, 0.4934, 0.5220, 0.4965],\n",
      "        [0.4886, 0.5099, 0.5324, 0.4939, 0.5220, 0.4968],\n",
      "        [0.4869, 0.5092, 0.5313, 0.4931, 0.5221, 0.4963],\n",
      "        [0.4873, 0.5092, 0.5314, 0.4932, 0.5218, 0.4964],\n",
      "        [0.4879, 0.5095, 0.5319, 0.4937, 0.5220, 0.4968],\n",
      "        [0.4888, 0.5092, 0.5316, 0.4938, 0.5217, 0.4962],\n",
      "        [0.4879, 0.5099, 0.5324, 0.4937, 0.5223, 0.4968],\n",
      "        [0.4875, 0.5093, 0.5315, 0.4932, 0.5217, 0.4964],\n",
      "        [0.4878, 0.5094, 0.5316, 0.4935, 0.5221, 0.4964],\n",
      "        [0.4876, 0.5098, 0.5321, 0.4935, 0.5222, 0.4967]], device='cuda:0')\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(test_loader, model, criterion)\n",
    "\n",
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
